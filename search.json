[{"title":"Survey","url":"/2022/07/29/Survey/","content":"<h1 id=\"a-survey\">A Survey</h1>\r\n<blockquote>\r\n<p>目前的seq2seq类的模型在NLP领域大行其道。但是，它将各种复合句都编码为一个向量来处理。这样会出现组合爆炸问题，即简单句的组合会导致数据量剧增。因此，分析句子的结构，对复合句进行拆分，并将句子的结构知识运用到模型中，有望解决数据获取难等问题。针对该直觉，我进行了相关工作的调研，现将一些调研结果总结如下。\r\n<span id=\"more\"></span></p>\r\n</blockquote>\r\n<h2 id=\"句子的拆分和改写sentence-split-and-rephrase\">句子的拆分和改写：Sentence\r\nSplit and Rephrase</h2>\r\n<ul>\r\n<li>Fact-Aware Sentence Split and Rephrase with Permutation Invariant\r\nTraining\r\n<ul>\r\n<li>训练过程中对事实的遗失：Fact-aware Sentence Encoding</li>\r\n<li>简单句的顺序的影响：PIT(Permutation Invariant Training)</li>\r\n<li><img src=\"/2022/07/29/Survey/img-20220730153106.png\" title=\"fig:\" alt=\"img-20220730153106\"></li>\r\n</ul></li>\r\n</ul>\r\n<h2 id=\"语义解析semantic-parsing\">语义解析:Semantic Parsing</h2>\r\n<ul>\r\n<li>Iterative Utterance Segmentation for Neural Semantic Parsing\r\n<ul>\r\n<li>神经语义解析器通常无法将长时间和复杂的话语解析为正确的含义表示，因为缺乏利用组成的原则。为了解决这个问题，我们提出了一个新颖的框架，用于通过迭代话语细分来促进神经语义解析器。给定输入话语，我们的框架在两个神经模块之间迭代：用于从说话分割跨度的细分器，以及将跨度映射到部分含义表示的解析器。然后，这些中间解析结果被组成到最终含义表示形式中。一个关键优势是，该框架不需要任何手工艺模板或其他标记的数据进行分割：我们通过提出一种新颖的培训方法来实现这一目标，在这种方法中，解析器为细分器提供伪监督</li>\r\n<li><img src=\"/2022/07/29/Survey/img-20220730153231.png\" title=\"fig:\" alt=\"img-20220730153231\"></li>\r\n</ul></li>\r\n<li>SEQZERO: Few-shot Compositional Semantic Parsing with Sequential\r\nPrompts and Zero-shot Models\r\n<ul>\r\n<li>Seqzero将问题分解为一系列子问题，这些序列与形式语言的子语言相对应。基于分解，LMS只需要使用预测子段的提示来生成简短的答案。因此，seqzero避免了一次产生长长的规范话语。此外，Seqzero不仅采用了几个射击模型，而且还采用了零拍模型来减轻过度拟合。特别是，Seqzero通过配备了我们建议的约束重新制定的合奏来阐明两种模型的优点。\r\nSeqzero在GeoQuery和EcommerceQuery上实现了基于BART的模型的SOTA性能，它们是两个具有组成数据分配的少量数据集。</li>\r\n<li>SQL拆分示例<img src=\"/2022/07/29/Survey/img-20220730151705.png\" alt=\"img-20220730151705\"></li>\r\n</ul></li>\r\n</ul>\r\n<h2 id=\"组合泛化compositional-generalization\">组合泛化：Compositional\r\nGeneralization</h2>\r\n<ul>\r\n<li>Hierarchical Poset Decoding for Compositional Generalization in\r\nLanguage\r\n<ul>\r\n<li>我们将人类语言理解形式化为结构化的预测任务，其中输出为部分有序集（POSET）。当前的编码器架构不能正确考虑语义的POSET结构，因此遭受了不良的组成概括能力。在本文中，我们提出了一种新型的层次poset解码范式，用于语言中的组成概括。直觉：（1）拟议的范式在语义中执行部分置换不变性，从而避免过拟合bias\r\nordering信息；\r\n（2）分层机制允许捕获POSET的高级结构。我们评估了建议的decoder关于CFQ的表现。这是一个庞大而现实的自然语言问题，回答数据集，专门设计用于衡量组成概括。结果表明，它的表现优于当前解码器。</li>\r\n<li><img src=\"/2022/07/29/Survey/img-20220730153205.png\" title=\"fig:\" alt=\"img-20220730153205\"></li>\r\n</ul></li>\r\n<li>SUBS: Subtree Substitution for Compositional Semantic Parsing\r\n<ul>\r\n<li>将子树替换用于组成数据增强，在此我们认为具有类似语义函数的子树是可交换的。</li>\r\n<li>子树替换示例：<img src=\"/2022/07/29/Survey/img-20220730151835.png\" alt=\"img-20220730151835\"></li>\r\n</ul></li>\r\n<li>Unlocking Compositional Generalization in Pre-trained Models Using\r\nIntermediate Representations\r\n<ul>\r\n<li>序列到序列（SEQ2SEQ）模型在语义解析中很普遍，但已被发现在分布外的组成概括方面挣扎。尽管已经提出了专门的模型体系结构和SEQ2SEQ模型的预培训来解决此问题，但前者通常以一般性为代价，而后者仅显示有限的成功。在本文中，我们研究了中间表示对预训练的SEQ2SEQ模型中组成概括的影响，而无需更改模型体系结构，并确定设计有效表示的关键方面。我们没有将自然语言直接映射到可执行形式的训练，而是将其映射到具有更强的与自然语言的结构对应的可逆或有损中间表示形式。我们提出的中间表示和预培训模型的组合非常有效，最佳组合获得了CFQ上的最新最新作品（+14.8精度点）以及三个文本到\r\n- 到 -\r\nSQL数据集（+15.0至+19.4精度点）。这项工作强调了中间表示提供了一种重要且可能被忽视的自由度，以提高预训练的SEQ2SEQ模型的组成概括能力。</li>\r\n</ul></li>\r\n</ul>\r\n<h2 id=\"语义角色标注semantic-role-labeling\">语义角色标注：Semantic role\r\nlabeling</h2>\r\n<ul>\r\n<li>Syntax-aware Neural Semantic Role Labeling∗\r\n<ul>\r\n<li>传统的基于离散功能的SRL方法是由句法和语义结构之间的紧密相关性的激励，从而大大利用了句法特征。相反，基于深神经网络的方法通常将输入句子编码为单词序列，而无需考虑句法结构。在这项工作中，我们研究了以前的几种编码句法树的方法，并对额外的语法感知表示是否对神经SRL模型有益。基准CONLL-2005数据集的实验表明，语法感知的SRL方法可以通过Elmo的外部单词表示有效地改善强大基线的性能。借助额外的语法意识表示，我们的方法在测试数据上实现了新的最新的85.6\r\nF1（单个模型）和86.6\r\nF1（集合），分别优于0.8和1.0的Elmo的相应强基础。进行了详细的错误分析，以获得有关研究方法的更多见解。</li>\r\n</ul></li>\r\n</ul>\r\n<h2 id=\"自动化合规检查accautomated-compliance-checking\">自动化合规检查：ACC（Automated\r\nCompliance Checking）</h2>\r\n<ul>\r\n<li>SPAR.txt, a cheap Shallow Parsing approach for Regulatory texts\r\n<ul>\r\n<li>自动化合规检查（ACC）系统旨在将语义解析为一组规则。但是，已知语义解析很难，需要大量的培训数据。创建此类培训数据的复杂性导致了研究的研究，该研究重点是小型子任务，例如浅解析或提取有限的规则子集。这项研究介绍了一项浅解析任务，培训数据相对便宜，目的是学习ACC的词典。我们注释了200个句子Spar.txt1的小域特异性数据集，并训练一个序列标记器，该序列标记器在测试集上达到79,93\r\nF1分数。</li>\r\n<li><img src=\"/2022/07/29/Survey/img-20220730152243.png\" title=\"fig:\" alt=\"img-20220730152243\"></li>\r\n</ul></li>\r\n</ul>\r\n"},{"title":"EM","url":"/2023/01/15/EM/","content":"<h1 id=\"em算法\">EM算法</h1>\r\n<blockquote>\r\n<p>最大期望演算法（Expectation-maximization\r\nalgorithm，又譯期望最大化算法）在统计中被用于寻找，依赖于不可观察的隐性变量的概率模型中，参数的最大似然估计。本文将从EM算法的背景、原理和应用三个层面对该算法进行细致的讲解。\r\n<span id=\"more\"></span></p>\r\n</blockquote>\r\n<h2 id=\"引入高斯混合模型gmm\">引入——高斯混合模型（GMM）</h2>\r\n<p><strong>定义</strong>：高斯混合模型是指具有<span class=\"math inline\">\\(P(y|\\theta) = \\sum \\limits_{k=1}^K\r\n\\alpha_k\\phi(y|\\theta_k)\\)</span>形式的概率分布模型。其中<span class=\"math inline\">\\(\\alpha_k \\geq 0\\)</span>且<span class=\"math inline\">\\(\\sum \\limits_{k=1}^K \\alpha_k= 1\\)</span>。<span class=\"math inline\">\\(\\phi(y|\\theta_k)\\)</span>是高斯分布密度，<span class=\"math inline\">\\(\\theta_k=(\\mu_k,\\sigma_k^2)\\)</span>，</p>\r\n<p><span class=\"math display\">\\[\\begin{aligned}\r\n\\phi(y|\\theta_k)=\\frac{1}{\\sqrt{2\\pi}\\sigma_k}exp(-\\frac{(y-\\mu_k)^2}{2\\sigma_k^2})\r\n\\end{aligned}\\]</span> 称为第k个分模型。\r\n<strong>GMM参数估计的EM算法</strong> 输入：观测数据<span class=\"math inline\">\\(y_1,y_2,...,y_N\\)</span>，高斯混合模型；\r\n输出：高斯混合模型的参数</p>\r\n<ul>\r\n<li><p>取参数初始值开始迭代</p></li>\r\n<li><p>E步：根据当前模型参数，计算分模型k对观测数据<span class=\"math inline\">\\(y_j\\)</span>的响应度 <span class=\"math inline\">\\(\\begin{aligned}\\hat\\gamma_{jk} =\r\n\\frac{\\alpha_k\\phi(y_j|\\theta_k)}{\\sum\r\n\\limits_{k=1}^K\\alpha_k\\phi(y_j|\\theta_k)}\\end{aligned}\\)</span></p></li>\r\n<li><p>M步：计算新一轮的模型参数 <span class=\"math inline\">\\(n_k = \\sum\r\n\\limits_{j=1}^NE_{\\gamma_{jk}}\\)</span></p>\r\n<p><span class=\"math inline\">\\(\\begin{aligned}\\hat\\mu_k = \\frac{\\sum\r\n\\limits_{j=1}^N\\hat\\gamma_{jk}y_j}{\\sum\r\n\\limits_{j=1}^N\\hat\\gamma_{jk}}\\end{aligned}\\)</span></p>\r\n<p><span class=\"math inline\">\\(\\begin{aligned}\\hat\\sigma_k^2 =\r\n\\frac{\\sum \\limits_{j=1}^N\\hat\\gamma_{jk}(y_j-\\mu_k)^2}{\\sum\r\n\\limits_{j=1}^N\\hat\\gamma_{jk}}\\end{aligned}\\)</span></p></li>\r\n<li><p>重复以上两步，直到收敛。</p></li>\r\n</ul>\r\n<p>根据这个算法，我们使用python实现GMM中参数估计的EM算法，并三次迭代过程的运行结果依次进行展示。其中，实线部分代表真实的概率分布。虚线部分代表当前参数对应的概率分布。</p>\r\n<p><strong>例子解析</strong>\r\n通过这个例子，我们可以总结出EM算法的基本使用步骤： (1)选取参数初始值\r\n(2)E步：根据当前参数值，计算一个函数值\r\n(3)M步：根据计算出的函数值，更新参数估计值 (4)重复(2)(3)直到收敛\r\n但是，我们仍然存在很多疑问：</p>\r\n<ul>\r\n<li>为什么要使用EM算法？</li>\r\n<li>EM算法为什么可行？</li>\r\n<li>EM算法中的参数应当如何进行初始化？</li>\r\n<li>E步中需要根据当前参数值去求哪个函数的值？</li>\r\n<li>M步中参数应该如何根据E步求出的函数值进行估计？</li>\r\n<li>收敛的判断标准是什么？</li>\r\n</ul>\r\n<p>带着这些疑问，我们进行进一步的EM算法的产生背景和原理的学习。解决完这些疑问后，本文将进一步展示EM算法的应用实例，帮助读者真正掌握EM算法的使用流程。</p>\r\n<h2 id=\"背景\">背景</h2>\r\n<p><strong>基本概念</strong></p>\r\n<ul>\r\n<li>概率模型：是用来描述不同随机变量之间关系的数学模型，通常情况下刻画了一个或多个随机变量之间的相互非确定性的概率关系。从数学上讲，该模型通常被表达为(Y,P)，其中Y是观测集合用来描述可能的观测结果，P是Y对应的概率分布函数或密度函数集合。最常见的概率分布函数是参数模型，它是由有限维参数构成的分布集合。</li>\r\n<li>观测变量是指在试验中可以通过观测直接得到的随机变量。</li>\r\n<li>隐变量指的是不可观测的随机变量。隐变量可以通过使用数学模型依据观测得的数据被推断出来。</li>\r\n</ul>\r\n<p>如果使用概率模型来对观测变量进行描述，在选定概率模型后，需要解决的问题就变成了对概率模型的参数的估计。其中，最常见并且也是应用最广泛的方法是极大似然估计法（英語：Maximum\r\nLikelihood Estimation，簡作MLE）。</p>\r\n<ul>\r\n<li>MLE算法\r\n<ul>\r\n<li>基本思想\r\n<ul>\r\n<li>选定一组参数，使得在该参数条件下，观测变量存在的概率最大</li>\r\n</ul></li>\r\n<li>算法流程\r\n<ul>\r\n<li>写出模型的对数似然函数</li>\r\n<li>求参数的梯度，并使梯度为0，求解极大值点，作为参数的估计值</li>\r\n</ul></li>\r\n</ul></li>\r\n</ul>\r\n<p>对于只存在观测变量的概率模型，使用极大似然估计法往往就可以很好地估计参数。但是，当概率模型中引入隐变量的时候，MLE就难以按照上述流程解决问题了。</p>\r\n<p><strong>典型问题</strong>\r\n抛硬币A,B,C，正面的概率分别为π,p,q。先抛A，当A的结果是正面时抛B，反之抛C。记录第二次抛硬币的结果，独立重复n次实验。\r\n根据上述流程，写出其似然函数如下： <span class=\"math inline\">\\(P(Y|\\theta)=\\prod \\limits_{j=1}^n[\\pi\r\np^{y_j}(1-p)^{1-y_j} + (1-\\pi)q^{y_j}(1-q)^{1-y_j}]\\)</span>\r\n由于隐变量的存在，导致对该似然函数求极值点，无解析解。针对MLE中存在的这种问题，EM算法产生，并有效地解决了这类问题。\r\n<strong>EM算法</strong>\r\n输入：观测变量数据Y，隐变量数据Z，联合分布P(Y,Z|θ)，条件分布P(Z|Y,θ)；\r\n输出：模型参数估计值θ (1)选择初始参数\r\n(2)E：根据当前参数θi的估计值，计算Q(θ,θi)\r\n(3)M：求使Q(θ,θi)最大的估计值θ，作为新一轮的参数估计值θi+1\r\n(4)重复(2)和(3)，直至收敛（参数估计值变化量小于预设阈值或者Q函数值变化量小于预设阈值）</p>\r\n<p>由于在隐变量存在时，概率模型的参数估计问题没有解析解。因此，EM算法产生。它试图通过一种迭代的方式去逼近最佳估计。\r\n至此，我们已经成功解决了EM算法为什么会产生的疑问。引入中的其他疑问，将会在原理中进一步解释。</p>\r\n<h2 id=\"原理\">原理</h2>\r\n<p><strong>Q函数的选取</strong>\r\n在刚刚提到的EM算法的定义中，我们看到在E步和M步都涉及到一个函数:<span class=\"math inline\">\\(Q(\\theta,\\theta_i)\\)</span>。那么这个函数是如何得到的？\r\n我们知道，EM算法的产生是为了解决MLE的局限性。但是其思想是一致的，最大化似然概率。\r\n<span class=\"math inline\">\\(P(Y|\\theta) = \\sum\r\n\\limits_ZP(Y,Z|\\theta)\\)</span> 最大化似然概率又等价于最大化对数似然概率\r\n<span class=\"math inline\">\\(L(\\theta) = log(\\sum\r\n\\limits_ZP(Y,Z|\\theta))\\)</span>\r\n而EM算法通过迭代逐步逼近最佳参数估计，因此我们考量两次相邻迭代之间的差：\r\n<span class=\"math inline\">\\(\\begin{aligned}L(\\theta)-L(\\theta^{(i)})\r\n&amp;= log(\\sum \\limits_{Z}P(Y|Z,\\theta)P(Z|\\theta)) -\r\nlogP(Y|\\theta^{(i)}) \\\\ &amp;= log(\\sum\r\n\\limits_{Z}P(Z|Y,\\theta^{(i)})\\frac{P(Y|Z,\\theta)P(Z|\\theta))}{P(Z|Y,\\theta^{(i)})}\r\n- logP(Y|\\theta^{(i)})\\end{aligned}\\)</span>\r\n这里，我们需要利用Jessen不等式进行进一步的缩放。</p>\r\n<blockquote>\r\n<p>Jessen不等式证明： <strong>凸函数</strong>\r\n凸函数是一个定义在某个向量空间的凸子集 C（区间）上的实值函数\r\nf，如果在其定义域 C 上的任意两点<span class=\"math inline\">\\(x_1,x_2,0\r\n\\leq t \\leq 1\\)</span>，有 <span class=\"math inline\">\\(tf(x_1)+(1-t)f(x_2) \\geq f(tx_1+(1-t)x_2) \\quad\r\n\\quad (1)\\)</span> 也就是说凸函数任意两点的割线位于函数图形上方，\r\n这也是Jensen不等式的两点形式。 <strong>Jensen不等式</strong>\r\n若对于任意点集<span class=\"math inline\">\\({x_i}\\)</span>，若<span class=\"math inline\">\\(\\lambda_i \\geq 0\\)</span>且<span class=\"math inline\">\\(\\sum \\limits_i\\lambda_i =\r\n1\\)</span>，使用数学归纳法，可以<a href=\"(https://zhuanlan.zhihu.com/p/39315786)\">证明</a>凸函数 f (x)\r\n满足： <span class=\"math inline\">\\(f(\\sum \\limits_{i=1}^M\\lambda_ix_i)\r\n\\leq \\sum \\limits_{i=1}^M\\lambda_if(x_i) \\quad \\quad (2)\\)</span>\r\n公式(2)被称为 Jensen 不等式，它是式(1)的泛化形式。</p>\r\n</blockquote>\r\n<p>对log函数取负号即变为凸函数，然后进行缩放，然后左右再同时取负号，可以得到：\r\n<span class=\"math display\">\\[\\begin{aligned}\r\nL(\\theta)-L(\\theta^{i})&amp;=log(\\sum_{Z}P(Z|Y,\\theta^i)\\frac{\r\nP(Y|Z,\\theta)P(Z|\\theta)}{P(Z|Y,\\theta^i)})-\\log P(Y|\\theta^i)\\\\\r\n&amp;\\ge \\sum_{Z}\r\nP(Z|Y,\\theta^i)log(\\frac{P(Y|Z,\\theta)P(Z|\\theta)}{P(Z|Y,\\theta^i)})-\\log\r\nP(Y|\\theta^i)\\\\ &amp;=\\sum_{Z}\r\nP(Z|Y,\\theta^i)log(\\frac{P(Y|Z,\\theta)P(Z|\\theta)}{P(Z|Y,\\theta^i)})-\\sum_{Z}\r\nP(Z|Y,\\theta^i)\\log P(Y|\\theta^i)\\\\ &amp;= \\sum_{Z}\r\nP(Z|Y,\\theta^i)[log\\frac{P(Y|Z,\\theta)P(Z|\\theta)}{P(Z|Y,\\theta^i)}-logP(Y|\\theta^{i})]\r\n\\\\ &amp;= \\sum_{Z}\r\nP(Z|Y,\\theta^i)log\\frac{P(Y|Z,\\theta)P(Z|\\theta)}{P(Z|Y,\\theta^i)\r\nP(Y|\\theta^{i})} \\end{aligned}\\]</span></p>\r\n<p>我们将缩放后的差值和上一轮迭代的对数似然函数的结果相加，定义如下：\r\n<span class=\"math inline\">\\(\\begin{aligned}B(\\theta,\\theta_i) =\r\nL(\\theta_i) + \\sum_{Z}\r\nP(Z|Y,\\theta^i)log\\frac{P(Y|Z,\\theta)P(Z|\\theta)}{P(Z|Y,\\theta^i)\r\nP(Y|\\theta^{i})}\\end{aligned}\\)</span>\r\n我们根据定义，可以得知如下两个结论： (1)<span class=\"math inline\">\\(B(\\theta_i,\\theta_i) = L(\\theta_i)\\)</span>\r\n(2)<span class=\"math inline\">\\(L(\\theta) \\geq\r\nB(\\theta,\\theta_i)\\)</span> 更形象地看，两者的关系可以用下图表示：\r\n<img src=\"/2023/01/15/EM/01/15/EM/BL.png\" class title=\"图片引用方法一\">\r\n其中，对于每次迭代的增值。B函数的增值幅度永远不超过对数似然函数的增值幅度。因此，我们只需要保证迭代每次都可以增加B函数，即可达到通过迭代逐步增加对数似然函数的目的。\r\n因此，第i+1轮的<span class=\"math inline\">\\(\\theta\\)</span>的估计值可以表示为： <span class=\"math inline\">\\(\\begin{aligned}\\theta_{i+1} &amp;= argmax_{\\theta}\r\nB(\\theta,\\theta_i) \\\\ &amp;= argmax_\\theta (L(\\theta_i) + \\sum_{Z}\r\nP(Z|Y,\\theta^i)log\\frac{P(Y|Z,\\theta)P(Z|\\theta)}{P(Z|Y,\\theta^i)\r\nP(Y|\\theta^{i})})\\\\ &amp;= argmax_\\theta(L(\\theta_i) -\\sum_{Z}\r\nP(Z|Y,\\theta^i)logP(Z|Y,\\theta^i) P(Y|\\theta^{i}) + \\sum_{Z}\r\nP(Z|Y,\\theta^i)logP(Y|Z,\\theta)P(Z|\\theta))\\\\\r\n&amp;=argmax_\\theta(\\sum_{Z}\r\nP(Z|Y,\\theta^i)logP(Y|Z,\\theta)P(Z|\\theta))\\\\\r\n&amp;=argmax_\\theta(\\sum\\limits_ZP(Z|Y,\\theta_i)logP(Y,Z|\\theta))\\\\\r\n&amp;=argmax_\\theta(Q(\\theta,\\theta^i)) \\end{aligned}\\)</span>\r\n最后一行就是EM算法定义中提到的Q函数。它的期望形式如下： <span class=\"math display\">\\[\\begin{aligned}Q(\\theta,\\theta^i)&amp;=\\sum\\limits_{Z}\r\nP(Z|Y,\\theta^i)logP(Y,Z|\\theta)\\\\\r\n&amp;=E_Z[logP(Y,Z|\\theta)|Y,\\theta^i]\\\\\r\n&amp;=E_{Z|Y,\\theta^i}logP(Y,Z|\\theta) \\end{aligned}\\]</span>\r\n至此，Q函数的来源问题我们也已经解决。下面，我们来进一步证明EM算法可以通过迭代的方式逐步增大对数似然函数。\r\n<strong>证明：</strong><span class=\"math inline\">\\(P(Y|\\theta_{i+1})\r\n\\geq P(Y|\\theta_i)\\)</span></p>\r\n<h2 id=\"应用\">应用</h2>\r\n<ul>\r\n<li><p>隐马尔可夫模型无监督学习</p></li>\r\n<li><p>PLSA</p></li>\r\n<li><p>LDA的变分EM算法</p></li>\r\n</ul>\r\n<h2 id=\"推广\">推广</h2>\r\n<p><strong>F函数</strong>：假设隐变量数据<span class=\"math inline\">\\(Z\\)</span>的概率分布为<span class=\"math inline\">\\(\\widetilde{P}(Z)\\)</span>,定义分布$ <span class=\"math inline\">\\(与参数\\)</span>$的函数: <span class=\"math display\">\\[\r\nF( \\widetilde{P},\\theta) = E_{ \\widetilde{P}}[\\log P(Y,Z|\\theta)] + H(\r\n\\widetilde{P})\r\n\\]</span> 称为<span class=\"math inline\">\\(F\\)</span>函数。式中<span class=\"math inline\">\\(H(\\widetilde{P}) =\r\n-E_{\\widetilde{P}}\\log\\widetilde{P}(Z)\\)</span>是分布<span class=\"math inline\">\\(\\widetilde{P}(Z)\\)</span>的熵。</p>\r\n<h3 id=\"推论em算法的一次迭代可由f函数的极大-极大算法实现\">推论：EM算法的一次迭代可由F函数的极大-极大算法实现。</h3>\r\n<ul>\r\n<li>GEM算法1：直接对F函数中的<span class=\"math inline\">\\(\\widetilde{P}\\)</span>和<span class=\"math inline\">\\(\\theta\\)</span>进行迭代\r\n<ul>\r\n<li>缺点：很难直接找到<span class=\"math inline\">\\(\\theta\\)</span>对用的极大值点</li>\r\n</ul></li>\r\n<li>GME算法2：对Q函数进行迭代\r\n<ul>\r\n<li>优点：只需找到<span class=\"math inline\">\\(\\theta^{i+1}\\)</span>使Q函数变大即可</li>\r\n</ul></li>\r\n<li>GME算法3：对Q函数中的参数，一次进行一个分量的迭代</li>\r\n</ul>\r\n<h2 id=\"理解em算法的几重境界\">理解EM算法的几重境界</h2>\r\n<h3 id=\"em-e-m\">EM = E + M</h3>\r\n<ul>\r\n<li>使用E+M的形式，突破了MLE的限制</li>\r\n</ul>\r\n<h3 id=\"em算法是一种局部下限构造\">EM算法是一种局部下限构造</h3>\r\n<ul>\r\n<li><p>根据EM算法证明，我们可以看出，他是通过构造下限，让下限逐步提高，从而保证似然函数也是逐步提升的</p>\r\n<figure>\r\n<img src=\"https://picx.zhimg.com/50/v2-a38b6748f36f0cb9bcd43b5ca435e5c6_720w.jpg?source=1940ef5c\" alt=\"img\">\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure></li>\r\n<li><p>如下图所示，每次都构造一个下限（绿色），然后通过下限的不断提升，保证似然函数的不断提升</p>\r\n<figure>\r\n<img src=\"/2023/01/15/EM/image-20230115193948771.png\" alt=\"image-20230115193948771\">\r\n<figcaption aria-hidden=\"true\">image-20230115193948771</figcaption>\r\n</figure></li>\r\n</ul>\r\n<h3 id=\"k-means是一种hard-em算法\">K-means是一种Hard EM算法</h3>\r\n<figure>\r\n<img src=\"/2023/01/15/EM/image-20220913224805897.png\" alt=\"image-20220913224805897\">\r\n<figcaption aria-hidden=\"true\">image-20220913224805897</figcaption>\r\n</figure>\r\n<ul>\r\n<li><p>K-Means算法对数据点的聚类进行了“硬分配”，即每个数据点只属于唯一的聚类；而GMM的EM解法则基于后验概率分布，对数据点进行“软分配”，即每个单独的高斯模型对数据聚类都有贡献，不过贡献值有大有小。</p></li>\r\n<li><p>而其实，我们可以将K-Means算法归类为GMM的EM解法的一个特例。</p>\r\n<figure>\r\n<img src=\"https://pic2.zhimg.com/50/v2-1c1d5d2b658b4e9580a051f955df7b48_720w.jpg?source=1940ef5c\" alt=\"img\">\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure></li>\r\n</ul>\r\n<h4 id=\"关于初始化\">关于初始化</h4>\r\n<ul>\r\n<li>随机选取一个点作为第一个聚类中心。</li>\r\n<li>计算所有样本与第一个聚类中心的距离。</li>\r\n<li>选择出上一步中距离最大的点作为第二个聚类中心。</li>\r\n<li>迭代：计算所有点到与之最近的聚类中心的距离，选取最大距离的点作为新的聚类中心。</li>\r\n<li>终止条件：直到选出了这k个中心。</li>\r\n</ul>\r\n<h4 id=\"类比k-meansem算法初始化\">类比K-means,EM算法初始化</h4>\r\n<ul>\r\n<li><p>采用一种基于网格的聚类算法来初始化EM算法</p>\r\n<figure>\r\n<img src=\"/2023/01/15/EM/797505-20160401131828238-1041936013.png\" alt=\"img\">\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure>\r\n<figure>\r\n<img src=\"https://images2015.cnblogs.com/blog/797505/201604/797505-20160401131856191-574167681.png\" alt=\"img\">\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure></li>\r\n<li><p>我觉得这篇论文的主要思想应该是这样的：就拿身高举例。它就是首先做一个预处理，将身高在一个范围内（例如1.71至1.74）的分成一个网格，再看这个网格占全部数据的多少，以此判断出该网格为高密度还是低密度，然后循环算出所有网格的，再使用EM算法计算哪些高密度网格，这样会使整个算法收敛的快一些。还有一些其他的论文也是讲的这个。</p></li>\r\n</ul>\r\n<h4 id=\"进一步理解隐变量是存在一种分布的\">进一步理解：隐变量是存在一种分布的</h4>\r\n<figure>\r\n<img src=\"https://picx.zhimg.com/50/v2-1cb36ffe3e6b918080b16627389395a5_720w.jpg?source=1940ef5c\" alt=\"img\">\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure>\r\n<h3 id=\"em-是广义em的特例从隐变量到隐分布\">EM\r\n是广义EM的特例：从隐变量到隐分布</h3>\r\n<ul>\r\n<li><p>引入隐分布来再次证明EM算法</p>\r\n<figure>\r\n<img src=\"https://pica.zhimg.com/50/v2-866e11172dc0fba6daefa9f370411b11_720w.jpg?source=1940ef5c\" alt=\"img\">\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure></li>\r\n<li><p>我们把Jensen不等收右边的部分定义为<strong>自由能</strong>，那么<strong>E步骤是固定参数优化隐分布，\r\nM步骤是固定隐分布优化参数，这就是广义EM算法了</strong>。</p>\r\n<figure>\r\n<img src=\"https://pica.zhimg.com/50/v2-4240a9b9e33693ff67024bd96821e2f7_720w.jpg?source=1940ef5c\" alt=\"img\">\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure></li>\r\n<li><p>有了广义EM算法之后， 我们对自由能深入挖掘，\r\n发现自由能和似然度和KL距离之间的关系：</p>\r\n<figure>\r\n<img src=\"https://pica.zhimg.com/50/v2-47d2d736c98ab6bf95e56f66620f3fc7_720w.jpg?source=1940ef5c\" alt=\"img\">\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure>\r\n<blockquote>\r\n<p><strong>KL距离</strong></p>\r\n<ul>\r\n<li><p>全称：Kullback-Leibler差异（Kullback-Leibler\r\ndivergence）</p></li>\r\n<li><p>又称：相对熵（relative entropy）</p></li>\r\n<li><p>数学本质：衡量<strong>相同事件空间</strong>里<strong>两个概率分布</strong>相对<strong>差距</strong>的<strong>测度</strong></p></li>\r\n<li><p>定义; <span class=\"math display\">\\[\r\nD(p||q) = \\sum_{x \\in X}p(x)\\log \\frac{p(x)}{q(x)}\r\n\\]</span></p></li>\r\n<li><p>约定：$0log(0/q)=0、p l o g ( p / 0 ) = $</p></li>\r\n<li><p>等价形式： <span class=\"math display\">\\[\r\nD(p||q) = E_p[\\log \\frac{p(X)}{q(X)}]\r\n\\]</span></p></li>\r\n<li><p>说明：</p>\r\n<ul>\r\n<li>两个概率分布差距越大，KL距离越大</li>\r\n<li>两个概率分布差距越小，KL距离为0</li>\r\n</ul></li>\r\n</ul>\r\n</blockquote></li>\r\n<li><p>所以固定参数的情况下， 那么只能最优化KL距离了，\r\n那么隐分布只能取如下分布：</p>\r\n<figure>\r\n<img src=\"https://pic2.zhimg.com/50/v2-28aa54c91428fa32a93fe7243034e70f_720w.jpg?source=1940ef5c\" alt=\"img\">\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure></li>\r\n<li><p>而这个<strong>在EM算法里面是直接给出的</strong>。\r\n所以EM算法是广义EM算法的天然最优的隐分布情况。\r\n<strong>但是很多时候隐分布不是那么容易计算的！</strong></p>\r\n<p>前面的推理虽然很简单， 但是要理解到位真心不容易，\r\n首先要<strong>深入理解KL距离是如何被引入的？</strong></p>\r\n<figure>\r\n<img src=\"https://pic3.zhimg.com/50/v2-5fb1549c245298846063a9742cb11e1a_720w.jpg?source=1940ef5c\" alt=\"img\">\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure></li>\r\n<li><p>其次要理解， 为什么传统的EM算法，\r\n<strong>不存在第一个最优化</strong>？因为在<strong>没有限制的隐分布（天然情况下）</strong>情况下，\r\n第一个最优就是要求：</p>\r\n<figure>\r\n<img src=\"https://pic3.zhimg.com/50/v2-227eccdac2131d6e0538d83515444624_720w.jpg?source=1940ef5c\" alt=\"img\">\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure></li>\r\n<li><p>而这个隐分布， EM算法里面是直接给出的，而不是让你证明得到的。</p>\r\n<figure>\r\n<img src=\"https://pic1.zhimg.com/50/v2-2004ef50d0796d32e6cd61ac7a6cdf2d_720w.jpg?source=1940ef5c\" alt=\"img\">\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure></li>\r\n</ul>\r\n","tags":["EM算法"]},{"title":"GNN4NLP","url":"/2023/01/16/GNN4NLP/","content":"<h1 id=\"gnn-in-natural-language-processing\">GNN in Natural Language\r\nProcessing</h1>\r\n<blockquote>\r\n<p>本篇主要介绍GNN在NLP中的使用情况。聚焦于其理论基础和主流的应用框架。对GNN在NLP中的使用情况有总体的了解。</p>\r\n<span id=\"more\"></span>\r\n</blockquote>\r\n<ol type=\"1\">\r\n<li><p><strong>Conversation Modeling on Reddit using a Graph-Structured\r\nLSTM.</strong> TACL 2018. <a href=\"https://arxiv.org/pdf/1704.02080\">paper</a></p>\r\n<p><em>Vicky Zayats, Mari Ostendorf.</em></p></li>\r\n<li><p><strong>Learning Graphical State Transitions.</strong> ICLR 2017.\r\n<a href=\"https://openreview.net/forum?id=HJ0NvFzxl\">paper</a></p>\r\n<p><em>Daniel D. Johnson.</em></p></li>\r\n<li><p><strong>Multiple Events Extraction via Attention-based Graph\r\nInformation Aggregation.</strong> EMNLP 2018. <a href=\"https://arxiv.org/pdf/1809.09078.pdf\">paper</a></p>\r\n<p><em>Xiao Liu, Zhunchen Luo, Heyan Huang.</em></p></li>\r\n<li><p><strong>Recurrent Relational Networks.</strong> NeurIPS 2018. <a href=\"http://papers.nips.cc/paper/7597-recurrent-relational-networks.pdf\">paper</a></p>\r\n<p><em>Rasmus Palm, Ulrich Paquet, Ole Winther.</em></p></li>\r\n<li><p><strong>Improved Semantic Representations From Tree-Structured\r\nLong Short-Term Memory Networks.</strong> ACL 2015. <a href=\"https://www.aclweb.org/anthology/P15-1150\">paper</a></p>\r\n<p><em>Kai Sheng Tai, Richard Socher, Christopher D.\r\nManning.</em></p></li>\r\n<li><p><strong>Encoding Sentences with Graph Convolutional Networks for\r\nSemantic Role Labeling.</strong> EMNLP 2017. <a href=\"https://arxiv.org/abs/1703.04826\">paper</a></p>\r\n<p><em>Diego Marcheggiani, Ivan Titov.</em></p></li>\r\n<li><p><strong>Graph Convolutional Networks with Argument-Aware Pooling\r\nfor Event Detection.</strong> AAAI 2018. <a href=\"http://ix.cs.uoregon.edu/~thien/pubs/graphConv.pdf\">paper</a></p>\r\n<p><em>Thien Huu Nguyen, Ralph Grishman.</em></p></li>\r\n<li><p><strong>Exploiting Semantics in Neural Machine Translation with\r\nGraph Convolutional Networks.</strong> NAACL 2018. <a href=\"http://www.aclweb.org/anthology/N18-2078\">paper</a></p>\r\n<p><em>Diego Marcheggiani, Joost Bastings, Ivan Titov.</em></p></li>\r\n<li><p><strong>Exploring Graph-structured Passage Representation for\r\nMulti-hop Reading Comprehension with Graph Neural Networks.</strong>\r\n2018. <a href=\"https://arxiv.org/abs/1809.02040\">paper</a></p>\r\n<p><em>Linfeng Song, Zhiguo Wang, Mo Yu, Yue Zhang, Radu Florian, Daniel\r\nGildea.</em></p></li>\r\n<li><p><strong>Graph Convolution over Pruned Dependency Trees Improves\r\nRelation Extraction.</strong> EMNLP 2018. <a href=\"https://arxiv.org/abs/1809.10185\">paper</a></p>\r\n<p><em>Yuhao Zhang, Peng Qi, Christopher D. Manning.</em></p></li>\r\n<li><p><strong>N-ary relation extraction using graph state\r\nLSTM.</strong> EMNLP 18. <a href=\"https://arxiv.org/abs/1808.09101\">paper</a></p>\r\n<p><em>Linfeng Song, Yue Zhang, Zhiguo Wang, Daniel\r\nGildea.</em></p></li>\r\n<li><p><strong>A Graph-to-Sequence Model for AMR-to-Text\r\nGeneration.</strong> ACL 2018. <a href=\"https://arxiv.org/abs/1805.02473\">paper</a></p>\r\n<p><em>Linfeng Song, Yue Zhang, Zhiguo Wang, Daniel\r\nGildea.</em></p></li>\r\n<li><p><strong>Graph-to-Sequence Learning using Gated Graph Neural\r\nNetworks.</strong> ACL 2018. <a href=\"https://arxiv.org/pdf/1806.09835.pdf\">paper</a></p>\r\n<p><em>Daniel Beck, Gholamreza Haffari, Trevor Cohn.</em></p></li>\r\n<li><p><strong>Cross-Sentence N-ary Relation Extraction with Graph\r\nLSTMs.</strong> TACL. <a href=\"https://arxiv.org/abs/1708.03743\">paper</a></p>\r\n<p><em>Nanyun Peng, Hoifung Poon, Chris Quirk, Kristina Toutanova,\r\nWen-tau Yih.</em></p></li>\r\n<li><p><strong>Sentence-State LSTM for Text Representation.</strong> ACL\r\n2018. <a href=\"https://arxiv.org/abs/1805.02474\">paper</a></p>\r\n<p><em>Yue Zhang, Qi Liu, Linfeng Song.</em></p></li>\r\n<li><p><strong>End-to-End Relation Extraction using LSTMs on Sequences\r\nand Tree Structures.</strong> ACL 2016. <a href=\"https://arxiv.org/abs/1601.00770\">paper</a></p>\r\n<p><em>Makoto Miwa, Mohit Bansal.</em></p></li>\r\n<li><p><strong>Graph Convolutional Encoders for Syntax-aware Neural\r\nMachine Translation.</strong> EMNLP 2017. <a href=\"https://arxiv.org/pdf/1704.04675\">paper</a></p>\r\n<p><em>Joost Bastings, Ivan Titov, Wilker Aziz, Diego Marcheggiani,\r\nKhalil Sima'an.</em></p></li>\r\n<li><p><strong>Semi-supervised User Geolocation via Graph Convolutional\r\nNetworks.</strong> ACL 2018. <a href=\"https://arxiv.org/pdf/1804.08049.pdf\">paper</a></p>\r\n<p><em>Afshin Rahimi, Trevor Cohn, Timothy Baldwin.</em></p></li>\r\n<li><p><strong>Modeling Semantics with Gated Graph Neural Networks for\r\nKnowledge Base Question Answering.</strong> COLING 2018. <a href=\"https://arxiv.org/pdf/1808.04126.pdf\">paper</a></p>\r\n<p><em>Daniil Sorokin, Iryna Gurevych.</em></p></li>\r\n<li><p><strong>Graph Convolutional Networks for Text\r\nClassification.</strong> AAAI 2019. <a href=\"https://arxiv.org/pdf/1809.05679.pdf\">paper</a></p>\r\n<p><em>Liang Yao, Chengsheng Mao, Yuan Luo.</em></p></li>\r\n</ol>\r\n<details open style=\"box-sizing: border-box; display: block; margin-top: 0px; margin-bottom: 16px;\">\r\n<summary style=\"box-sizing: border-box; display: list-item; cursor: pointer;\">\r\nmore\r\n</summary>\r\n<ol start=\"21\" dir=\"auto\" style=\"box-sizing: border-box; padding-left: 2em; margin-top: 0px; margin-bottom: 16px;\">\r\n<li style=\"box-sizing: border-box;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">Constructing\r\nNarrative Event Evolutionary Graph for Script Event\r\nPrediction.</strong><span> </span>IJCAI\r\n2018.<span> </span><a href=\"https://arxiv.org/pdf/1805.05081.pdf\" rel=\"nofollow\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Zhongyang Li, Xiao Ding, Ting\r\nLiu.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">Incorporating\r\nSyntactic and Semantic Information in Word Embeddings using Graph\r\nConvolutional Networks.</strong><span> </span>ACL\r\n2019.<span> </span><a href=\"https://arxiv.org/pdf/1809.04283\" rel=\"nofollow\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Shikhar Vashishth, Manik Bhandari,\r\nPrateek Yadav, Piyush Rai, Chiranjib Bhattacharyya, Partha Talukdar</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">PaperRobot:\r\nIncremental Draft Generation of Scientific\r\nIdeas.</strong><span> </span>ACL\r\n2019.<span> </span><a href=\"https://arxiv.org/pdf/1905.07870\" rel=\"nofollow\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Qingyun Wang, Lifu Huang, Zhiying\r\nJiang, Kevin Knight, Heng Ji, Mohit Bansal, Yi Luan.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">Inter-sentence\r\nRelation Extraction with Document-level Graph Convolutional Neural\r\nNetwork.</strong><span> </span>ACL\r\n2019.<span> </span><a href=\"https://arxiv.org/pdf/1906.04684\" rel=\"nofollow\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Sunil Kumar Sahu, Fenia\r\nChristopoulou, Makoto Miwa, Sophia Ananiadou.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">Textbook\r\nQuestion Answering with Multi-modal Context Graph Understanding and\r\nSelf-supervised Open-set Comprehension.</strong><span> </span>ACL\r\n2019.<span> </span><a href=\"https://arxiv.org/pdf/1811.00232\" rel=\"nofollow\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Daesik Kim, Seonhoon Kim, Nojun\r\nKwak.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">Multi-hop\r\nReading Comprehension across Multiple Documents by Reasoning over\r\nHeterogeneous Graphs.</strong><span> </span>ACL\r\n2019.<span> </span><a href=\"https://arxiv.org/pdf/1905.07374\" rel=\"nofollow\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Ming Tu, Guangtao Wang, Jing Huang,\r\nYun Tang, Xiaodong He, Bowen Zhou.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">Dynamically\r\nFused Graph Network for Multi-hop Reasoning.</strong><span> </span>ACL\r\n2019.<span> </span><a href=\"https://arxiv.org/pdf/1905.06933\" rel=\"nofollow\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Yunxuan Xiao, Yanru Qu, Lin Qiu, Hao\r\nZhou, Lei Li, Weinan Zhang, Yong Yu.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">Cognitive\r\nGraph for Multi-Hop Reading Comprehension at\r\nScale.</strong><span> </span>ACL\r\n2019.<span> </span><a href=\"https://arxiv.org/pdf/1905.05460\" rel=\"nofollow\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Ming Ding, Chang Zhou, Qibin Chen,\r\nHongxia Yang, Jie Tang.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">Joint Type\r\nInference on Entities and Relations via Graph Convolutional\r\nNetworks.</strong><span> </span>ACL\r\n2019.<span> </span><a href=\"http://www.czsun.site/publications/joint_entrel_gcn.pdf\" rel=\"nofollow\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Changzhi Sun, Yeyun Gong, Yuanbin\r\nWu, Ming Gong, Daxing Jiang, Man Lan, Shiliang Sun1, Nan Duan.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">Attention\r\nGuided Graph Convolutional Networks for Relation\r\nExtraction.</strong><span> </span>ACL\r\n2019.<span> </span><a href=\"http://www.statnlp.org/wp-content/uploads/2019/06/Attention_Guided_Graph_Convolutional_Networks_for_Relation_Extraction.pdf\" rel=\"nofollow\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Zhijiang Guo, Yan Zhang, Wei\r\nLu.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">GraphRel:\r\nModeling Text as Relational Graphs for Joint Entity and Relation\r\nExtraction.</strong><span> </span>ACL\r\n2019.<span> </span><a href=\"https://tsujuifu.github.io/pubs/acl19_graph-rel.pdf\" rel=\"nofollow\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Tsu-Jui Fu, Peng-Hsuan Li, Wei-Yun\r\nMa.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">Graph Neural\r\nNetworks with Generated Parameters for Relation\r\nExtraction.</strong><span> </span>ACL\r\n2019.<span> </span><a href=\"https://arxiv.org/pdf/1902.00756\" rel=\"nofollow\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Hao Zhu, Yankai Lin, Zhiyuan Liu,\r\nJie Fu, Tat-seng Chua, Maosong Sun.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">Generating\r\nLogical Forms from Graph Representations of Text and\r\nEntities.</strong><span> </span>ACL\r\n2019.<span> </span><a href=\"https://arxiv.org/pdf/1905.08407\" rel=\"nofollow\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Peter Shaw, Philip Massey, Angelica\r\nChen, Francesco Piccinno, Yasemin Altun.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">Matching\r\nArticle Pairs with Graphical Decomposition and\r\nConvolutions.</strong><span> </span>ACL\r\n2019.<span> </span><a href=\"https://arxiv.org/pdf/1802.07459\" rel=\"nofollow\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Bang Liu, Di Niu, Haojie Wei,\r\nJinghong Lin, Yancheng He, Kunfeng Lai, Yu Xu.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">Representing\r\nSchema Structure with Graph Neural Networks for Text-to-SQL\r\nParsing.</strong><span> </span>ACL\r\n2019.<span> </span><a href=\"https://arxiv.org/pdf/1905.06241\" rel=\"nofollow\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Ben Bogin, Matt Gardner, Jonathan\r\nBerant.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">Coherent\r\nComment Generation for Chinese Articles with a Graph-to-Sequence\r\nModel.</strong><span> </span>ACL\r\n2019.<span> </span><a href=\"https://arxiv.org/pdf/1906.01231\" rel=\"nofollow\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Wei Li, Jingjing Xu, Yancheng He,\r\nShengli Yan, Yunfang Wu, Xu sun.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">GEAR:\r\nGraph-based Evidence Aggregating and Reasoning for Fact\r\nVerification.</strong><span> </span>ACL\r\n2019.<span> </span><a href=\"https://www.aclweb.org/anthology/P19-1085\" rel=\"nofollow\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Jie Zhou, Xu Han, Cheng Yang,\r\nZhiyuan Liu, Lifeng Wang, Changcheng Li, Maosong Sun.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">Look Again at\r\nthe Syntax: Relational Graph Convolutional Network for Gendered\r\nAmbiguous Pronoun Resolution.</strong><span> </span>ACL\r\n2019.<span> </span><a href=\"https://arxiv.org/pdf/1905.08868.pdf\" rel=\"nofollow\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Yinchuan Xu, Junlin Yang.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">Structured\r\nNeural Summarization.</strong><span> </span>ICLR\r\n2019.<span> </span><a href=\"https://openreview.net/pdf?id=H1ersoRqtm\" rel=\"nofollow\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Patrick Fernandes, Miltiadis\r\nAllamanis, Marc Brockschmidt.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">Long-tail\r\nRelation Extraction via Knowledge Graph Embeddings and Graph Convolution\r\nNetworks.</strong><span> </span>NAACL\r\n2019.<span> </span><a href=\"https://arxiv.org/pdf/1903.01306.pdf\" rel=\"nofollow\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Ningyu Zhang, Shumin Deng, Zhanlin\r\nSun, Guanying Wang, Xi Chen, Wei Zhang, Huajun Chen.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">Text\r\nGeneration from Knowledge Graphs with Graph\r\nTransformers.</strong><span> </span>NAACL\r\n2019.<span> </span><a href=\"https://arxiv.org/pdf/1904.02342.pdf\" rel=\"nofollow\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Rik Koncel-Kedziorski, Dhanush\r\nBekal, Yi Luan, Mirella Lapata, Hannaneh Hajishirzi.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">Question\r\nAnswering by Reasoning Across Documents with Graph Convolutional\r\nNetworks.</strong><span> </span>NAACL\r\n2019.<span> </span><a href=\"https://arxiv.org/pdf/1808.09920.pdf\" rel=\"nofollow\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Nicola De Cao, Wilker Aziz, Ivan\r\nTitov.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">BAG:\r\nBi-directional Attention Entity Graph Convolutional Network for\r\nMulti-hop Reasoning Question Answering.</strong><span> </span>NAACL\r\n2019.<span> </span><a href=\"https://arxiv.org/pdf/1904.04969.pdf\" rel=\"nofollow\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Yu Cao, Meng Fang, Dacheng Tao.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">GraphIE: A\r\nGraph-Based Framework for Information\r\nExtraction.</strong><span> </span>NAACL\r\n2019.<span> </span><a href=\"https://arxiv.org/pdf/1810.13083.pdf\" rel=\"nofollow\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Yujie Qian, Enrico Santus, Zhijing\r\nJin, Jiang Guo, Regina Barzilay.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">Graph\r\nConvolution for Multimodal Information Extraction from Visually Rich\r\nDocuments.</strong><span> </span>NAACL\r\n2019.<span> </span><a href=\"https://arxiv.org/pdf/1903.11279.pdf\" rel=\"nofollow\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Xiaojing Liu, Feiyu Gao, Qiong\r\nZhang, Huasha Zhao.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">Structural\r\nNeural Encoders for AMR-to-text Generation.</strong><span> </span>NAACL\r\n2019.<span> </span><a href=\"https://arxiv.org/pdf/1903.11410.pdf\" rel=\"nofollow\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Marco Damonte, Shay B. Cohen.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">Abusive\r\nLanguage Detection with Graph Convolutional\r\nNetworks.</strong><span> </span>NAACL\r\n2019.<span> </span><a href=\"https://arxiv.org/pdf/1904.04073.pdf\" rel=\"nofollow\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Pushkar Mishra, Marco Del Tredici,\r\nHelen Yannakoudakis, Ekaterina Shutova.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">Learning Graph\r\nPooling and Hybrid Convolutional Operations for Text\r\nRepresentations.</strong><span> </span>WWW\r\n2019.<span> </span><a href=\"https://arxiv.org/pdf/1901.06965.pdf\" rel=\"nofollow\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Hongyang Gao, Yongjun Chen, Shuiwang\r\nJi.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">Graph­‐based\r\nTransformer with Cross-candidate Verification for Semantic\r\nParsing.</strong><span> </span>AAAI\r\n2020.<span> </span><a href=\"https://github.com/thunlp/GNNPapers/blob/master\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Bo Shao, Yeyun Gong, Weizhen Qi,\r\nGuihong Cao, Jianshu Ji, Xiaola Lin.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">Efficient\r\nMulti-Person Pose Estimation with Provable\r\nGuarantees.</strong><span> </span>AAAI\r\n2020.<span> </span><a href=\"https://arxiv.org/abs/1711.07794\" rel=\"nofollow\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Shaofei Wang, Konrad Paul Kording,\r\nJulian Yarkony.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">Graph\r\nTransformer for Graph-to-Sequence Learning.</strong><span> </span>AAAI\r\n2020.<span> </span><a href=\"https://arxiv.org/abs/1911.07470\" rel=\"nofollow\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Deng Cai, Wai Lam.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">Multi-­‐label\r\nPatent Categorization with Non-­‐local Attention-­‐based Graph\r\nConvolutional Network.</strong><span> </span>AAAI\r\n2020.<span> </span><a href=\"https://github.com/thunlp/GNNPapers/blob/master\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Pingjie Tang, Meng Jiang, Bryan\r\n(Ning) Xia, Jed Pitera, Jeff Welser, Nitesh Chawla.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">Multi-task\r\nLearning for Metaphor Detection with Graph Convolutional Neural Networks\r\nand Word Sense Disambiguation.</strong><span> </span>AAAI\r\n2020.<span> </span><a href=\"https://github.com/thunlp/GNNPapers/blob/master\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Duong Minh Le, My Thai and Thien Huu\r\nNguyen.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">Schema-Guided\r\nMulti-Domain Dialogue State Tracking with Graph Attention Neural\r\nNetworks.</strong><span> </span>AAAI\r\n2020.<span> </span><a href=\"https://github.com/thunlp/GNNPapers/blob/master\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Lu Chen, Boer Lv, Chi Wang, Su Zhu,\r\nBowen Tan, Kai Yu.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">GraphER:\r\nToken-Centric Entity Resolution with Graph Convolutional Neural\r\nNetworks.</strong><span> </span>AAAI\r\n2020.<span> </span><a href=\"https://github.com/thunlp/GNNPapers/blob/master\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Bing Li, Wei Wang, Yifang Sun,\r\nLinhan Zhang, Muhammad Asif Ali, Yi Wang.</em>\r\n</p>\r\n</li>\r\n<li style=\"box-sizing: border-box; margin-top: 0.25em;\">\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<strong style=\"box-sizing: border-box; font-weight: 600;\">CFGNN:Cross\r\nFlow Graph Neural Networks for Question Answering on Complex\r\nTables.</strong><span> </span>AAAI\r\n2020.<span> </span><a href=\"https://github.com/thunlp/GNNPapers/blob/master\" style=\"box-sizing: border-box; background-color: transparent; color: var(--color-accent-fg); text-decoration: none;\">paper</a>\r\n</p>\r\n<p dir=\"auto\" style=\"box-sizing: border-box; margin-top: 16px; margin-bottom: 16px;\">\r\n<em style=\"box-sizing: border-box;\">Xuanyu Zhang.</em>\r\n</p>\r\n</li>\r\n</ol>\r\n</details>\r\n<h1 id=\"graph-neural-networks-for-natural-language-processing-a-survey\">Graph\r\nNeural Networks for Natural Language Processing: A Survey</h1>\r\n<h2 id=\"introduction\">Introduction</h2>\r\n<ul>\r\n<li><p>There is a rich variety of NLP problems that can be best\r\nexpressed with a graph structure.</p>\r\n<ul>\r\n<li>the <strong>sentence structure information</strong> in text\r\nsequence(i.e. syntactic parsing trees like dependency and constituency\r\nparsing trees) can be exploited to augment original sequence data by\r\nincorporating the task-specific knowledge.</li>\r\n<li>the <strong>semantic information</strong> in sequence data (i.e.\r\nsemantic parsing graphs like Abstract Meaning Representation graphs and\r\nInformation Extraction graphs) can be leveraged to enhance original\r\nsequence data as well.</li>\r\n</ul></li>\r\n<li><p>Therefore, these graph-structured data can encode complicated\r\npairwise relationships between entity tokens for learning more\r\ninformative representations.</p></li>\r\n<li><p>Deep learning techniques that were disruptive for Euclidean data\r\n(e.g, images) or sequence data (e.g, text) are not immediately\r\napplicable to graph-structured data, due to the complexity of graph data\r\nsuch as irregular structure and varying size of node neighbors.</p></li>\r\n<li><p>As a result, this gap has driven a tide in research for deep\r\nlearning on graphs, especially in development of graph neural networks\r\n(GNNs)</p>\r\n<ul>\r\n<li>classification tasks</li>\r\n<li>generation tasks</li>\r\n</ul></li>\r\n<li><p>Despite the successes these existing research has achieved, deep\r\nlearning on graphs for NLP still encounters many challenges, namely,</p>\r\n<ul>\r\n<li><p>Automatically transforming original text sequence data into\r\nhighly graph-structured data.</p>\r\n<blockquote>\r\n<p>Automatic graph construction from the text sequence to utilize the\r\nunderlying structural information is a crucial step in utilizing graph\r\nneural networks for NLP problems.</p>\r\n</blockquote></li>\r\n<li><p>Properly determining graph representation learning\r\ntechniques.</p>\r\n<blockquote>\r\n<p>It is critical to come up with specially-designed GNNs to learn the\r\nunique characteristics of different graph-structures data such as\r\nundirected, directed, multi-relational and heterogeneous graphs.</p>\r\n</blockquote></li>\r\n<li><p>Effectively modeling complex data.</p>\r\n<blockquote>\r\n<p>Such challenge is important since many NLP tasks involve learning the\r\nmapping between the graph-based inputs and other highly structured\r\noutput data such as sequences, trees, as well as graph data with\r\nmulti-types in both nodes and edges.</p>\r\n</blockquote></li>\r\n</ul></li>\r\n<li><p>The taxonomy, which systematically organizes GNNs for NLP along\r\nthree axes: graph construction, graph representation learning,\r\nencoder-decoder models, and the applications.<img src=\"/2023/01/16/GNN4NLP/image-20221009143334468-167384297065818.png\" alt=\"image-20221009143334468\"></p></li>\r\n</ul>\r\n<h2 id=\"graph-based-algorithms-for-natural-language-processing\">Graph\r\nBased Algorithms for Natural Language Processing</h2>\r\n<h4 id=\"tips\">Tips</h4>\r\n<h6 id=\"省流\">省流</h6>\r\n<blockquote>\r\n<p>本节我们从图的视角审视NLP的问题，并且简单地介绍了许多相对传统的基于图解决NLP问题的方法</p>\r\n</blockquote>\r\n<h3 id=\"natural-language-processing-a-graph-perspective\">Natural\r\nLanguage Processing: A Graph Perspective</h3>\r\n<h4 id=\"three-ways-to-representing-natural-language\">Three ways to\r\nrepresenting natural language</h4>\r\n<ul>\r\n<li><p>a bag of tokens</p>\r\n<blockquote>\r\n<p>This view of natural language completely ignores the specific\r\n<strong>positions</strong> of tokens appearing in text, and only\r\nconsiders <strong>how many times a unique token appears in\r\ntext</strong>. If one randomly shuffles a given text, the meaning of the\r\ntext does not change at all from this perspective.</p>\r\n</blockquote>\r\n<ul>\r\n<li><p>topic modeling</p>\r\n<blockquote>\r\n<p>It aims to model each input text as a mixture of topics where each\r\ntopic can be further modeled as a mixture of words.</p>\r\n</blockquote></li>\r\n</ul></li>\r\n<li><p>a sequence of tokens</p>\r\n<blockquote>\r\n<p>This is how human beings normally speak and write natural\r\nlanguage.</p>\r\n<p>this view of natural language is able to capture richer information\r\nof text, e.g., which two tokens are <strong>consecutive</strong> and how\r\nmany times a word pair <strong>co-occurs</strong> in local context.</p>\r\n</blockquote>\r\n<ul>\r\n<li>linear-chain CRF</li>\r\n<li>word2vec</li>\r\n</ul></li>\r\n<li><p>a graph</p>\r\n<blockquote>\r\n<p>While it is probably most apparent to regard text as sequential data,\r\nin the NLP community, there is a long history of representing text as\r\nvarious kinds of graphs.</p>\r\n<p>Common graph representations of text or world knowledge include\r\ndependency graphs, constituency graphs, AMR graphs, IE graphs, lexical\r\nnetworks, and knowledge graphs.</p>\r\n<p>Besides, one can also construct a text graph containing\r\n<strong>multiple hierarchies of elements</strong> such as document,\r\npassage, sentence and word.</p>\r\n<p>In comparison with the above two perspectives, this view of natural\r\nlanguage is able to <strong>capture richer relationships</strong> among\r\ntext elements.</p>\r\n</blockquote></li>\r\n</ul>\r\n<h3 id=\"graph-based-methods-for-natural-language-processing\">Graph Based\r\nMethods for Natural Language Processing</h3>\r\n<h6 id=\"省流-1\">省流</h6>\r\n<blockquote>\r\n<p>介绍各种已经成功应用于NLP的经典的基于图的算法</p>\r\n<ul>\r\n<li>首先介绍各种算法</li>\r\n<li>然后讨论它们和GNNs的联系</li>\r\n</ul>\r\n</blockquote>\r\n<ul>\r\n<li><p>Random Walk Algorithms</p>\r\n<h5 id=\"解释\">解释</h5>\r\n<blockquote>\r\n<ul>\r\n<li>是一组基于图的算法，可以在图中产生随机的路径</li>\r\n<li>从任意节点出发，根据特定的转移概率重复地随机选择邻居节点并转移</li>\r\n<li>在随机游走中所有经过的节点就构成了一条随机路径</li>\r\n<li>随机游走收敛后，可以得到一个图中所有节点的平稳分布\r\n<ul>\r\n<li>可以通过概率分数排序来选择图中结构重要性最高的节点，</li>\r\n<li>可以通过计算两个随机游走分布之间的相似性衡量两个图的相关性</li>\r\n</ul></li>\r\n</ul>\r\n</blockquote>\r\n<ul>\r\n<li><p>TextRank: Bringing Order into Texts</p>\r\n<h4 id=\"例子详解\">例子详解</h4>\r\n<blockquote>\r\n<p><strong>基本思想</strong>：利用图形递归绘制全局信息，从而决定顶点的重要程度</p>\r\n<ul>\r\n<li><p>text2graph</p>\r\n<p>为了使基于图的排序算法可以应用于自然语言文本，需要将文本表示成图，并将具有语义关系的单词或其他文本实体用边相连</p></li>\r\n<li><p>pipeline</p>\r\n<ul>\r\n<li>确定最佳定义手头任务的<strong>文本单位</strong>，并将其作为顶点添加到图形中</li>\r\n<li>识别连接这些文本单元的<strong>关系</strong>，并使用这些关系在图中的顶点之间绘制边。\r\n边可以是有向的或无向的，加权的或未加权的</li>\r\n<li>迭代基于图的排序算法，直到<strong>收敛</strong></li>\r\n<li>根据最终得分对顶点进行<strong>排序</strong>。\r\n使用附加到每个顶点的值进行排名 / 选择决策</li>\r\n</ul></li>\r\n<li><p>核心算法</p>\r\n<ul>\r\n<li>通过随机游走来生成随机路径，并按照以下公式更新节点，直到收敛到稳定分布，然后排序即可\r\n<span class=\"math display\">\\[\r\nW S\\left(V_i\\right)=(1-d)+d * \\sum_{V_j \\in\r\n\\operatorname{In}\\left(V_i\\right)} \\frac{w_{j i}}{\\sum_{V_k \\in O u\r\nt\\left(V_j\\right)}{w_{j k}}} W S\\left(V_j\\right)\r\n\\]</span></li>\r\n</ul></li>\r\n<li><p>关键词抽取</p>\r\n<ul>\r\n<li>将通过一定规则提取的一系列<strong>词</strong>加入节点，词之间的关系（任何关系都可以）作为边。</li>\r\n<li>在本任务中，选择<strong>共现关系</strong>作为关系的标准。</li>\r\n<li>具体而言，两个节点如果出现在一个<strong>窗口</strong>内，那么这两个词之间有一条边。窗口从\r\n2 到 N（最大值）</li>\r\n<li>在构建图形（无向未加权图）之后，将与每个顶点相关联的分数设置为初始值\r\n1，并且根据<strong>排序算法</strong>在图上运行多次迭代，直到它<strong>收敛</strong>\r\n- 通常为 20- 30 次迭代，阈值为 0.0001</li>\r\n<li>获得了图中每个顶点的<strong>最终分数</strong>，顶点按其分数的相反顺序进行排序，并保留排名中的前\r\n<strong>top T</strong> 顶点进行后期处理</li>\r\n<li>在后期处理期间，所有词汇单位被选中作为 TextRank\r\n算法的潜在关键词在文本中标记，并显示相邻关键字的序列被折叠成多字关键字</li>\r\n<li>效果：<img src=\"/2023/01/16/GNN4NLP/v2-1e430ba69797cf8242d2885f99b350bd_b-167384301715396.jpg\" alt=\"img\"></li>\r\n</ul></li>\r\n<li><p>句子提取</p>\r\n<ul>\r\n<li><p>节点是text中的每个句子，需要过滤(通过词性和长度来过滤)</p></li>\r\n<li><p>边的权重是句子之间的Similarity(使用单词重叠度来衡量) <span class=\"math display\">\\[\r\n\\operatorname{Similarity}\\left(S_i, S_j\\right)=\\frac{\\left|\\left\\{w_k\r\n\\mid w_k \\in S_i \\&amp; w_k \\in S_j\\right\\}\\right|}{\\log\r\n\\left(\\left|S_i\\right|\\right)+\\log \\left(\\left|S_j\\right|\\right)}\r\n\\]</span></p></li>\r\n<li><p>效果：<img src=\"/2023/01/16/GNN4NLP/image-20221009160825337-167384297065819.png\" alt=\"image-20221009160825337\"></p></li>\r\n</ul></li>\r\n</ul>\r\n</blockquote></li>\r\n</ul></li>\r\n<li><p>Graph Clustering Algorithms</p>\r\n<ul>\r\n<li><p>Spectral clustering(谱聚类)</p>\r\n<h5 id=\"相关知识定义\">相关知识定义</h5>\r\n<blockquote>\r\n<p><strong>无向权重图</strong></p>\r\n<p>图<span class=\"math inline\">\\(G\\)</span>通常表示为<span class=\"math inline\">\\(G(V,E)\\)</span>。其中<span class=\"math inline\">\\(V\\)</span>即为我们数据集里面所有的点<span class=\"math inline\">\\((v_1,v_2,...,v_n)\\)</span>。</p>\r\n<p>对<span class=\"math inline\">\\(V\\)</span>中的任意两个点<span class=\"math inline\">\\(v_i\\)</span>和<span class=\"math inline\">\\(v_j\\)</span>，可以有边连接，也可以没有。我们定义权重<span class=\"math inline\">\\(w_{ij}\\)</span>为点<span class=\"math inline\">\\(v_i,v_j\\)</span>之间的权重。由于我们是无向图，所以<span class=\"math inline\">\\(w_{ij} = w_{ji}\\)</span>。其中，<span class=\"math inline\">\\(w_{ij}&gt;0\\)</span>等价于两个点之间有边。<span class=\"math inline\">\\(w_{ij}=0\\)</span>代表没有边。</p>\r\n<p>对图中任意一个点<span class=\"math inline\">\\(v_i\\)</span>,它的度<span class=\"math inline\">\\(d_i\\)</span>定义为和它连接的所有边的权重之和 <span class=\"math display\">\\[\r\nd_i = \\sum_{j=1}^{n}w_{ij}\r\n\\]</span> 利用每个点度的定义，我们得到一个nxn的矩阵<span class=\"math inline\">\\(D\\)</span>,它是一个对角矩阵，只有主对角线有值，对应第i行的第i个点的度数，定义如下：\r\n<span class=\"math display\">\\[\r\n\\mathbf{D}=\\left(\\begin{array}{ccc}\r\nd_1 &amp; \\ldots &amp; \\ldots \\\\\r\n\\ldots &amp; d_2 &amp; \\ldots \\\\\r\n\\vdots &amp; \\vdots &amp; \\ddots \\\\\r\n\\ldots &amp; \\ldots &amp; d_n\r\n\\end{array}\\right)\r\n\\]</span> 利用所有店的权重值，我们可以得到图的邻接矩阵<span class=\"math inline\">\\(W\\)</span>,它也是一个nxn矩阵，第i行的第j个值对应我们的权重<span class=\"math inline\">\\(w_{ij}\\)</span></p>\r\n<p>此外，对点集<span class=\"math inline\">\\(V\\)</span>的一个子集<span class=\"math inline\">\\(A \\subset V\\)</span>,我们定义： <span class=\"math display\">\\[\r\n|A|:=子集A中点的个数\r\n\\newline\r\nvol(A):=\\sum_{i \\in A}d_i\r\n\\]</span> <strong>相似矩阵</strong></p>\r\n<p>获取邻接矩阵的基本思想：距离远的两个点边权值较低，而距离近的两个点之间边权值较高</p>\r\n<p>构建方法：通过样本点距离度量的相似矩阵S来获得邻接矩阵W</p>\r\n<p>1、<span class=\"math inline\">\\(\\epsilon\\)</span>-临近法</p>\r\n<p>设置了一个阈值<span class=\"math inline\">\\(\\epsilon\\)</span>,使用欧氏距离<span class=\"math inline\">\\(s_ij\\)</span>度量任意两点<span class=\"math inline\">\\(x_i\\)</span>和<span class=\"math inline\">\\(x_j\\)</span>之间的距离。即相似矩阵的<span class=\"math inline\">\\(s_{ij} =\r\n\\left\\|x_i-x_j\\right\\|_2^2\\)</span>,然后定义<span class=\"math inline\">\\(W\\)</span>元素如下： <span class=\"math display\">\\[\r\nw_{i j}= \\begin{cases}0 &amp; s_{i j}&gt;\\epsilon \\\\ \\epsilon &amp; s_{i\r\nj} \\leq \\epsilon\\end{cases}\r\n\\]</span> 距离度量不够精准，一般不使用。</p>\r\n<p>2、K临近法</p>\r\n<p>KNN(K-Nearest\r\nNeighbor)算法:计算当前点和其他点的距离，并找到最近的K个点。这K个点中哪个种类数目最多，则将当前点判定为该种类。</p>\r\n<p>如果使用KNN的思想，我们自然地得到只有样本距离最近的K个点之间的<span class=\"math inline\">\\(w_{ij}&gt;0\\)</span>。但是这样得到的<span class=\"math inline\">\\(W\\)</span>是不对称的，为此，我们修改为如下两种形式：\r\n<span class=\"math display\">\\[\r\nw_{ij}=w_{ji}= \\begin{cases} 0&amp; {x_i \\notin KNN(x_j) \\;and \\;x_j\r\n\\notin KNN(x_i)}\\\\ exp(-\\frac{||x_i-x_j||_2^2}{2\\sigma^2})&amp; {x_i \\in\r\nKNN(x_j)\\; or\\; x_j \\in KNN(x_i}) \\end{cases}\r\n\\newline\r\nor\r\n\\newline\r\nw_{ij}=w_{ji}= \\begin{cases} 0&amp; {x_i \\notin KNN(x_j) \\;or\\;x_j\r\n\\notin KNN(x_i)}\\\\ exp(-\\frac{||x_i-x_j||_2^2}{2\\sigma^2})&amp; {x_i \\in\r\nKNN(x_j)\\; and \\; x_j \\in KNN(x_i}) \\end{cases}\r\n\\]</span> 3、全连接法（最普遍）</p>\r\n<p>所有的点之间的权重都大于0。可以选择不同的核函数来定义边权重，比如多项式核函数，高斯核函数和Sigmoid核函数。最常用的是高斯核函数RBF，此时相似矩阵和邻接矩阵相同：\r\n<span class=\"math display\">\\[\r\nw_{ij}=s_{ij}=exp(-\\frac{||x_i-x_j||_2^2}{2\\sigma^2})\r\n\\]</span> <strong>拉普拉斯矩阵</strong> <span class=\"math display\">\\[\r\nL = D-W\r\n\\]</span> 拉普拉斯矩阵=度矩阵 - 邻接矩阵</p>\r\n<p>好的性质：</p>\r\n<ul>\r\n<li><p>对称矩阵（对称矩阵只差是对称矩阵）</p></li>\r\n<li><p>由于拉普拉斯矩阵是对称矩阵，所以它的所有特征值都是实数</p></li>\r\n<li><p>对任意向量<span class=\"math inline\">\\(f\\)</span>,我们有 <span class=\"math display\">\\[\r\nf^TLf = \\frac{1}{2}\\sum\\limits_{i,j=1}^{n}w_{ij}(f_i-f_j)^2\r\n\\]</span> 这个利用拉普拉斯矩阵的定义很容易得到如下： <span class=\"math display\">\\[\r\n\\begin{align*}\\label{12}\r\n&amp; f^TLf \\\\\r\n&amp; = f^TDf - f^TWf \\\\\r\n&amp; = \\sum\\limits_{i=1}^{n}d_if_i^2 -\r\n\\sum\\limits_{i,j=1}^{n}w_{ij}f_if_j \\\\\r\n&amp; =\\frac{1}{2}( \\sum\\limits_{i=1}^{n}d_if_i^2 - 2\r\n\\sum\\limits_{i,j=1}^{n}w_{ij}f_if_j + \\sum\\limits_{j=1}^{n}d_jf_j^2) \\\\\r\n&amp; = \\frac{1}{2}\\sum\\limits_{i,j=1}^{n}w_{ij}(f_i-f_j)^2 \\\\\r\n\\end{align*}\r\n\\]</span></p></li>\r\n<li><p>拉普拉斯矩阵是半正定的，且对应的n个实数特征值都大于0，即<span class=\"math inline\">\\(0 = \\lambda_1 \\leq \\lambda_2 \\leq···\\leq\r\n\\lambda_n\\)</span>，且最小的特征值是0，这个性质由性质3很容易得出。</p></li>\r\n</ul>\r\n<p>关于拉普拉斯算子与图中的拉普拉斯矩阵：</p>\r\n<ul>\r\n<li><p>拉普拉斯算子是自变量的非混合二阶偏导数之和 <span class=\"math display\">\\[\r\n\\Delta f = \\sum_{i=1}^{n}\\frac{\\partial ^2f}{\\partial   x_i^2}\r\n\\]</span> 我们进行离散化，并且简化为增量为1，则有： <span class=\"math display\">\\[\r\n\\Delta f = \\sum_{(k,l) \\in N(i,j)}(f(x_k,y_l)  - f(x_i,y_j))\r\n\\]</span> 其中<span class=\"math inline\">\\(N(i,j)\\)</span>是<span class=\"math inline\">\\((x_i,y_j)\\)</span>的邻居节点的集合</p>\r\n<figure>\r\n<img src=\"/2023/01/16/GNN4NLP/v2-4d7bf05128e4ba55df16a9fd61913a8e_b-167384304011199.jpg\" alt=\"img\">\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure></li>\r\n<li><p>推广到图中 <span class=\"math display\">\\[\r\n\\Delta f_i = \\sum_{j \\in N_i}w_{ij}(f_i-f_j)\r\n\\]</span> <img src=\"/2023/01/16/GNN4NLP/v2-1bfc2035f4d2a95d0af6ea0288cd8680_b-1673843042737102.jpg\" alt=\"img\"></p>\r\n<p>如果j不是i的邻居，则<span class=\"math inline\">\\(w_{ij}=0\\)</span>。因此，上面的式子可以写成：\r\n<span class=\"math display\">\\[\r\n\\Delta f_i = \\sum_{j \\in V}w_{ij}(f_i-f_j) = \\sum_{j\\in\r\nV}w_{ij}f_i-\\sum_{j\\in V}w_{ij}f_j = d_if_i -  \\textbf{w}_i\\textbf{f}\r\n\\]</span> 因此，我们得到 <span class=\"math display\">\\[\r\n\\Delta f = (\\textbf{D}-\\textbf{W})\\textbf{f}\r\n\\]</span> 由此我们可以得到拉普拉斯矩阵的定义及以上几个性质。</p></li>\r\n</ul>\r\n<p><strong>无向图切图</strong></p>\r\n<p>对无向图<span class=\"math inline\">\\(G\\)</span>的切图,每个子图的集合为:<span class=\"math inline\">\\(A_1,A_2,...,A_k\\)</span>,它们满足<span class=\"math inline\">\\(A_i \\cap A_j = \\emptyset\\)</span> , 且有<span class=\"math inline\">\\(A_1 \\cup A_2 \\cup ... \\cup A_k = V\\)</span></p>\r\n<p>对于任意两个子图点的集合<span class=\"math inline\">\\(A,B \\subset V, A\r\n\\cap B = \\emptyset\\)</span> , 我们定义两个子图之间的切图权重为 <span class=\"math display\">\\[\r\nW(A, B) = \\sum\\limits_{i \\in A, j \\in B}w_{ij}\r\n\\]</span> 那么对k个子图点的集合：<span class=\"math inline\">\\(A_1,A_2,...,A_k\\)</span>,我们定义切图cut为： <span class=\"math display\">\\[\r\ncut(A_1,A_2,...A_k) = \\frac{1}{2}\\sum\\limits_{i=1}^{k}W(A_i,\r\n\\overline{A}_i )\r\n\\]</span> 其中<span class=\"math inline\">\\(\\overline{A}_i\\)</span>为<span class=\"math inline\">\\(A_i\\)</span>的补集，意为除<span class=\"math inline\">\\(A_i\\)</span>子集外其他V的子集的并集</p>\r\n<p>那么如何切图可以让子图内的点权重和高，子图间的权重和低呢？一个自然地想法是最小化<span class=\"math inline\">\\(cut(A_1,A_2,...,A_k)\\)</span>,但是可以发现，这种方案存在问题：<img src=\"/2023/01/16/GNN4NLP/1042406-20161227180625461-1385841797-1673843046978105.jpg\" alt=\"img\"></p>\r\n<p>这个最小化方案给出的最优解Smallest cut并不是全局的最优解Best\r\ncut。如何解决？——谱聚类之切图聚类</p>\r\n<p><strong>谱聚类之切图聚类</strong></p>\r\n<ul>\r\n<li><p>RatioCut切图</p>\r\n<p>为了避免上述问题发生，需要额外考虑最大化每个子图点的个数： <span class=\"math display\">\\[\r\nRatioCut(A_1,A_2,...A_k) = \\frac{1}{2}\\sum\\limits_{i=1}^{k}\\frac{W(A_i,\r\n\\overline{A}_i )}{|A_i|}\r\n\\]</span> 我们引入指示向量<span class=\"math inline\">\\(h_j \\in \\{h_1,\r\nh_2,..h_k\\}\\; j =1,2,...k\\)</span>,对任意一个向量<span class=\"math inline\">\\(h_j\\)</span>,它是一个n维向量(n是样本数)，其中\r\n<span class=\"math display\">\\[\r\nh_{ij}= \\begin{cases} 0&amp; { v_i \\notin A_j}\\\\\r\n\\frac{1}{\\sqrt{|A_j|}}&amp; { v_i \\in A_j} \\end{cases}\r\n\\]</span> 则有： <span class=\"math display\">\\[\r\n\\begin{align} h_i^TLh_i &amp; =\r\n\\frac{1}{2}\\sum\\limits_{m=1}\\sum\\limits_{n=1}w_{mn}(h_{im}-h_{in})^2\r\n\\\\&amp; =\\frac{1}{2}(\\sum\\limits_{m \\in A_i, n \\notin\r\nA_i}w_{mn}(\\frac{1}{\\sqrt{|A_i|}} - 0)^2 +  \\sum\\limits_{m \\notin A_i, n\r\n\\in A_i}w_{mn}(0 - \\frac{1}{\\sqrt{|A_i|}} )^2\\\\&amp; =\r\n\\frac{1}{2}(\\sum\\limits_{m \\in A_i, n \\notin A_i}w_{mn}\\frac{1}{|A_i|}\r\n+  \\sum\\limits_{m \\notin A_i, n \\in A_i}w_{mn}\\frac{1}{|A_i|}\\\\&amp; =\r\n\\frac{1}{2}(cut(A_i, \\overline{A}_i) \\frac{1}{|A_i|} +\r\ncut(\\overline{A}_i, A_i) \\frac{1}{|A_i|}) \\\\&amp; =  \\frac{cut(A_i,\r\n\\overline{A}_i)}{|A_i|} \\end{align}\r\n\\]</span> 上述第（1）式用了上面第四节的拉普拉斯矩阵的性质3.\r\n第二式用到了指示向量的定义。可以看出，对于某一个子图i，它的RatioCut对应于<span class=\"math inline\">\\(h_i^TLh_i\\)</span>​,那么我们的k个子图呢？对应的RatioCut函数表达式为：\r\n<span class=\"math display\">\\[\r\nRatioCut(A_1,A_2,...A_k) = \\sum\\limits_{i=1}^{k}h_i^TLh_i =\r\n\\sum\\limits_{i=1}^{k}(H^TLH)_{ii} = tr(H^TLH)\r\n\\]</span> 注意到<span class=\"math inline\">\\(H^TH =\r\nI\\)</span>,则我们的切图优化目标为： <span class=\"math display\">\\[\r\n\\underbrace{arg\\;min}_H\\; tr(H^TLH) \\;\\; s.t.\\;H^TH=I\r\n\\]</span> 注意到我们 H 矩阵里面的每一个指示向量都是 n\r\n维的，向量中每个变量的取值为 0 或者 <span class=\"math inline\">\\(\\frac{1}{\\sqrt{|A_j|}}\\)</span>，就有 <span class=\"math inline\">\\(2^n\\)</span>种取值，有 k 个子图的话就有 k\r\n个指示向量，共有 <span class=\"math inline\">\\(k2^n\\)</span>种\r\nH，因此找到满足上面优化目标的 H 是一个 NP\r\n难的问题。那么是不是就没有办法了呢？</p>\r\n<p>　　　　注意观察 <span class=\"math inline\">\\(tr(H^TLH)\\)</span>中每一个优化子目标 <span class=\"math inline\">\\(h_i^TLh_i\\)</span>, 其中 <span class=\"math inline\">\\(h\\)</span>是单位正交基， L 为对称矩阵，此时 <span class=\"math inline\">\\(h_i^TLh_i\\)</span>的最大值为 L\r\n的最大特征值，最小值是 L 的最小特征值。如果你对主成分分析 PCA\r\n很熟悉的话，这里很好理解。在 PCA\r\n中，我们的目标是找到协方差矩阵（对应此处的拉普拉斯矩阵\r\nL）的最大的特征值，而在我们的谱聚类中，我们的目标是找到目标的最小的特征值，得到对应的特征向量，此时对应二分切图效果最佳。也就是说，我们这里要用到维度规约的思想来近似去解决这个\r\nNP 难的问题。</p>\r\n<p>　　　　对于 <span class=\"math inline\">\\(h_i^TLh_i\\)</span>，我们的目标是找到最小的 L\r\n的特征值，而对于 <span class=\"math inline\">\\(tr(H^TLH) =\r\n\\sum\\limits_{i=1}^{k}h_i^TLh_i\\)</span>，则我们的目标就是找到 k\r\n个最小的特征值，一般来说，k 远远小于\r\nn，也就是说，此时我们进行了维度规约，将维度从 n 降到了\r\nk，从而近似可以解决这个 NP 难的问题。</p>\r\n<p>　　　　通过找到 L 的最小的 k 个特征值，可以得到对应的 k\r\n个特征向量，这 k 个特征向量组成一个 nxk 维度的矩阵，即为我们的\r\nH。一般需要对 H 矩阵按行做标准化，即</p>\r\n<p><span class=\"math display\">\\[h_{ij}^{*}=\r\n\\frac{h_{ij}}{(\\sum\\limits_{t=1}^kh_{it}^{2})^{1/2}}\\]</span></p>\r\n<p>　　　　由于我们在使用维度规约的时候损失了少量信息，导致得到的优化后的指示向量\r\nh 对应的 H 现在不能完全指示各样本的归属，因此一般在得到 nxk 维度的矩阵 H\r\n后还需要对每一行进行一次传统的聚类，比如使用 K-Means 聚类.</p>\r\n<ul>\r\n<li>6.2 Ncut 切图</li>\r\n</ul>\r\n<p>　　　　Ncut 切图和 RatioCut 切图很类似，但是把 Ratiocut 的分母 <span class=\"math inline\">\\(|Ai|\\)</span>换成 <span class=\"math inline\">\\(vol(A_i)\\)</span>.\r\n由于子图样本的个数多并不一定权重就大，我们切图时基于权重也更合我们的目标，因此一般来说\r\nNcut 切图优于 RatioCut 切图。</p>\r\n<p><span class=\"math display\">\\[NCut(A_1,A_2,...A_k) =\r\n\\frac{1}{2}\\sum\\limits_{i=1}^{k}\\frac{W(A_i,\r\n\\overline{A}_i )}{vol(A_i)}\\]</span></p>\r\n<p>　　　　，对应的，Ncut 切图对指示向量 <span class=\"math inline\">\\(h\\)</span>做了改进。注意到 RatioCut\r\n切图的指示向量使用的是 <span class=\"math inline\">\\(\\frac{1}{\\sqrt{|A_j|}}\\)</span>标示样本归属，而\r\nNcut 切图使用了子图权重 <span class=\"math inline\">\\(\\frac{1}{\\sqrt{vol(A_j)}}\\)</span>来标示指示向量\r\nh，定义如下:</p>\r\n<p><span class=\"math display\">\\[h_{ij}= \\begin{cases} 0&amp; { v_i\r\n\\notin A_j}\\\\ \\frac{1}{\\sqrt{vol(A_j)}}&amp; { v_i \\in A_j}\r\n\\end{cases}\\]</span></p>\r\n<p>　　　　那么我们对于 <span class=\"math inline\">\\(h_i^TLh_i\\)</span>,\r\n有：</p>\r\n<p><span class=\"math display\">\\[\\begin{align} h_i^TLh_i &amp;\r\n= \\frac{1}{2}\\sum\\limits_{m=1}\\sum\\limits_{n=1}w_{mn}(h_{im}-h_{in})^2\r\n\\\\&amp; =\\frac{1}{2}(\\sum\\limits_{m \\in A_i, n \\notin\r\nA_i}w_{mn}(\\frac{1}{\\sqrt{vol(A_i)}} - 0)^2 +  \\sum\\limits_{m \\notin\r\nA_i, n \\in A_i}w_{mn}(0 - \\frac{1}{\\sqrt{vol(A_i)}} )^2\\\\&amp; =\r\n\\frac{1}{2}(\\sum\\limits_{m \\in A_i, n \\notin\r\nA_i}w_{mn}\\frac{1}{vol(A_i)} +  \\sum\\limits_{m \\notin A_i, n \\in\r\nA_i}w_{mn}\\frac{1}{vol(A_i)}\\\\&amp; = \\frac{1}{2}(cut(A_i,\r\n\\overline{A}_i) \\frac{1}{vol(A_i)} + cut(\\overline{A}_i, A_i)\r\n\\frac{1}{vol(A_i)}) \\\\&amp; =  \\frac{cut(A_i, \\overline{A}_i)}{vol(A_i)}\r\n\\end{align}\\]</span></p>\r\n<p>　　　　推导方式和 RatioCut\r\n完全一致。也就是说，我们的优化目标仍然是</p>\r\n<p><span class=\"math display\">\\[NCut(A_1,A_2,...A_k) =\r\n\\sum\\limits_{i=1}^{k}h_i^TLh_i = \\sum\\limits_{i=1}^{k}(H^TLH)_{ii} =\r\ntr(H^TLH)\\]</span></p>\r\n<p>　　　　但是此时我们的 <span class=\"math inline\">\\(H^TH \\neq\r\nI\\)</span>, 而是 <span class=\"math inline\">\\(H^TDH =\r\nI\\)</span>。推导如下：</p>\r\n<p><span class=\"math display\">\\[h_i^TDh_i =\r\n\\sum\\limits_{j=1}^{n}h_{ij}^2d_j =\\frac{1}{vol(A_i)}\\sum\\limits_{j \\in\r\nA_i}d_j= \\frac{1}{vol(A_i)}vol(A_i) =1\\]</span></p>\r\n<p>　　　　也就是说，此时我们的优化目标最终为：</p>\r\n<p><span class=\"math display\">\\[\\underbrace{arg\\;min}_H\\; tr(H^TLH) \\;\\;\r\ns.t.\\;H^TDH=I\\]</span></p>\r\n<p>　　　　此时我们的 H 中的指示向量 <span class=\"math inline\">\\(h\\)</span>并不是标准正交基，所以在 RatioCut\r\n里面的降维思想不能直接用。怎么办呢？其实只需要将指示向量矩阵 H\r\n做一个小小的转化即可。</p>\r\n<p>　　　　我们令 <span class=\"math inline\">\\(H = D^{-1/2}F\\)</span>,\r\n则：<span class=\"math inline\">\\(H^TLH =\r\nF^TD^{-1/2}LD^{-1/2}F\\)</span>，<span class=\"math inline\">\\(H^TDH=F^TF =\r\nI\\)</span>, 也就是说优化目标变成了:</p>\r\n<p><span class=\"math display\">\\[\\underbrace{arg\\;min}_F\\;\r\ntr(F^TD^{-1/2}LD^{-1/2}F) \\;\\; s.t.\\;F^TF=I\\]</span></p>\r\n<p>　　　　可以发现这个式子和 RatioCut 基本一致，只是中间的 L 变成了\r\n<span class=\"math inline\">\\(D^{-1/2}LD^{-1/2}\\)</span>。这样我们就可以继续按照\r\nRatioCut 的思想，求出 <span class=\"math inline\">\\(D^{-1/2}LD^{-1/2}\\)</span>的最小的前 k\r\n个特征值，然后求出对应的特征向量，并标准化，得到最后的特征矩阵 <span class=\"math inline\">\\(F\\)</span>, 最后对 <span class=\"math inline\">\\(F\\)</span>进行一次传统的聚类（比如\r\nK-Means）即可。</p>\r\n<p>　　　　一般来说， <span class=\"math inline\">\\(D^{-1/2}LD^{-1/2}\\)</span>相当于对拉普拉斯矩阵\r\n<span class=\"math inline\">\\(L\\)</span>做了一次标准化，即 <span class=\"math inline\">\\(\\frac{L_{ij}}{\\sqrt{d_i*d_j}}\\)</span></p>\r\n<p><strong>谱聚类算法流程</strong></p>\r\n<p>最常用的相似矩阵的生成方式是基于高斯核距离的全连接方式，最常用的切图方式是\r\nNcut。而到最后常用的聚类方法为 K-Means。下面以 Ncut\r\n总结谱聚类算法流程。</p>\r\n<p>输入：样本集 D=<span class=\"math inline\">\\((x_1,x_2,...,x_n)\\)</span>，相似矩阵的生成方式,\r\n降维后的维度 <span class=\"math inline\">\\(k_1\\)</span>,\r\n聚类方法，聚类后的维度 <span class=\"math inline\">\\(k_2\\)</span></p>\r\n<p>输出： 簇划分 <span class=\"math inline\">\\(C(c_1,c_2,...c_{k_2})\\)</span>.</p>\r\n<ol type=\"1\">\r\n<li><p>根据输入的相似矩阵的生成方式构建样本的相似矩阵 S</p></li>\r\n<li><p>根据相似矩阵 S 构建邻接矩阵 W，构建度矩阵 D</p></li>\r\n<li><p>计算出拉普拉斯矩阵 L</p></li>\r\n<li><p>构建标准化后的拉普拉斯矩阵 <span class=\"math inline\">\\(D^{-1/2}LD^{-1/2}\\)</span></p></li>\r\n<li><p>计算 <span class=\"math inline\">\\(D^{-1/2}LD^{-1/2}\\)</span>最小的\r\n<span class=\"math inline\">\\(k_1\\)</span>个特征值所各自对应的特征向量\r\n<span class=\"math inline\">\\(f\\)</span></p></li>\r\n<li><p>将各自对应的特征向量 <span class=\"math inline\">\\(f\\)</span>组成的矩阵按行标准化，最终组成 <span class=\"math inline\">\\(n \\times k_1\\)</span>维的特征矩阵 F</p></li>\r\n<li><p>对 F 中的每一行作为一个 <span class=\"math inline\">\\(k_1\\)</span>维的样本，共 n\r\n个样本，用输入的聚类方法进行聚类，聚类维数为 <span class=\"math inline\">\\(k_2\\)</span>。</p></li>\r\n<li><p>得到簇划分 <span class=\"math inline\">\\(C(c_1,c_2,...c_{k_2})\\)</span>.</p></li>\r\n</ol>\r\n<p><strong>谱聚类总结</strong></p>\r\n<ul>\r\n<li>优点\r\n<ul>\r\n<li>谱聚类只需要数据之间的相似度矩阵，因此对于处理稀疏数据的聚类很有效。这点传统聚类算法比如\r\nK-Means 很难做到</li>\r\n<li>由于使用了降维，因此在处理高维数据聚类时的复杂度比传统聚类算法好。</li>\r\n</ul></li>\r\n<li>缺点\r\n<ul>\r\n<li>如果最终聚类的维度非常高，则由于降维的幅度不够，谱聚类的运行速度和最后的聚类效果均不好。</li>\r\n<li>聚类效果依赖于相似矩阵，不同的相似矩阵得到的最终聚类效果可能很不同。</li>\r\n</ul></li>\r\n</ul></li>\r\n</ul>\r\n</blockquote>\r\n<h4 id=\"例子\">例子</h4>\r\n<blockquote>\r\n<p>得到文档的语义图之后，利用聚类算法就可以对文档进行聚类。</p>\r\n</blockquote></li>\r\n</ul></li>\r\n<li><p>Graph Matching Algorithms</p>\r\n<h5 id=\"定义\">定义</h5>\r\n<blockquote>\r\n<p>计算两个图之间的相似度</p>\r\n</blockquote>\r\n<ul>\r\n<li><p>Graph Edit Distance</p>\r\n<h4 id=\"例子-1\">例子</h4>\r\n<blockquote>\r\n<p><strong>基本思想</strong>：计算两个图之间的相似度</p>\r\n<ul>\r\n<li>它将距离计算为将一个图转换为另一个图所需的更改次数（即添加、删除、替换）。</li>\r\n</ul>\r\n</blockquote></li>\r\n</ul>\r\n<h4 id=\"解释与例子\">解释与例子</h4></li>\r\n<li><p>Label Propagation Algorithms</p>\r\n<h5 id=\"定义-1\">定义</h5>\r\n<blockquote>\r\n<p><strong>基本思想</strong>：标签传播算法 (LPAs)\r\n是一类基于图的半监督算法，可将标签从标记的数据点传播到以前未标记的数据点。</p>\r\n<p><strong>操作实现</strong>：</p>\r\n<ul>\r\n<li>基本上，LPAs 通过在图上迭代地传播和聚合标签来操作。</li>\r\n<li>在每次迭代中，每个节点根据其相邻节点拥有的标签更改其标签。</li>\r\n<li>结果，标签信息在图形中扩散。</li>\r\n</ul>\r\n</blockquote>\r\n<h4 id=\"应用\">应用</h4>\r\n<h4 id=\"实例\">实例</h4>\r\n<blockquote>\r\n<ul>\r\n<li>LPA have been widely used in the network science literature for\r\ndiscovering <strong>community structures</strong> in complex\r\nnetworks.</li>\r\n<li>word-sense disambiguation</li>\r\n<li>sentiment analysis</li>\r\n</ul>\r\n<p>这些应用程序通常专注于标记数据稀缺的<strong>半监督学习</strong>设置，并利用\r\nLPA\r\n算法将标签从有限的标记示例传播到大量类似的未标记示例，并<strong>假设类似示例应该具有相似的标签</strong>。</p>\r\n</blockquote></li>\r\n<li><p>传统方法的限制和与GNNs的联系</p>\r\n<ul>\r\n<li><strong>限制</strong>\r\n<ul>\r\n<li>他们的表达能力有限。他们主要专注于捕获图的结构信息，但没有考虑节点和边的特征，这对于许多\r\nNLP 应用程序也非常重要。</li>\r\n<li>传统的基于图的算法没有统一的学习框架。不同的基于图的算法具有非常不同的属性和设置，并且仅适用于某些特定的用例</li>\r\n</ul></li>\r\n<li><strong>联系</strong>\r\n<ul>\r\n<li>因此需要一个学习能力更强的统一的框架</li>\r\n<li>GNNs 作为一类特殊的神经网络，可以对任意图结构数据进行建模</li>\r\n<li>大多数 GNNs\r\n变体可以被视为基于消息传递的学习框架。与传统的基于消息传递的算法（如\r\nLPAs）通过在图上传播标签进行操作不同，GNNs\r\n通常通过通过多个神经层转换、传播和聚合节点/边的特征来操作，以便学习更好的图表示。</li>\r\n<li>作为一种通用的基于图的学习框架，GNNs\r\n可以应用于各种与图相关的任务，例如节点分类、链接预测和图分类。</li>\r\n</ul></li>\r\n</ul></li>\r\n</ul>\r\n<h2 id=\"graph-neural-networks\">Graph Neural Networks</h2>\r\n<figure>\r\n<img src=\"/2023/01/16/GNN4NLP/image-20221009232432760-167384297065920.png\" alt=\"image-20221009232432760\">\r\n<figcaption aria-hidden=\"true\">image-20221009232432760</figcaption>\r\n</figure>\r\n<figure>\r\n<img src=\"/2023/01/16/GNN4NLP/image-20221009232455005-167384297065921.png\" alt=\"image-20221009232455005\">\r\n<figcaption aria-hidden=\"true\">image-20221009232455005</figcaption>\r\n</figure>\r\n<h3 id=\"foundations\">Foundations</h3>\r\n<ul>\r\n<li><p>本质上是图表示学习的模型，可以被应用到关注节点的任务以及关注图的任务中去。</p></li>\r\n<li><p>它学习图中每个节点的embedding，并综合节点embeddings来产生图embedding</p></li>\r\n<li><p>通常节点embedding的学习需要利用节点embedding和图结构 <span class=\"math display\">\\[\r\nh_i(l) = f_{filter}(A,H^{(l-1)})\r\n\\]</span> 其中<span class=\"math inline\">\\(A\\in\\mathbb{R}^{n\\times\r\nn}\\)</span>是图的邻接矩阵，<span class=\"math inline\">\\(H^{(l-1)} = \\{\r\nh_1^{(l-1)},h_2^{(l-1)},...,h_n^{(l-1)} \\} \\in \\mathbb{R}^{n \\times\r\nd}\\)</span>表示第<span class=\"math inline\">\\(l-1\\)</span>GNN层的节点embeddings输入。d是<span class=\"math inline\">\\(h_i^{(l-1)}\\)</span>的维数。我们将上面式子中描述的过程称为<span class=\"math inline\">\\(graph\\ filtering\\)</span>并且<span class=\"math inline\">\\(f_{filter}(·,·)\\)</span>被称为图滤波器。</p>\r\n<ul>\r\n<li>不同的模型只在图滤波器的选择和参数化上有区别</li>\r\n<li>图滤波不改变图的结构，但是会提炼节点embeddings</li>\r\n</ul></li>\r\n<li><p>由于图滤波不会改变图结构，因此我们受CNNs的影响引入池化操作来产生图级的embeddings</p>\r\n<ul>\r\n<li>图池化将图及其节点嵌入作为输入，然后生成一个具有较少节点的较小图及其相应的新节点嵌入。\r\n<span class=\"math display\">\\[\r\nA&#39;,H&#39; = f_{pool}(A,H)\r\n\\]</span> 其中<span class=\"math inline\">\\(f_{pool}(·,·) \\\r\nA\\in\\mathbb{R}^{n\\times n}\\)</span> 和<span class=\"math inline\">\\(A&#39;\r\n\\in \\mathbb{R}^{n&#39;\\times\r\nn&#39;}\\)</span>是进行池化前后的邻接矩阵。<span class=\"math inline\">\\(H,H&#39;\\)</span>则是池化前后的节点embeddings。在绝大多数情况下，将<span class=\"math inline\">\\(n&#39;\\)</span>设置成1来获取整个图的embedding</li>\r\n</ul></li>\r\n</ul>\r\n<h3 id=\"methodologies\">Methodologies</h3>\r\n<p><strong>Graph Filtering</strong></p>\r\n<h6 id=\"基础数学知识\">基础数学知识</h6>\r\n<blockquote>\r\n<p><strong>谱图理论（Spectral Graph Theory）</strong></p>\r\n<p>通过分析图的拉普拉斯矩阵来学习图的性质。</p>\r\n<ul>\r\n<li><p>Laplacian Matrix</p>\r\n<ul>\r\n<li>对称</li>\r\n<li>半正定</li>\r\n<li>0特征向量的数量等于图中联通分量的数量</li>\r\n</ul></li>\r\n<li><p>Graph Signal Processing</p>\r\n<ul>\r\n<li><p>graph signal</p>\r\n<p>一个graph signal由图和一个定义在图域中的映射函数<span class=\"math inline\">\\(f\\)</span>构成。 <span class=\"math display\">\\[\r\nf: V \\rightarrow \\mathbb{R}^{1\\times d}\r\n\\]</span>\r\n其中d是和每个节点相关的值得维数。不失一般性，我们将d设置为1，从而对所有的节点，我们有$\r\n$</p>\r\n<figure>\r\n<img src=\"/2023/01/16/GNN4NLP/image-20221010154638572-167384297065922.png\" alt=\"image-20221010154638572\">\r\n<figcaption aria-hidden=\"true\">image-20221010154638572</figcaption>\r\n</figure>\r\n<p>一个一维的图信号实例</p>\r\n<p>如果连接节点中的值相似，则图是<strong>平滑</strong>的。一个平滑的图信号的<strong>频率（frequency）</strong>会更低，因为值在图上通过边的变化是缓慢的。</p>\r\n<p>可以用<span class=\"math inline\">\\(\\textbf{f}^TL\\textbf{f}\\)</span>来表征信号<span class=\"math inline\">\\(\\textbf{f}\\)</span>的平滑程度，称为图信号的smoothness/frequency。</p>\r\n<p>图信号和经典的信号一样，都可以在<strong>时域(time\r\ndomain)</strong>和<strong>频域(frequency\r\ndomain)</strong>中表示。</p></li>\r\n<li><p>Graph Fourier Transform <span class=\"math display\">\\[\r\n\\hat{f} ( \\xi ) = \\lt f ( t ) , e x p ( - 2 \\pi i t \\xi ) \\gt = \\int _ {\r\n- \\infty } ^ { \\infty } f ( t ) e x p ( - 2 \\pi i t\\xi ) d t\r\n\\]</span> 经典的傅里叶变换将信号<span class=\"math inline\">\\(f(t)\\)</span>分解为了一系列任意实数<span class=\"math inline\">\\(\\xi\\)</span>的复指数<span class=\"math inline\">\\(exp(-2\\pi i t \\xi)\\)</span>。其中，<span class=\"math inline\">\\(\\xi\\)</span>可以看做是对应的指数项的频率。</p>\r\n<p>这些指数可以看成是<strong>拉普拉斯算子</strong>的<strong>特征函数</strong>。\r\n<span class=\"math display\">\\[\r\n{ \\nabla  }   exp ( - 2 \\pi i t \\xi) = \\frac { \\partial ^ { 2 } } {\r\n\\partial t ^ { 2 } }  }exp ( - 2 \\pi i t \\xi) \\\\\r\n{ = \\frac { \\partial } { \\partial t } ( - 2 \\pi i \\xi ) e x p ( - 2 \\pi\r\ni t\\xi ) } \\\\ { = - ( 2 \\pi i  \\xi ) ^ { 2 } { e x p ( - 2\\pi i t \\xi) }\r\n\\]</span> 类似的，图傅里叶变换可以表示为： <span class=\"math display\">\\[\r\n\\hat{\\textbf{f}}[l] =\r\n&lt;\\textbf{f},\\textbf{u}_l&gt;=\\sum_{i=1}^{N}\\textbf{f}[i]\\textbf{u}_l[i]\r\n\\]</span> 其中<span class=\"math inline\">\\(\\textbf{u}_l\\)</span>是图的拉普拉斯矩阵的第<span class=\"math inline\">\\(l\\)</span>个特征向量。对应的特征值<span class=\"math inline\">\\(\\lambda_l\\)</span>代表特征向量的frequency/smoothness。</p>\r\n<p>计算得到的<span class=\"math inline\">\\(\\hat{\\textbf{f}}\\)</span>就成为了信号<span class=\"math inline\">\\(\\textbf{f}\\)</span>的图傅里叶变换的结果。 <span class=\"math display\">\\[\r\n\\hat{\\textbf{f}} = \\textbf{U}^T\\textbf{f}\r\n\\]</span>\r\n图傅里叶变换可以看做是将输入信号<strong>分解</strong>为<strong>不同频率的图傅里叶基</strong>的过程。得到的<strong>系数</strong><span class=\"math inline\">\\(\\hat{\\textbf{f}}\\)</span>则表示不同傅里叶基对输入信号的贡献程度。是信号在<strong>spectral\r\ndomain</strong>中的表示。</p>\r\n<p>如以下等式所示： <span class=\"math display\">\\[\r\n\\textbf{u}_l^T\\textbf{L}\\textbf{u}_l=\\lambda_l·\\textbf{u}_l^T\\textbf{u}_l=\\lambda_l\r\n\\]</span>\r\n特征向量对应的特征值衡量其smoothness(因为上面的式子本身就是衡量信号在图中的平滑程度).<img src=\"/2023/01/16/GNN4NLP/image-20221010164908386-167384297065923.png\" alt=\"image-20221010164908386\"></p>\r\n<p>同样的，有逆图傅里叶变换过程，会将spectral\r\nrepresentation再转换回spatial representation <span class=\"math display\">\\[\r\n\\textbf{f} = \\sum_{l=1}^N\\hat{f}[l]\\textbf{u}_l[i]\r\n\\]</span> 即<span class=\"math inline\">\\(\\textbf{f} =\r\n\\textbf{U}\\hat{\\textbf{f}}\\)</span>。</p>\r\n<figure>\r\n<img src=\"/2023/01/16/GNN4NLP/image-20221010170329407-167384297066024.png\" alt=\"image-20221010170329407\">\r\n<figcaption aria-hidden=\"true\">image-20221010170329407</figcaption>\r\n</figure>\r\n<p>图 2.5 显示了空间域和频谱域中的图形信号。具体来说，图 2.5a\r\n显示了空间域中的图形信号，图 2.5b 显示了频谱域中的相同图形信号。在图\r\n2.5b 中，x 轴是图傅立叶基，y 轴表示相应的图傅立叶系数。</p></li>\r\n</ul></li>\r\n</ul>\r\n</blockquote>\r\n<ul>\r\n<li><p>Spectral-based Graph Filters</p>\r\n<h5 id=\"定义-2\">定义</h5>\r\n<blockquote>\r\n<ul>\r\n<li><p>Graph Spectral Filtering</p>\r\n<figure>\r\n<img src=\"/2023/01/16/GNN4NLP/image-20221010143237008-167384297066025.png\" alt=\"image-20221010143237008\">\r\n<figcaption aria-hidden=\"true\">image-20221010143237008</figcaption>\r\n</figure>\r\n<p>图谱滤波的思想是调制图信号的频率，使得其中的一些频率组成保持或增强，其他的则被移除或减弱。</p>\r\n<p>因此，给定一个图信号$ ^{N}$,我们首先需要在信号上应用<strong>Graph\r\nFourier Transform(GFT)</strong>来得到它的<strong>graph Fourier\r\ncoefficients(图傅里叶系数)</strong>。然后，在空间域中重建信号前调整这些图傅里叶系数。</p>\r\n<p>首先我们通过图傅里叶变换得到信号在频域中的系数 <span class=\"math display\">\\[\r\n\\hat{\\textbf{f}} = \\textbf{U}^T\\textbf{f}\r\n\\]</span>\r\n为了调节信号的频率(frequencies)，我们对图傅里叶系数进行如下滤波操作：\r\n<span class=\"math display\">\\[\r\n\\hat{\\textbf{f}}&#39;[i] =\r\n\\hat{\\textbf{f}}[i]·\\gamma(\\lambda_i),for\\quad i=1,...,N\r\n\\]</span> 其中<span class=\"math inline\">\\(\\gamma(\\lambda_i)\\)</span>是以<span class=\"math inline\">\\(\\lambda_i\\)</span>为输入的，来决定对应频率成分如何调节的函数。这个过程可以被下面的矩阵形式表述：\r\n<span class=\"math display\">\\[\r\n\\hat{\\textbf{f}} ^ { \\prime } = \\gamma ( \\Lambda ) \\cdot\r\n\\hat{\\textbf{f}} = \\gamma ( \\Lambda ) \\cdot \\textbf{U} ^ { T }\r\n\\textbf{f}\r\n\\]</span> 其中<span class=\"math inline\">\\(\\Lambda\\)</span>是一个由频率构成的对角矩阵(拉普拉斯矩阵的特征值)，并且<span class=\"math inline\">\\(\\gamma(\\Lambda)\\)</span>会将函数<span class=\"math inline\">\\(\\gamma()\\)</span>应用到对角矩阵<span class=\"math inline\">\\(\\Lambda\\)</span>中的每一个元素上。</p>\r\n<figure>\r\n<img src=\"/2023/01/16/GNN4NLP/image-20221011132228704-167384297066126.png\" alt=\"image-20221011132228704\">\r\n<figcaption aria-hidden=\"true\">image-20221011132228704</figcaption>\r\n</figure>\r\n<p>得到过滤后的系数后，我们就可以用逆图傅里叶变换将信号重建会图域中：\r\n<span class=\"math display\">\\[\r\n\\textbf{f}^{\\prime} =\r\n\\textbf{U}\\hat{\\textbf{f}}^{\\prime}=\\textbf{U}\\cdot\\gamma(\\Lambda)\\cdot\\textbf{U}^T\\textbf{f}\r\n\\]</span> 其中<span class=\"math inline\">\\(\\textbf{f}^{\\prime}\\)</span>是得到的过滤后的图信号。这个过滤的过程可以看做是将算子<span class=\"math inline\">\\(\\textbf{U}\\cdot\\gamma(\\Lambda)\\cdot\\textbf{U}^\\top\\)</span>应用于输入的图信号。</p>\r\n<p>便利起见，我们有时将函数<span class=\"math inline\">\\(\\gamma(\\Lambda)\\)</span>称为滤波器，因为它控制了图信号中的频率分量是如何被过滤的。比如，如果<span class=\"math inline\">\\(\\gamma(\\lambda_i)\\)</span>等于0，然后<span class=\"math inline\">\\(\\hat{\\textbf{f}}^{\\prime}[i]=0\\)</span>这就意味着信号<span class=\"math inline\">\\(\\textbf{f}\\)</span>中的频率组分<span class=\"math inline\">\\(\\textbf{u}_i\\)</span>被移除了。</p></li>\r\n<li><p>Spectral-based Graph Filter</p>\r\n<p>如果我们想要图信号更加平滑，我们可以将<span class=\"math inline\">\\(\\gamma(\\Lambda)\\)</span>设置成低通滤波器。但是，在图神经网络中，我们不知道哪些频率是更重要的，因此我们需要学习出滤波器的具体形式。更详细地说，我们选定<span class=\"math inline\">\\(\\gamma(\\Lambda)\\)</span>为特定的函数，然后学习其中的参数。</p>\r\n<p>最只有的方式，是对每一个特征值都有一个对应的函数 <span class=\"math display\">\\[\r\n\\gamma(\\lambda_l) = \\theta_l\r\n\\]</span> 但是，这种滤波器会有很大的局限性：</p>\r\n<ul>\r\n<li>参数过多，等于节点的个数。现实世界中的图的节点会过多</li>\r\n<li>滤波器<span class=\"math inline\">\\(\\textbf{U}\\cdot\\gamma(\\Lambda)\\cdot\\textbf{U}^\\top\\)</span>很可能是一个稠密矩阵，因此输出信号<span class=\"math inline\">\\(\\textbf{f}^{\\prime}\\)</span>的第i个元素会和图中的所有节点有关。即算子并非<strong>空间局部（spatially\r\nlocalized）</strong>的。此外，由于拉普拉斯矩阵的特征分解和稠密矩阵的矩阵乘法使得计算成本很昂贵。</li>\r\n</ul>\r\n<p>为了解决这个问题，一个<strong>多项式滤波算子——Poly-Filter</strong>被提出了。\r\n<span class=\"math display\">\\[\r\n\\gamma(\\lambda_l) = \\sum_{k=0}^{K}\\theta_k\\lambda_l^k\r\n\\newline\r\n\\gamma(\\Lambda) = \\sum_{k=0}^{K}\\theta_k\\Lambda^k\r\n\\]</span> 此时，同阶的是共用同一个参数<span class=\"math inline\">\\(\\theta\\)</span>的，因此参数个数是K+1，并不依赖于图节点的个数。</p>\r\n<p>同时，滤波算子<span class=\"math inline\">\\(\\textbf{U}\\cdot\\gamma({\\Lambda})\\cdot\\textbf{U}^\\top\\)</span>可以表示成拉普拉斯矩阵的多项式。这意味着：</p>\r\n<ul>\r\n<li>不需要再进行拉普拉斯矩阵的特征分解</li>\r\n<li>多项式参数化滤波算子是<strong>空间局部化</strong>的，即输出 f'\r\n的每个元素的计算只涉及图中的少量节点。</li>\r\n</ul>\r\n<p>应用Poly-Filter，我们可以得到过滤后的图信号如下：<img src=\"/2023/01/16/GNN4NLP/image-20221011144220776-167384297066127.png\" alt=\"image-20221011144220776\"></p>\r\n<p>其中<img src=\"/2023/01/16/GNN4NLP/image-20221011144520825-167384297066128.png\" alt=\"image-20221011144520825\"></p>\r\n<p>因此，我们有：<img src=\"/2023/01/16/GNN4NLP/image-20221011144758370-167384297066129.png\" alt=\"image-20221011144758370\"></p>\r\n<p>拉普拉斯矩阵的多项式都是稀疏的。同时，只有当节点<span class=\"math inline\">\\(v_i\\)</span>和节点<span class=\"math inline\">\\(v_j\\)</span>之间的最短路径长度即<span class=\"math inline\">\\(dis(v_i, v_j)\\)</span>小于或等于k时，<span class=\"math inline\">\\(\\textbf{L}^k\\)</span>的第i，j个元素才非零。(可以用归纳法进行证明)</p>\r\n<p>下面我们来关注输出的过滤后的信号的单个元素和哪些节点有关： <span class=\"math display\">\\[\r\n\\textbf{f}^\\prime[i] = \\sum_{v_j\\in\r\nV}(\\sum_{k=0}^K\\theta_k\\textbf{L}_{i,j}^k)\\textbf{f}[j]\r\n\\]</span>\r\n根据上面的结论我们知道，只有在K跳之内的节点才能参与计算，并不是图中的所有节点都参与计算的:<img src=\"/2023/01/16/GNN4NLP/image-20221011150648322-167384297066130.png\" alt=\"image-20221011150648322\"><img src=\"/2023/01/16/GNN4NLP/image-20221011150702333-167384297066131.png\" alt=\"image-20221011150702333\"></p>\r\n<p>其中<span class=\"math inline\">\\(N^K(v_i)\\)</span>代表节点K跳内的邻居节点；<span class=\"math inline\">\\(dis(v_i,v_j)\\)</span>代表节点之间最短路径的长度。</p>\r\n<p>Poly-Filter是在空间局部的，因为只和最邻近的K跳节点有关；也可以看做是空间滤波器，因为可以用空间结构表出（如上面的式子所示）。</p>\r\n<p>尽管Poly-Filter有很多优势，它也有很多局限性：</p>\r\n<ul>\r\n<li>多项式的基(<span class=\"math inline\">\\(1,x,x^2,...\\)</span>)彼此是不正交的。</li>\r\n<li>这就意味着系数彼此是相互依赖的，会导致一个节点的更新可能会导致其他节点的变动</li>\r\n</ul>\r\n<p>为了解决这个问题——<strong>Chebyshev Polynomial and\r\nCheby-Filter</strong></p>\r\n<p>切比雪夫多项式<span class=\"math inline\">\\(T_k(y)\\)</span>可以根据下面的递归关系产生 <span class=\"math display\">\\[\r\nT_k(y) = 2yT_{k-1}(y)-T_{k-2}(y)\r\n\\]</span> 其中，<span class=\"math inline\">\\(T_0(y)\\)</span>=1且<span class=\"math inline\">\\(T_1(y) = y\\)</span>。对于<span class=\"math inline\">\\(y \\in\r\n[-1,1]\\)</span>，这些切比雪夫多项式可以被表示成三角形式 <span class=\"math display\">\\[\r\nT_k(y) = cos(k\\ arccos(y))\r\n\\]</span> 而且这些切比雪夫多项式还满足如下的关系：</p>\r\n<figure>\r\n<img src=\"/2023/01/16/GNN4NLP/image-20221011161701031-167384297066132.png\" alt=\"image-20221011161701031\">\r\n<figcaption aria-hidden=\"true\">image-20221011161701031</figcaption>\r\n</figure>\r\n<p>其中<span class=\"math inline\">\\(\\delta_{l,m}\\)</span>=1当且仅当l=m时成立，否则为0；该式子表明了切比雪夫多项式是相互正交的。因此，切比雪夫多项式组成了希尔伯特空间中平方可积函数的一组正交基，在<span class=\"math inline\">\\(dy/\\sqrt{1-y^2}\\)</span>的度量下。记作<span class=\"math inline\">\\(L^2([-1,1],dy/\\sqrt1-y^2)\\)</span></p>\r\n<p>由于切比雪夫多项式的域是[-1,1],为了用切比雪夫多项式来近似滤波器，我们重新缩放和移动拉普拉斯矩阵的特征值如下：\r\n<span class=\"math display\">\\[\r\n\\widetilde{\\lambda}_l = \\frac{2\\cdot\\lambda_l}{\\lambda_{max}}-1\r\n\\]</span> 其中<span class=\"math inline\">\\(\\lambda_{max}\\)</span>也就是最大的特征值<span class=\"math inline\">\\(\\lambda_N\\)</span>。这样一来，所有的特征值都被改变到[-1,1]范围内了。矩阵层面的表示为：\r\n<span class=\"math display\">\\[\r\n\\widetilde{\\Lambda} = \\frac{2\\cdot\\Lambda}{\\lambda_{max}}-I\r\n\\]</span> 用截断的 切比雪夫(Chebyshev)多项式参数化的 Chevy-Filter\r\n可以表述如下： <span class=\"math display\">\\[\r\n\\gamma(\\Lambda) = \\sum_{k=0}^{K}\\theta_kT_k(\\widetilde{\\Lambda})\r\n\\]</span> 因此，对图信号使用Cheby-Filter的滤波过程可以表示为：<img src=\"/2023/01/16/GNN4NLP/image-20221011195033784-167384297066133.png\" alt=\"image-20221011195033784\"></p>\r\n<p>通过数学归纳法容易证明 <span class=\"math display\">\\[\r\n\\textbf{U}T_k(\\widetilde{\\Lambda})\\textbf{U}^\\top =\r\nT_k(\\widetilde{\\textbf{L}})\r\n\\newline\r\n\\widetilde{\\textbf{L}} = \\frac{2\\textbf{L}}{\\Lambda_{max}} - \\textbf{I}\r\n\\]</span> 此时，Cheby-Filter可以写成：<img src=\"/2023/01/16/GNN4NLP/image-20221011195716309-167384297066134.png\" alt=\"image-20221011195716309\"></p>\r\n<p>因此，Cheby-Filter 仍然享有 Poly-Filter\r\n的优点，同时在扰动下更稳定。</p>\r\n<p><strong>GCN-Filter: Simplified Cheby-Filter Involving 1-hop\r\nNeighbors</strong></p>\r\n<p>通过将切比雪夫多项式中的K设置成1并逼近<span class=\"math inline\">\\(\\lambda_{max} =\r\n2\\)</span>,GCN-Filter可以从Cheby-Filter中简化得到。</p>\r\n<p>在这样的简化和逼近下，可以简化为：<img src=\"/2023/01/16/GNN4NLP/image-20221011200344382-167384297066135.png\" alt=\"image-20221011200344382\"></p>\r\n<p>相应地，将 GCN-Filter 应用于图信号 f，我们可以得到输出信号\r\nf'，如下所示：<img src=\"/2023/01/16/GNN4NLP/image-20221011200414926-167384297066236.png\" alt=\"image-20221011200414926\"></p>\r\n<p>注意这里的拉普拉斯矩阵是规范化的，即<span class=\"math inline\">\\(\\textbf{L} =\r\n\\textbf{I}-\\textbf{D}^{-\\frac{1}{2}}\\textbf{A}\\textbf{D}^{-\\frac{1}{2}}\\)</span></p>\r\n<p>将<span class=\"math inline\">\\(\\theta=\\theta_0=-\\theta_1\\)</span>带入进行进一步的化简得到：<img src=\"/2023/01/16/GNN4NLP/image-20221011200817824-167384297066237.png\" alt=\"image-20221011200817824\"></p>\r\n<p>由于矩阵<span class=\"math inline\">\\(\\textbf{I}+\\textbf{D}^{-\\frac{1}{2}}\\textbf{A}\\textbf{D}^{-\\frac{1}{2}}\\)</span>的特征值在[0,2]上，当在深度学习中反复使用这个算子的时候可能导致数值不稳定，梯度消失/梯度爆炸。为了解决这个问题，我们使用renormalization\r\ntrick <span class=\"math display\">\\[\r\n\\widetilde{\\textbf{A}} = \\textbf{A} + \\textbf{I}\r\n\\newline\r\n\\widetilde{\\textbf{D}}_{ii} = \\sum_{j}\\widetilde{\\textbf{A}}_{i,j\\cdot}\r\n\\newline\r\n\\widetilde{\\textbf{D}}^{-\\frac{1}{2}}\\widetilde{\\textbf{A}}\\widetilde{\\textbf{D}}^{-\\frac{1}{2}}\r\n\\]</span></p>\r\n<blockquote>\r\n<p>这里怎么理解呢？</p>\r\n<p>我们将这个矩阵抽象成<span class=\"math inline\">\\(A = S\\Lambda\r\nS^{-1}\\)</span>,那么<span class=\"math inline\">\\(A^k\\)</span>可以从<span class=\"math inline\">\\(\\Lambda^{k}\\)</span>中得到 <span class=\"math display\">\\[\r\nu_k = A^ku_0=S\\Lambda^kS^{-1}u_0\r\n\\]</span> 我们令<span class=\"math inline\">\\(S^{-1}u_0 =\r\nc\\)</span>则有：<img src=\"/2023/01/16/GNN4NLP/image-20221011221409703-167384297066238.png\" alt=\"image-20221011221409703\"></p>\r\n<p>当层数比较多的时候，这个式子的结果主要由最大的特征值决定。当特征值大于1的时候，会趋向于无穷；特征值小于1的时候，会趋向于0。正好对应着梯度爆炸和梯度消失两种情况。</p>\r\n<p>而新的用来替换的方案，虽然不是恒等的，但是相当于进行了一种新的标准化。新的方案的特征值分布在[-1,1]上，相较于[0,2]发生梯度消失/梯度爆炸的几率更小。</p>\r\n</blockquote>\r\n<p>此时，我们得到GCN-Filter的算子如下： <span class=\"math display\">\\[\r\n\\textbf{f}^{\\prime} =\r\n\\theta\\widetilde{\\textbf{D}}^{-\\frac{1}{2}}\\widetilde{\\textbf{A}}\\widetilde{\\textbf{D}}^{-\\frac{1}{2}}\\textbf{f}\r\n\\]</span> 对于单个节点，这个过程可以看作是从它的 1\r\n跳邻居聚合信息，其中节点本身也被认为是它的 1 跳邻居。因此，GCN-Filter\r\n也可以看作是一个基于空间的过滤器，它在更新节点特征时只涉及直接连接的邻居。</p>\r\n<p><strong>Graph Filters for Multi-channel Graph Signals</strong></p>\r\n<p>上面我们讨论的都是1-channel的图信号，即每个节点的信号是一个标量。然而，实际上典型的图信号大都是multi-channel的。即每个节点都有一个特征向量。</p>\r\n<p>一个<span class=\"math inline\">\\(d_{in}\\)</span>维度的多通道图信号可以表示为<span class=\"math inline\">\\(\\textbf{F} \\in \\mathbb{R}^{N\\times\r\nd_{in}}\\)</span>。为了将图滤波器扩展到多通道信号上，我们利用来自所有输入通道的信号来生成输出信号，如下所示：\r\n<span class=\"math display\">\\[\r\n\\textbf{f}_{out} =\r\n\\sum_{d=1}^{d_{in}}\\textbf{U}\\cdot\\gamma_d(\\Lambda)\\cdot\\textbf{U}^\\top\\textbf{F}_{:,d}\r\n\\]</span> 其中<span class=\"math inline\">\\(\\textbf{f}_{out} \\in\r\n\\mathbb{R}^N\\)</span>是滤波器的单通道输出。因此，该过程可以被视为在每个输入通道中应用图形过滤器，然后计算它们的结果的总和。</p>\r\n<p>就像经典的卷积神经网络一样，在大多数情况下，使用多个滤波器来过滤输入通道，输出也是多通道信号。假如我们使用<span class=\"math inline\">\\(d_out\\)</span>通道的滤波器，则： <span class=\"math display\">\\[\r\n\\textbf{F}^{\\prime}_{:,j} =\r\n\\sum_{d=1}^{d_{in}}\\textbf{U}\\cdot\\gamma_{j,d}(\\Lambda)\\cdot\\textbf{U}^\\top\\textbf{F}_{:,d}\r\n\\quad for \\ j=1,...,d_{out}\r\n\\]</span> 具体来说，在方程式中的 GCN-Filter\r\n的情况下。这个多通道输入和输出的过程可以简单地表示为： <span class=\"math display\">\\[\r\n\\textbf{F}^{\\prime}_{:,j} =\r\n\\sum_{d=1}^{d_{in}}\\theta_{j,d}\\widetilde{\\textbf{D}}^{-\\frac{1}{2}}\\widetilde{\\textbf{A}}\\widetilde{\\textbf{D}}^{-\\frac{1}{2}}\\textbf{F}_{:,d}\r\n\\quad for \\ j=1,...,d_{out}\r\n\\]</span> 可以进一步写成： <span class=\"math display\">\\[\r\n\\textbf{F}^{\\prime} =\r\n\\widetilde{\\textbf{D}}^{-\\frac{1}{2}}\\widetilde{\\textbf{A}}\\widetilde{\\textbf{D}}^{-\\frac{1}{2}}\\textbf{F}\\Theta\r\n\\]</span> 其中<span class=\"math inline\">\\(\\Theta \\in\r\n\\mathbb{R}^{d_{in}\\times d_{out}}\\)</span>并且<span class=\"math inline\">\\(\\Theta[d,j]=\\theta_{j,d}\\)</span>是和第j个输出通道和第d个输入通道相对应的参数。</p>\r\n<p>具体来说，对于单个节点 <span class=\"math inline\">\\(v_i\\)</span>，等式中的过滤过程也可以表述为以下形式：<img src=\"/2023/01/16/GNN4NLP/image-20221011235610664-167384297066239.png\" alt=\"image-20221011235610664\"></p>\r\n<p>其中<span class=\"math inline\">\\(\\widetilde{d_i}=\\widetilde{\\textbf{D}}_{i,i}\\)</span>并且我们使用<span class=\"math inline\">\\(\\textbf{F}_i\\in \\mathbb{R}^{1\\times\r\nd_{out}}\\)</span>代表的是<span class=\"math inline\">\\(\\textbf{F}\\)</span>的第i行，即节点<span class=\"math inline\">\\(v_i\\)</span>的特征。上述方程式中的过程可以看作是从节点\r\nvi 的 1 跳邻居聚合信息。</p></li>\r\n</ul>\r\n</blockquote></li>\r\n<li><p>Spatial-based Graph Filters</p>\r\n<h5 id=\"再次学习\">再次学习</h5>\r\n<blockquote>\r\n<ul>\r\n<li><p>Filter in the very first GNN</p>\r\n<p>对节点<span class=\"math inline\">\\(v_i\\)</span>而言，它对应的标签可以表示为<span class=\"math inline\">\\(l_i\\)</span>。在过滤的过程中，输入的图特征可以被表示为<span class=\"math inline\">\\(\\textbf{F}\\)</span>,其中<span class=\"math inline\">\\(\\textbf{F}_i\\)</span>是它的第i行，是和节点<span class=\"math inline\">\\(v_i\\)</span>相对应的特征。整个过程可以表示为：\r\n<span class=\"math display\">\\[\r\n\\textbf{F}^{\\prime}_i = \\sum_{v_j \\in N(v_i)}g(l_i,\\textbf{F}_j,l_j)\r\n\\]</span> 其中g()是参数化的函数，称为local transition\r\nfunction，是空间局部的。这个过程对每个节点来说只使用其1跳的邻居节点。</p>\r\n<p>注意，节点的标签信息<span class=\"math inline\">\\(l_i\\)</span>可以被视为<strong>初始的输入信息</strong>，在过滤过程中是<strong>固定的</strong>并被利用。</p></li>\r\n<li><p>GraphSAGE-Filter</p>\r\n<p>对一个单独的节点<span class=\"math inline\">\\(v_i\\)</span>，产生它的新的特征的过程可以描绘如下：<img src=\"/2023/01/16/GNN4NLP/image-20221012145843950-167384297066240.png\" alt=\"image-20221012145843950\"></p>\r\n<p>其中 SAMPLE() 是将一个集合作为输入并从输入中随机采样 S\r\n个元素作为输出的函数，AGGREGATE()\r\n是一个组合来自相邻节点的信息的函数，其中 <span class=\"math inline\">\\(f&#39;_{N_S(v_i)}\\)</span> 表示AGGREGATE()\r\n函数的输出，而 [·,·] 是连接操作。</p>\r\n<p>目前，已经有很多AGGREGATE()函数被提出了：</p>\r\n<ul>\r\n<li><p><strong>Mean aggregator</strong>:\r\n直接对向量逐元素取平均。这和GCN-Filter很像，两者都使用（加权）平均，但区别在于：本方案后续对待节点自身的特征时是拼接上去的，而GCN-Filter则是同等对待，也是加权平均的一部分。</p></li>\r\n<li><p><strong>LSTM aggregator</strong>:\r\n将邻居节点视作一个序列，然后使用LSTM结构进行处理，最后一个单元的输出就作为操作的结果。</p>\r\n<p>由于节点本身不存在序列，因此采用随机序列。</p></li>\r\n<li><p><strong>Pooling operator</strong>:\r\n在进行最大池化操作前首先通过一层神经网络： <span class=\"math display\">\\[\r\n\\textbf{f}^{\\prime}_{N_S(v_i)}=max(\\{ \\alpha(\\textbf{F}_j\\Theta_{pool}\r\n),\\forall v_j \\in N_S(v_i)\\})\r\n\\]</span> 其中max()是逐元素的最大化操作；<span class=\"math inline\">\\(\\Theta_{pool}\\)</span>代表转移矩阵，<span class=\"math inline\">\\(\\alpha()\\)</span>是一个非线性激活函数。</p></li>\r\n</ul>\r\n<p>是空间局部性的，且聚合器是节点间共享的。</p></li>\r\n<li><p>MPNN: 基于空间的图滤波器的通用框架</p>\r\n<p>Message Passing Neural Networks (MPNN)\r\n是一个通用的图神经网络框架。很多基于空间的图滤波器都是它的特殊情况。</p>\r\n<p>对一个节点<span class=\"math inline\">\\(v_i\\)</span>而言，MPNN-Filter按照如下流程更新其特征：<img src=\"/2023/01/16/GNN4NLP/image-20221012154439952-167384297066341.png\" alt=\"image-20221012154439952\"></p>\r\n<p>其中<span class=\"math inline\">\\(M()\\)</span>是message函数，<span class=\"math inline\">\\(U()\\)</span>是更新函数，<span class=\"math inline\">\\(e_{(v_i,v_j)}\\)</span>是可能有的边特征。</p>\r\n<p>M()从节点的邻居节点产生需要传递给该节点的messages.</p>\r\n<p>U()然后通过结合<strong>原始特征</strong>和<strong>来自其邻居的聚合消息</strong>来更新节点\r\nvi 的特征。</p>\r\n<p>如果我们将第一个式子中的<strong>求和</strong>操作替换成一个抽象的操作，这个框架可以更加通用。</p></li>\r\n</ul>\r\n</blockquote></li>\r\n<li><p>Attention-based Graph Filter</p>\r\n<h5 id=\"学习\">学习</h5>\r\n<blockquote>\r\n<p>Self-attention机制被引入到graph attention\r\nnetworks(GAT)中来建立空间图滤波器。我们将GAT中的滤波器称为<strong>GAT-Filter</strong>。</p>\r\n<p>和GCN-Filter类似，GAT-Filter也在更新节点特征的时候使用了来自邻居节点的聚合信息。但是，GCN-Filter仅仅是基于图结构，GAT-Filter则是在执行聚合时尝试<strong>区分邻居的重要性</strong>。</p>\r\n<ul>\r\n<li><p>Pipeline</p>\r\n<ul>\r\n<li>在为节点 <span class=\"math inline\">\\(v_i\\)</span>\r\n生成新特征时，它会关注其所有邻居以生成每个邻居的重要性分数。</li>\r\n<li>然后在聚合过程中采用这些重要性分数作为线性系数。</li>\r\n</ul></li>\r\n<li><p>节点<span class=\"math inline\">\\(v_i\\)</span>和邻居节点及自身的重要性计算方法：\r\n<span class=\"math display\">\\[\r\ne_{ij} = a(\\textbf{F}_i\\Theta,\\textbf{F}_j\\Theta)\r\n\\]</span> 其中<span class=\"math inline\">\\(\\Theta\\)</span>是一个共享的参数矩阵。<span class=\"math inline\">\\(a()\\)</span>是一个共享的注意力函数，它是一个单层的前馈网络：\r\n<span class=\"math display\">\\[\r\na(\\textbf{F}_i\\Theta,\\textbf{F}_j\\Theta) = LeakyReLU(a^\\top\r\n[\\textbf{F}_i\\Theta,\\textbf{F}_j\\Theta])\r\n\\]</span> 其中<span class=\"math inline\">\\([\\cdot,\\cdot]\\)</span>指的是连接操作。<span class=\"math inline\">\\(a\\)</span>是一个参数化的向量。而<span class=\"math inline\">\\(LeakyReLU\\)</span>则是一种非线性激活函数。</p>\r\n<p>由方程式计算的分数在被用作聚合过程中的权重之前需要进行归一化，以将输出表示保持在合理的范围内。\r\n<span class=\"math inline\">\\(v_i\\)</span> 的所有邻居的归一化是通过\r\nsoftmax 层执行的：<img src=\"/2023/01/16/GNN4NLP/image-20221012165608095-167384297066342.png\" alt=\"image-20221012165608095\"></p>\r\n<p><span class=\"math inline\">\\(\\alpha_{ij}\\)</span>就是标准化后的节点<span class=\"math inline\">\\(v_j\\)</span>到节点<span class=\"math inline\">\\(v_i\\)</span>的重要性分数。</p>\r\n<p>有了重要性分数，节点的新的表示的计算过程就可以写成： <span class=\"math display\">\\[\r\n\\textbf{F}_i^{\\prime} = \\sum_{v_j\\in\r\nN(v_i)\\cup\\{v_i\\}}\\alpha_{ij}\\textbf{F}_j\\Theta\r\n\\]</span> 其中<span class=\"math inline\">\\(\\Theta\\)</span>是计算e的时候的同一个参数矩阵。</p>\r\n<p>为了稳定自注意力机制，提出了多头注意力机制。</p>\r\n<p>M个独立的拥有不同的<span class=\"math inline\">\\(\\Theta^m\\)</span>和<span class=\"math inline\">\\(\\alpha_{ij}^m\\)</span>的，按照上式形式的注意力机制被平行地使用，他们的输出之后会连接在一起来产生最终的表示：<img src=\"/2023/01/16/GNN4NLP/image-20221012171329066-167384297066343.png\" alt=\"image-20221012171329066\"></p>\r\n<p>注意力机制的滤波器也是空间局部性的，并且初始版本中各个独立的注意力机制连接前要通过激活函数，这里为了方便进行省略。</p></li>\r\n</ul>\r\n</blockquote></li>\r\n<li><p>Recurrent-based Graph Filter</p>\r\n<p>使用Gated Recurrent Unit(GRU)改进GNN\r\nfilter就得到了<strong>GGNN-Filter</strong>。</p>\r\n<h5 id=\"学习-1\">学习</h5>\r\n<blockquote>\r\n<ul>\r\n<li><p>GGNN-Filter是为边是有向的同时具有不同类型的图而设计的。</p></li>\r\n<li><p>对边<span class=\"math inline\">\\((v_i,v_j)\\)</span>而言，我们使用<span class=\"math inline\">\\(tp(v_i,v_j)\\)</span>来表示其类型。过滤过程可以表示为：<img src=\"/2023/01/16/GNN4NLP/image-20221012194112426-167384297066344.png\" alt=\"image-20221012194112426\"></p>\r\n<p>其中<span class=\"math inline\">\\(\\Theta\\)</span>型的变量都是需要去学习的参数。第一步是要从传入邻居节点和传出邻居节点中聚合信息。在这个聚合过程中，转移矩阵<span class=\"math inline\">\\(\\Theta_{tp(v_j,v_i)}^e\\)</span>是被所有类型为<span class=\"math inline\">\\(tp(v_i,v_j)\\)</span>的边连接到节点<span class=\"math inline\">\\(v_i\\)</span>的节点共享的。</p>\r\n<p>剩下的四个式子是GRU的步骤，用来更新隐藏表示。因此，这个过程也可以表示为：<img src=\"/2023/01/16/GNN4NLP/image-20221012194657161-167384297066345.png\" alt=\"image-20221012194657161\"></p></li>\r\n</ul>\r\n</blockquote></li>\r\n</ul>\r\n<p><strong>Graph Pooling</strong></p>\r\n<h6 id=\"简介\">简介</h6>\r\n<blockquote>\r\n<ul>\r\n<li><p>图池化层是为了获取图级表示而提出的，主要服务于基于图滤波得到的节点embeddings进行图分类、预测的graph-focused的下流任务。</p></li>\r\n<li><p>图池化操作主要根据两种信息：</p>\r\n<ul>\r\n<li>node features</li>\r\n<li>graph structure</li>\r\n</ul></li>\r\n<li><p>主要分为平面池化层和分级池化层</p>\r\n<ul>\r\n<li>平面图池在一个步骤中直接从节点嵌入生成图级表示。</li>\r\n<li>分层图池包含几个图池层，每个池层都遵循一堆图过滤器。</li>\r\n</ul></li>\r\n<li><p>一个图池化层通常输入一个图，并返回粗化图： <span class=\"math display\">\\[\r\n\\textbf{A}^{(op)},\\textbf{F}^{(op)}=pool(\\textbf{A}^{(ip)},\\textbf{F}^{(ip)})\r\n\\]</span> 就是两件事：新的图+新的特征</p></li>\r\n</ul>\r\n</blockquote>\r\n<h4 id=\"easy\">easy</h4>\r\n<blockquote>\r\n<p><strong>Flat Graph Pooling</strong></p>\r\n<p>过程总结： <span class=\"math display\">\\[\r\n\\textbf{f}_G=pool(\\textbf{A}^{(ip)},\\textbf{F}^{(ip)})\r\n\\]</span> 其中<span class=\"math inline\">\\(\\textbf{f}_G\\in\r\n\\mathbb{R}^{1\\times d_{op}}\\)</span>是图表示。</p>\r\n<p>最大池化层： <span class=\"math display\">\\[\r\n\\textbf{f}_G = max(\\textbf{F}^{(ip)})\r\n\\newline\r\n\\textbf{f}_G[i] = max(\\textbf{F}^{(ip)}_{:,i})\r\n\\]</span> 平均池化层： <span class=\"math display\">\\[\r\n\\textbf{f}_G = ave(\\textbf{F}^{(ip)})\r\n\\]</span> 基于注意力的平面池化操作，称为<strong>门控全局池化(gated\r\nglobal\r\npooling)</strong>。衡量每个节点重要性的注意力分数用于总结节点表示以生成图形表示。具体来说，节点\r\nvi 的注意力分数计算为：<img src=\"/2023/01/16/GNN4NLP/image-20221012200836949-167384297066346.png\" alt=\"image-20221012200836949\"></p>\r\n<p>其中h是将输入映射到一个标量的前馈网络。</p>\r\n<p>使用学习到的注意力分数，图形表示可以从节点表示中总结为：</p>\r\n<figure>\r\n<img src=\"/2023/01/16/GNN4NLP/image-20221012201009369-167384297066347.png\" alt=\"image-20221012201009369\">\r\n<figcaption aria-hidden=\"true\">image-20221012201009369</figcaption>\r\n</figure>\r\n<p>其中<span class=\"math inline\">\\(\\Theta_{ip}\\)</span>是待学习的参数。</p>\r\n<p>一些层池化操作潜入了过滤层。一个“假”节点被添加到连接到所有节点的图中（Li\r\net al.,\r\n2015）。这个“假”节点的表示可以在过滤过程中学习。它的表示捕获整个图的信息，因为它连接到图中的所有节点。因此，“假”节点的表示可以用作下游任务的图表示。</p>\r\n</blockquote>\r\n<h5 id=\"进一步\">进一步</h5>\r\n<blockquote>\r\n<ul>\r\n<li><p>平面池化层在汇总图表示的节点表示时通常会忽略<strong>分层图结构信息</strong>。</p></li>\r\n<li><p>分层图池化层旨在通过逐步粗化图来保留分层图结构信息，直到实现图表示。</p></li>\r\n<li><p>分层池化层可以根据它们粗化图的方式进行粗略分组</p>\r\n<ul>\r\n<li>一种分层池化层通过<strong>子采样</strong>来粗化图，即选择最重要的节点作为粗化图的节点。</li>\r\n<li>一种不同类型的分层池化层将输入图中的<strong>节点组合</strong>在一起形成超级节点，作为粗化图的节点。</li>\r\n</ul></li>\r\n<li><p>Downsampling-based Pooling</p>\r\n<p>为了粗化输入的图，我们需要从输入的<span class=\"math inline\">\\(N_{op}\\)</span>个节点中根据重要性测度来进行筛选。</p>\r\n<p>在本类池化层中，主要由三个组成部分：</p>\r\n<ul>\r\n<li>developing the <strong>measure</strong> for downsampling</li>\r\n<li>generating <strong>graph structure</strong> for the coarsened\r\ngraph</li>\r\n<li>generating <strong>node features</strong> for the coarsened\r\ngraph</li>\r\n</ul>\r\n<p>开山之作——<strong>gPool layer</strong></p>\r\n<p>重要性测度是从输入节点特征中学到的： <span class=\"math display\">\\[\r\n\\textbf{y}=\\frac{\\textbf{F}^{(ip)}\\textbf{p}}{||\\textbf{p}||}\r\n\\]</span> <span class=\"math inline\">\\(\\textbf{F}^{(ip)}\\in\r\n\\mathbb{R}^{N_{ip}\\times d_{ip}}\\)</span>是代表输入节点特征的。而<span class=\"math inline\">\\(\\textbf{p}\\in\r\n\\mathbb{R}^{d_{ip}}\\)</span>是将输入特征投影到重要性分数中要学习的向量。</p>\r\n<p>得到重要性分数y之后就可以得到前k个最重要的节点了 <span class=\"math display\">\\[\r\nidx = rank(\\textbf{y},N_{op})\r\n\\]</span> 粗化图的图结构可以从输入图的图结构中推导出为： <span class=\"math display\">\\[\r\n\\textbf{A}^{(op)} = \\textbf{A}^{(ip)}(idx,idx)\r\n\\]</span> 等式右边的部分指的是从矩阵中按行和列进行抽取。</p>\r\n<p>同样，也可以从输入节点特征中提取节点特征。在（Gao 和\r\nJi，2019）中，采用门控系统来控制从输入特征到新特征的信息流。具体来说，具有较高重要性分数的选定节点可以有更多的信息流到粗化图，可以建模为：<img src=\"/2023/01/16/GNN4NLP/image-20221012220208418-167384297066348.png\" alt=\"image-20221012220208418\"></p>\r\n<p>其中，<span class=\"math inline\">\\(\\sigma()\\)</span>是将重要性分数映射到(0,1)的激活函数。而<span class=\"math inline\">\\(\\textbf{1}_{d_{ip}}\\in\r\n\\mathbb{R}^{d_{ip}}\\)</span>是全1向量。请注意，y(idx) 根据 idx\r\n中的索引从 y 中提取相应的元素，而 <span class=\"math inline\">\\(F^{(ip)}(idx)\\)</span> 根据 idx 检索相应的行。</p>\r\n<p>gPool\r\nlayer中学习重要性的方法忽视了<strong>图结构信息</strong>，为了容纳图结构信息，GCN-Filter被用来学习重要性分数。\r\n<span class=\"math display\">\\[\r\n\\textbf{y}=\\alpha(GCN-Filter(\\textbf{A}^{(ip)},\\textbf{F}^{(ip)}))\r\n\\]</span> 其中<span class=\"math inline\">\\(\\alpha\\)</span>是激活函数。请注意，y\r\n是向量而不是矩阵。也就是说，GCN-Filter的输出通道数设置为1。这个图池化操作被命名为SAGPool。</p></li>\r\n<li><p>Supernode-based Hierarchical Graph Pooling</p>\r\n<p>基于超节点的池化方法旨在通过生成超节点来粗化输入图。具体来说，他们尝试学习将输入图中的节点分配到不同的集群中，这些集群被视为超级节点。</p>\r\n<p>这些超节点被视为粗化图中的节点。然后生成超节点之间的边和这些超节点的特征以形成粗化图。</p>\r\n<p>这种方法有三种关键的组分：</p>\r\n<ul>\r\n<li>generating supernodes as the nodes for the coarsened graph</li>\r\n<li>generating graph structure for the coarsened graph</li>\r\n<li>generating node features for the coarsened graph</li>\r\n</ul>\r\n<p><strong>diffpool</strong></p>\r\n<p>具体来说，使用 GCN-Filter 学习从输入图中的节点到超节点的软分配矩阵：\r\n<span class=\"math display\">\\[\r\n\\textbf{S} = softmax(GCN-Filter(\\textbf{A}^{(ip)}))\r\n\\]</span> 其中<span class=\"math inline\">\\(\\textbf{S}\\in\r\n\\mathbb{R}^{N_{ip}\\times N_{op}}\\)</span>是需要被学习的分配矩阵。<span class=\"math inline\">\\(\\textbf{F}^{(ip)}\\)</span>通常是最新的图滤波层的输出。此外，可以堆叠几个\r\nGCN 过滤器来学习分配矩阵，尽管在上面的方程式中只使用了一个过滤器</p>\r\n<p>分配矩阵的每一行都可以看成是一个超节点。第 i 行中的第 j\r\n个元素表示将第 i 个节点分配给第 j 个超节点的概率。</p>\r\n<p>具体来说，粗化图的图结构可以通过利用软分配矩阵 S 从输入图生成：<img src=\"/2023/01/16/GNN4NLP/image-20221012231514618-167384297066449.png\" alt=\"image-20221012231514618\"></p>\r\n<p>同理，根据赋值矩阵 S\r\n对输入图的节点特征进行线性组合，可以得到超节点的节点特征：<img src=\"/2023/01/16/GNN4NLP/image-20221012231716198-167384297066450.png\" alt=\"image-20221012231716198\"></p>\r\n<p>其中<span class=\"math inline\">\\(\\textbf{F}^{(inter)}\\in\r\n\\mathbb{R}^{N_{ip}\\times\r\nd_{op}}\\)</span>是通过GCN-Filter学习到的中间特征： <span class=\"math display\">\\[\r\nF ^ { ( inter ) } = G C N - F i l t e r ( A ^ { ( i p ) } , F ^ { ( i p\r\n) } )\r\n\\]</span> 上面式子中的GCN-Filter也是可以堆叠多个。</p>\r\n<p><strong>EigenPooling</strong></p>\r\n<p>EigenPooling (Ma et al., 2019b)\r\n使用谱聚类方法生成超节点，并专注于为粗化图形成图结构和节点特征。</p>\r\n<p>应用谱聚类算法后，得到一组不重叠的簇，也可以作为粗化图的超节点。</p>\r\n<p>输入节点和输出节点之间的<strong>分配矩阵</strong>可以被表示为<span class=\"math inline\">\\(\\textbf{S} \\in \\{0,1\\}^{N_{ip}\\times\r\nN_{op}}\\)</span>,其中一行中只有一个元素是1，其余全是0。</p>\r\n<p>更具体地说，仅当第 i 个节点分配给第 j 个超级节点时，S[i, j] =\r\n1。对于第 k 个超级节点，我们使用 <span class=\"math inline\">\\(A(k) \\in\r\n\\mathbb{R}^{N^{(k)}×N^{(k)}}\\)</span> 来描述其对应集群中的图结构，其中\r\nN(k) 是该集群中的节点数。我们将采样算子<span class=\"math inline\">\\(\\textbf{C}^{(k)}\\in \\{0,1\\}^{N_{ip}\\times\r\nN^{(k)}}\\)</span>​定义为： <span class=\"math display\">\\[\r\n\\textbf{C}^{(k)}[i,j] = 1\\quad if\\ and \\ only \\ if\r\n\\  \\Gamma^{(k)}(j)=v_i\r\n\\]</span> 其中 <span class=\"math inline\">\\(Γ^{(k)}\\)</span> 表示第 k\r\n个集群中的节点列表，<span class=\"math inline\">\\(Γ^{(k)}(j) =\r\nv_i\\)</span> 表示节点 vi 对应于该集群中的第 j\r\n个节点。使用这个采样算子，第 k 个簇的邻接矩阵可以正式定义为：<img src=\"/2023/01/16/GNN4NLP/image-20221012235316597-167384297066451.png\" alt=\"image-20221012235316597\"></p>\r\n<p>接下来，我们讨论为粗化图生成图结构和节点特征的过程。为了形成超级节点之间的图结构，只考虑原始图中跨集群的连接。为了实现这个目标，我们首先为输入图生成簇内邻接矩阵，该矩阵仅由每个簇内的边组成：<img src=\"/2023/01/16/GNN4NLP/image-20221012235530298-167384297066452.png\" alt=\"image-20221012235530298\"></p>\r\n<p>然后，仅由跨集群的边组成的集群间邻接矩阵可以表示为 <span class=\"math inline\">\\(A_{ext} =\r\nA-A_{int}\\)</span>。粗化图的邻接矩阵可以得到：<img src=\"/2023/01/16/GNN4NLP/image-20221012235630483-167384297066453.png\" alt=\"image-20221012235630483\"></p>\r\n<p>采用<strong>图傅里叶变换</strong>生成节点特征。具体而言，利用每个子图（或集群）的图结构和节点特征来生成相应超节点的节点特征。接下来，我们以第\r\nk 个集群作为说明性示例来演示该过程。令 L(k) 表示该子图的拉普拉斯矩阵，$\r\nu<sup>{(k)}<em>1 , . . . , u^{(k)}</em>{n</sup>{(k)}}$\r\n是其对应的特征向量。该子图中节点的特征可以通过使用采样算子 <span class=\"math inline\">\\(C^{(k)}\\)</span> 从 <span class=\"math inline\">\\(F^{(ip) }\\)</span>中提取，如下所示：</p>\r\n<figure>\r\n<img src=\"/2023/01/16/GNN4NLP/image-20221013000115875-167384297066454.png\" alt=\"image-20221013000115875\">\r\n<figcaption aria-hidden=\"true\">image-20221013000115875</figcaption>\r\n</figure>\r\n<p>其中<span class=\"math inline\">\\(\\textbf{F}_{ip}^{(k)} \\in\r\n\\mathbb{R}^{N^{(k)}\\times\r\nd_{ip}}\\)</span>是第k集簇中的节点的输入特征。</p>\r\n<p>之后，我们使用傅里叶变换来为<span class=\"math inline\">\\(\\textbf{F}^{(k)}_{ip}\\)</span>中的所有频道产生系数：<img src=\"/2023/01/16/GNN4NLP/image-20221013000529937-167384297066455.png\" alt=\"image-20221013000529937\"></p>\r\n<p>其中<span class=\"math inline\">\\(\\textbf{f}^{(k)}_i \\in\r\n\\mathbb{R}^{1\\times d_{ip}}\\)</span>由所有特征通道的第 i\r\n个图傅里叶系数组成。</p>\r\n<p>第 k 个超节点的节点特征可以通过将这些系数连接起来形成：<img src=\"/2023/01/16/GNN4NLP/image-20221013000931882-167384297066456.png\" alt=\"image-20221013000931882\"></p>\r\n<p>我们通常只利用<strong>前几个系数</strong>来生成超级节点的特征，原因有两个。</p>\r\n<ul>\r\n<li>首先，不同的子图可能有不同数量的节点；因此，为了确保特征的相同维度，需要丢弃一些系数。</li>\r\n<li>其次，前几个系数通常捕获大部分重要信息，因为实际上，大多数图形信号都是平滑的。</li>\r\n</ul></li>\r\n</ul>\r\n</blockquote>\r\n","tags":["GNN in NLP"]},{"title":"广义EM的一个特例是VBEM","url":"/2023/01/16/%E5%B9%BF%E4%B9%89EM%E7%9A%84%E4%B8%80%E4%B8%AA%E7%89%B9%E4%BE%8B%E6%98%AFVBEM/","content":"<h1 id=\"em2\">EM2</h1>\r\n<blockquote>\r\n<p>这里是理解EM算法的几重境界的后续部分。对于以EM算法为线，串联重要的数学基础很重要。</p>\r\n<span id=\"more\"></span>\r\n</blockquote>\r\n<h3 id=\"广义em的一个特例是vbem\">广义EM的一个特例是VBEM</h3>\r\n<h4 id=\"lsalatent-semantic-analysis\">LSA(latent semantic analysis)</h4>\r\n<ul>\r\n<li><p>单词向量空间</p>\r\n<blockquote>\r\n<p>给定一个含有n个文本的集合<span class=\"math inline\">\\(D =\r\n{d_1,d_2,...,d_n}\\)</span>，以及在所有文本中出现的m个单词的集合<span class=\"math inline\">\\(W =\r\n{w_1,w_2,...,w_m}\\)</span>。将单词在文本中出现的数据用一个<strong>单词-文本矩阵(word-document\r\nmatrix)</strong>表示，记作X(mxn矩阵)。元素<span class=\"math inline\">\\(x_{ij}\\)</span>表示单词<span class=\"math inline\">\\(w_i\\)</span>在文本<span class=\"math inline\">\\(d_j\\)</span>中出现的频数或权值。</p>\r\n<p>单词种类多，单个文档中单词种类少，所以通常是一个稀疏矩阵。</p>\r\n<p>权值常用<strong>单词频率-逆文本频率(term frequency-inverse document\r\nfrequency)</strong>表示 <span class=\"math display\">\\[\r\nTFIDF_{ij} = \\frac{tf_{ij}}{tf_{·j}}\\log\\frac{df}{df_i},\\quad i =\r\n1,2,...,m;\\quad j = 1,2,...,n\r\n\\]</span> 其中<span class=\"math inline\">\\(tf_{ij}\\)</span>是单词<span class=\"math inline\">\\(w_i\\)</span>出现在文本<span class=\"math inline\">\\(d_j\\)</span>中的频数，<span class=\"math inline\">\\(df_i\\)</span>是所有含有单词<span class=\"math inline\">\\(w_i\\)</span>的文本数，<span class=\"math inline\">\\(df\\)</span>是文本集D全部的文档数。</p>\r\n<p>单词-文本矩阵X每一列代表一个文本，<span class=\"math inline\">\\(X =\r\n[x_1,x_2,...,x_n]\\)</span>即表示本的单词向量。</p>\r\n<p>使用内积/标准化内积（余弦）表示文本相似度。</p>\r\n</blockquote>\r\n<ul>\r\n<li>优点：简单，效率高</li>\r\n<li>缺点：无法解决<strong>一词多义</strong>及<strong>多词一义</strong>问题</li>\r\n</ul></li>\r\n<li><p>话题向量空间</p>\r\n<ul>\r\n<li><p>对一词多义和多词一义问题的解决</p>\r\n<blockquote>\r\n<p>一词多义的词可以对应多个话题，多词一义的词可以对应同一个话题</p>\r\n</blockquote></li>\r\n</ul>\r\n<blockquote>\r\n<p>假设所有文本共含有k个话题。假设每个话题由一个定义在单词集合W上的m维向量表示，称为话题向量。</p>\r\n<p>T是单词-话题矩阵(mxk)，其中<span class=\"math inline\">\\(t_{il}\\)</span>是单词<span class=\"math inline\">\\(w_i\\)</span>在话题<span class=\"math inline\">\\(t_l\\)</span>中的权值，权值越大，单词在该话题中的重要度就越大。</p>\r\n</blockquote>\r\n<blockquote>\r\n<p>单词向量空间中一个文本对应的向量<span class=\"math inline\">\\(x_j\\)</span>投影到T中可以得到话题向量空间中一个向量<span class=\"math inline\">\\(y_j\\)</span>,是一个k维向量。</p>\r\n<p>其中<span class=\"math inline\">\\(y_{lj}\\)</span>是文本<span class=\"math inline\">\\(d_j\\)</span>在话题<span class=\"math inline\">\\(t_l\\)</span>的权值，l=1,2,...,k,权值越大，该话题该文本中的重要程度就越高。</p>\r\n<p>Y称为话题-文本矩阵，<span class=\"math inline\">\\(Y =\r\n[y_1,y_2,...,y_n]\\)</span></p>\r\n</blockquote>\r\n<ul>\r\n<li><p>从单词向量空间到话题向量空间的<strong>线性变换</strong></p>\r\n<blockquote>\r\n<p>单词向量空间的文本向量<span class=\"math inline\">\\(x_j\\)</span>可以通过它在话题空间中的向量<span class=\"math inline\">\\(y_j\\)</span>近似表示，具体地由k个话题向量以<span class=\"math inline\">\\(y_j\\)</span>为系数的线性组合<strong>近似</strong>表示\r\n<span class=\"math display\">\\[\r\nx_j \\approx y_{1j}t_1 + y_{2j}t_2 + ··· + y_{kj}t_k\r\n\\]</span> 即 <span class=\"math inline\">\\(X \\approx\r\nTY\\)</span>(这里之所以是约等于，是因为话题个数k往往小于单词个数，导致其表达能力在单词之下，所以可能造成信息损失)\r\n<span class=\"math display\">\\[\r\nx_j \\Rightarrow y_j\r\n\\]</span> 即将m维的单词向量空间压缩到了k维的话题向量空间。</p>\r\n<figure>\r\n<img src=\"/2023/01/16/%E5%B9%BF%E4%B9%89EM%E7%9A%84%E4%B8%80%E4%B8%AA%E7%89%B9%E4%BE%8B%E6%98%AFVBEM/17-2.png\" alt=\"17-1\">\r\n<figcaption aria-hidden=\"true\">17-1</figcaption>\r\n</figure>\r\n</blockquote></li>\r\n</ul></li>\r\n<li><p>潜在语义分析算法</p>\r\n<ul>\r\n<li><p>矩阵奇异值分解算法</p>\r\n<ul>\r\n<li>截断奇异值分解至k维 <span class=\"math display\">\\[\r\nX \\approx U_k\\Sigma_kV_k^T\r\n\\]</span> 话题空间<span class=\"math inline\">\\(U_k\\)</span>,以及文本在话题空间的表示<span class=\"math inline\">\\((\\Sigma_kV_k^T)\\)</span></li>\r\n</ul></li>\r\n<li><p>非负矩阵分解算法</p>\r\n<blockquote>\r\n<p>若一个矩阵所有元素非负，则称该矩阵为非负矩阵，若X是非负矩阵，则记作<span class=\"math inline\">\\(X \\geq 0\\)</span></p>\r\n<p>给定一个非负矩阵X，找到两个非负矩阵W和H。使得 <span class=\"math display\">\\[\r\nX \\approx WH\r\n\\]</span>\r\nX可以看成基W和系数H的线性组合。非负矩阵分解旨在用较少的基向量，系数向量来表示较大的数据矩阵。</p>\r\n<p>非负矩阵分解有很直观的解释，话题向量和文本向量都非负，对应着“伪概率分布”，向量的线性组合表示局部叠加构成整体。</p>\r\n<p>即，单词向量是总的概率分布，有k个小的话题向量的分布组合而成。</p>\r\n</blockquote>\r\n<ul>\r\n<li><p>算法</p>\r\n<ul>\r\n<li><p>初始化</p>\r\n<blockquote>\r\n<p><span class=\"math inline\">\\(W\\geq\r\n0\\)</span>且对W的每一列数据归一化</p>\r\n<p><span class=\"math inline\">\\(H\\geq 0\\)</span></p>\r\n</blockquote></li>\r\n<li><p>迭代</p>\r\n<blockquote>\r\n<p>对迭代次数由1到t执行一下步骤</p>\r\n<ul>\r\n<li><p>更新W元素 <span class=\"math display\">\\[\r\nW_{il} = W_{il}\\frac{(XH^T)_{il}}{(WHH^T)_{il}},\\quad\r\ni=1,2,...,m;l=1,2,...,k\r\n\\]</span></p></li>\r\n<li><p>更新H元素 <span class=\"math display\">\\[\r\nH_{lj} = H_{lj}\\frac{(W^TX)_{lj}}{(W^TWH)_{lj}},\\quad\r\nl=1,2,...,k;j=1,2,...,n\r\n\\]</span></p></li>\r\n</ul>\r\n</blockquote></li>\r\n</ul></li>\r\n</ul></li>\r\n</ul></li>\r\n</ul>\r\n<h4 id=\"plsaprobabilistic-latent-semantic-analysis\">PLSA(probabilistic\r\nlatent semantic analysis)</h4>\r\n<ul>\r\n<li><p>生成模型</p>\r\n<blockquote>\r\n<p>每个文本拥有自己的话题概率分布<span class=\"math inline\">\\(P(z|d)\\)</span>，每个话题有自己的单词概率分布<span class=\"math inline\">\\(P(w|z)\\)</span>。即一个文本由其话题决定，一个话题由其单词决定</p>\r\n</blockquote>\r\n<ul>\r\n<li><p>生成模型生成文本-单词共现数据的步骤：</p>\r\n<ul>\r\n<li><p>根据P(d)，从文本（指标）集合中随机选取一个文本d，共生成N个文本；针对每个文本执行以下操作。</p></li>\r\n<li><p>在文本d给定条件下，依据P(z|d)从话题集合中随机选取一个话题z,共生成L个话题，这里L是文本长度</p></li>\r\n<li><p>在话题z给定条件下，根据P(w|z)从单词集合中随机选择一个单词w</p>\r\n<blockquote>\r\n<p>w和d是观测变量，z是隐变量</p>\r\n</blockquote></li>\r\n</ul>\r\n<blockquote>\r\n<p>从数据生成过程可知，文本-单词共现数据T的生成概率为所有单词-文本对(w,d)的生成概率的乘积\r\n<span class=\"math display\">\\[\r\nP(T) = \\prod_{(w,d)}P(w,d)^{n(w,d)}\r\n\\]</span> 这里n(w,d)表示(w,d)的出现次数单词-文本对出现的总次数是NxL。\r\n<span class=\"math display\">\\[\r\nP(w,d) = P(d)P(w|d)\r\n\\newline\r\n=P(d)\\sum_{z}P(w,z|d)\r\n\\newline\r\n=P(d)\\sum_{z}P(z|d)P(w|z)\r\n\\]</span>\r\n倒数第二步到最后一步基于一个假设：给定话题z的条件下，单词w和文本d条件独立:即给定d确定z之后，w就可以完全由z决定，而不需要再考虑d这个条件。\r\n<span class=\"math display\">\\[\r\nP(w,z|d) = P(z|d)P(w|d,z)\r\n\\newline\r\n=P(z|d)P(w|z)\r\n\\]</span></p>\r\n</blockquote>\r\n<p>生成模型属于概率有向图模型，可以用有向图表示<img src=\"/2023/01/16/%E5%B9%BF%E4%B9%89EM%E7%9A%84%E4%B8%80%E4%B8%AA%E7%89%B9%E4%BE%8B%E6%98%AFVBEM/image-20220918170426070-16738440550722.png\" alt=\"image-20220918170426070\"></p></li>\r\n</ul></li>\r\n<li><p>共现模型</p>\r\n<blockquote>\r\n<p><span class=\"math display\">\\[\r\nP(w,d) = \\sum_{z\\in Z}P(z)P(w|z)P(d|z)\r\n\\]</span></p>\r\n<p>同样假设话题z给定的情况下，单词w和文本d是条件独立的 <span class=\"math display\">\\[\r\nP(w,d|z) = P(w|z)P(d|z)\r\n\\]</span></p>\r\n</blockquote></li>\r\n</ul>\r\n<p>​ 从公式上而言共现模型和生成模型两者等价。<img src=\"/2023/01/16/%E5%B9%BF%E4%B9%89EM%E7%9A%84%E4%B8%80%E4%B8%AA%E7%89%B9%E4%BE%8B%E6%98%AFVBEM/image-20220918172005928-16738440550711.png\" alt=\"image-20220918172005928\"></p>\r\n<ul>\r\n<li><p>模型性质</p>\r\n<ul>\r\n<li>如果直接定义单词文本的贡献概率P(w,d)，模型参数个数<span class=\"math inline\">\\(O(M·N)\\)</span>。而引入隐变量之后，参数个数成为<span class=\"math inline\">\\(O(M·K+N·K)\\)</span>，其中K是话题数。现实中<span class=\"math inline\">\\(K \\ll\r\nM\\)</span>。所以，模型更加简洁，减少过拟合的可能性。<img src=\"/2023/01/16/%E5%B9%BF%E4%B9%89EM%E7%9A%84%E4%B8%80%E4%B8%AA%E7%89%B9%E4%BE%8B%E6%98%AFVBEM/image-20220918172922802-16738440550723.png\" alt=\"image-20220918172922802\"></li>\r\n</ul></li>\r\n<li><p>模型的几何解释</p>\r\n<blockquote>\r\n<p>单纯形：<a href=\"https://zh.m.wikipedia.org/wiki/几何学\">几何学</a>上，<strong>单纯形</strong>或者<strong>n-单纯形</strong>是和<a href=\"https://zh.m.wikipedia.org/wiki/三角形\">三角形</a>类似的<em>n</em>维<a href=\"https://zh.m.wikipedia.org/wiki/几何形状\">几何体</a>。精确的讲，单纯形是某个n维以上的<a href=\"https://zh.m.wikipedia.org/wiki/欧几里得空间\">欧几里得空间</a>中的（<em>n</em>+1）个<a href=\"https://zh.m.wikipedia.org/wiki/仿射变换\">仿射无关</a>（也就是没有<em>m-1</em>维<a href=\"https://zh.m.wikipedia.org/wiki/平面_(数学)\">平面</a>包含<em>m</em>+1个点；这样的点集被称为处于<a href=\"https://zh.m.wikipedia.org/wiki/一般位置\">一般位置</a>）的<a href=\"https://zh.m.wikipedia.org/wiki/点\">点</a>的集合的<a href=\"https://zh.m.wikipedia.org/wiki/凸包\">凸包</a>。</p>\r\n<p>例如，0-单纯形就是<a href=\"https://zh.m.wikipedia.org/wiki/点\">点</a>，1-单纯形就是<a href=\"https://zh.m.wikipedia.org/wiki/线段\">线段</a>，2-单纯形就是<a href=\"https://zh.m.wikipedia.org/wiki/三角形\">三角形</a>，3-单纯形就是<a href=\"https://zh.m.wikipedia.org/wiki/四面體\">四面体</a>，而4-单纯形是一个<a href=\"https://zh.m.wikipedia.org/wiki/正五胞体\">五胞体</a>（每种情况都包含内部）。</p>\r\n</blockquote>\r\n<p>概率分布<span class=\"math inline\">\\(P(w|d)\\)</span>表示文本d生成单词w的概率 <span class=\"math display\">\\[\r\n\\sum_{i=1}^{M}P(w_i|d) = 1,\\quad 0 \\leq P(w_i|d)\\leq1,i=1,2,...,M\r\n\\]</span> 可以由M维空间的(M-1)单纯形中的点表示。<img src=\"/2023/01/16/%E5%B9%BF%E4%B9%89EM%E7%9A%84%E4%B8%80%E4%B8%AA%E7%89%B9%E4%BE%8B%E6%98%AFVBEM/image-20220918211648082-16738440550724.png\" alt=\"image-20220918211648082\"></p>\r\n<p>PLSA(生成模型)中文本概率分布有如下关系成立： <span class=\"math display\">\\[\r\nP(w|d) = \\sum_{z}P(z|d)P(w|z)\r\n\\]</span> 概率分布<span class=\"math inline\">\\(P(w|z)\\)</span>也存在于M维空间中的(M-1)单纯形中(系数和是1，向量的线性表出在一个面上，则每个向量都在这个面上)。如果有K个话题，则对应(M-1)单纯形中的K个点。以这K个点为顶点，构成一个(K-1)单纯形，称为话题单纯形，是单词单纯形的子单纯形。图中所示是K=3,M=3。当K=2时，参数向量在空间中缩为线段。K=1缩为点。</p>\r\n<p>即参数空间相对变小。</p></li>\r\n<li><p>PLSA与LSA的关系</p>\r\n<ul>\r\n<li><p>对LSA而言，单词-文本矩阵进行奇异值分解得到<span class=\"math inline\">\\(X = U\\Sigma\r\nV^T\\)</span>，其中U和V为正交矩阵，<span class=\"math inline\">\\(\\Sigma\\)</span>为非负降序对角矩阵。<img src=\"/2023/01/16/%E5%B9%BF%E4%B9%89EM%E7%9A%84%E4%B8%80%E4%B8%AA%E7%89%B9%E4%BE%8B%E6%98%AFVBEM/image-20220918213649385-16738440550725.png\" alt=\"image-20220918213649385\"></p></li>\r\n<li><p>对PLSA而言，共现模型也可以表示为三个矩阵乘积的形式： <span class=\"math display\">\\[\r\nX&#39; = U&#39;\\Sigma &#39;V&#39;^T\r\n\\newline\r\nX&#39; = [P(w,d)]_{M\\times N}\r\n\\newline\r\nU&#39;=[P(w|z)]_{M\\times K}\r\n\\newline\r\n\\Sigma&#39; = [P&#39;(z)]_{K\\times K}\r\n\\newline\r\nV&#39; = [P(d|z)]_{N\\times K}\r\n\\]</span></p></li>\r\n<li><p>两组矩阵的区别</p>\r\n<ul>\r\n<li>U’和 V'是非负的，规范化的，表示条件概率分布</li>\r\n<li>U和V是正交的，未必非负，不表示概率分布</li>\r\n</ul></li>\r\n</ul></li>\r\n<li><p>PLSA求解算法</p>\r\n<figure>\r\n<img src=\"/2023/01/16/%E5%B9%BF%E4%B9%89EM%E7%9A%84%E4%B8%80%E4%B8%AA%E7%89%B9%E4%BE%8B%E6%98%AFVBEM/image-20220918230311979-16738440550726.png\" alt=\"image-20220918230311979\">\r\n<figcaption aria-hidden=\"true\">image-20220918230311979</figcaption>\r\n</figure>\r\n<figure>\r\n<img src=\"/2023/01/16/%E5%B9%BF%E4%B9%89EM%E7%9A%84%E4%B8%80%E4%B8%AA%E7%89%B9%E4%BE%8B%E6%98%AFVBEM/image-20220918230411724-16738440550727.png\" alt=\"image-20220918230411724\">\r\n<figcaption aria-hidden=\"true\">image-20220918230411724</figcaption>\r\n</figure>\r\n<figure>\r\n<img src=\"/2023/01/16/%E5%B9%BF%E4%B9%89EM%E7%9A%84%E4%B8%80%E4%B8%AA%E7%89%B9%E4%BE%8B%E6%98%AFVBEM/image-20220918230642299-16738440550729.png\" alt=\"image-20220918230642299\">\r\n<figcaption aria-hidden=\"true\">image-20220918230642299</figcaption>\r\n</figure></li>\r\n</ul>\r\n<h4 id=\"马尔可夫链蒙特卡洛法\">马尔可夫链蒙特卡洛法</h4>\r\n<p>蒙特卡洛方法是从概率模型的随机抽样进行近似数值计算的方法。</p>\r\n<p>马尔可夫链蒙特卡洛法则是以马尔可夫链为概率模型的蒙特卡洛法。构建一个马尔可夫链，使其分布就是要抽样的分布，首先基于该马尔可夫链进行随机游走，产生样本的序列，之后使用该平稳分布的样本进行近似数值计算。</p>\r\n<ul>\r\n<li><p>蒙特卡洛法</p>\r\n<ul>\r\n<li><p>随机抽样</p>\r\n<p>接受-拒绝法一般流程：</p>\r\n<ul>\r\n<li>从[0,1]均匀分布抽样随机数<span class=\"math inline\">\\(u_0\\)</span>，然后计算<span class=\"math inline\">\\(x =\r\nF^{-1}(u_0)\\)</span>得到建议分布的随机样本<span class=\"math inline\">\\(x\\)</span>。(其中<span class=\"math inline\">\\(F(\\cdot)\\)</span>是建议分布的累积分布函数，<span class=\"math inline\">\\(F^{-1}(\\cdot)\\)</span>则是其逆函数)</li>\r\n<li>再从[0,1]均匀分布中抽样随机数<span class=\"math inline\">\\(u_1\\)</span>，和<span class=\"math inline\">\\(A(x) =\r\n\\frac{p(x)}{M\\cdot q(x)}\\)</span>比较，大于则拒绝；小于则接受。</li>\r\n<li>得到抽样<span class=\"math inline\">\\(x\\)</span>。</li>\r\n</ul></li>\r\n<li><p>数学期望估计</p>\r\n<p>对概率密度函数<span class=\"math inline\">\\(p(x)\\)</span>独立抽取n个样本<span class=\"math inline\">\\(x_1,x_2,...,x_n\\)</span>，之后计算函数<span class=\"math inline\">\\(f(x)\\)</span>的样本均值<span class=\"math inline\">\\(\\hat{f}_n\\)</span>: <span class=\"math display\">\\[\r\n\\hat{f}_n = \\frac{1}{n}\\sum_{i=1}^nf(x_i)\r\n\\]</span> 作为数学期望<span class=\"math inline\">\\(E_{p(x)}[f(x)]\\)</span>的估计值。（由大数定律可得到）</p></li>\r\n<li><p>积分计算 <span class=\"math display\">\\[\r\n\\int_{\\mathcal{X}}h(x)dx = \\int_{\\mathcal{X}}g(x)f(x)dx=E_{p(x)}[f(x)]\r\n\\]</span></p></li>\r\n</ul></li>\r\n</ul>\r\n<h4 id=\"马尔可夫链\">马尔可夫链</h4>\r\n<ul>\r\n<li><p>遍历定理</p>\r\n<p>设有马尔可夫链 <span class=\"math inline\">\\(X =\r\n\\{X_0,X_1,...,X_t,...\\}\\)</span>，状态空间为<span class=\"math inline\">\\(S\\)</span>，若马尔可夫链是不可约、非周期且正常返的，则该马尔可夫链有唯一平稳分布<span class=\"math inline\">\\(\\pi =\r\n(\\pi_1,\\pi_2,...)^T\\)</span>，并且转移概率的极限分布是马尔可夫链的平稳分布\r\n<span class=\"math display\">\\[\r\n\\lim_{t\\rightarrow\\infty}P(X_t=i|X_0=j) = \\pi_i,i=1,2,...;j=1,2,...\r\n\\]</span> 若<span class=\"math inline\">\\(f(X)\\)</span>是定义在状态空间上的函数，<span class=\"math inline\">\\(E_{\\pi}[|f(X)|]&lt;\\infty\\)</span>，则 <span class=\"math display\">\\[\r\nP\\{\\hat{f}_t\\rightarrow E_\\pi[f(X)] \\} = 1,t\\rightarrow \\infty\r\n\\\\\r\n\\hat{f}_t = \\frac{1}{t}\\sum_{s=1}^t f(x_s)\r\n\\\\\r\nE_\\pi[f(X)] = \\sum_if(i)\\pi_i\r\n\\]</span>\r\n样本均值是一次次时间步骤产生的，是时间均值。期望是同一时间状态空间不同状态和对应概率的积的和，是空间均值。遍历定理其实是证明了当时间趋于无穷的时候，时间均值就等于空间均值。</p></li>\r\n<li><p>可逆马尔可夫链</p>\r\n<p>设有马尔可夫链<span class=\"math inline\">\\(X =\r\n\\{X_0,X_1,...,X_t,...\\}\\)</span>，状态空间为<span class=\"math inline\">\\(S\\)</span>，转移概率矩阵为<span class=\"math inline\">\\(P\\)</span>，如果状态分布<span class=\"math inline\">\\(\\pi =\r\n(\\pi_1,\\pi_2,\\cdot\\cdot\\cdot)^T\\)</span>，对于任意状态<span class=\"math inline\">\\(i,j\\in S\\)</span>，对任意一个时刻<span class=\"math inline\">\\(t\\)</span>满足: <span class=\"math display\">\\[\r\nP(X_t = i|X_{t-1} = j)\\pi_j = P(X_{t-1}=j|X_t = i)\\pi_i,i,j=1,2,...\r\n\\]</span> 或简写为 <span class=\"math display\">\\[\r\np_{ij}\\pi_j = p_{ji}\\pi_i,i,j=1,2,...\r\n\\]</span> 则称此马尔可夫链<span class=\"math inline\">\\(X\\)</span>为可逆马尔科夫链，上式称为<strong>细致平衡方程</strong>。</p>\r\n<p>直观上，对一个可逆马尔可夫链而言，以该马尔可夫链的平稳分布作为初始分布，进行随机状态转移，无论是面向未来还是面向过去，任何一个时刻的状态分布都是该平稳分布。</p>\r\n<p><strong>定理</strong>：满足细致平衡方程的状态分布<span class=\"math inline\">\\(\\pi\\)</span>就是该马尔可夫链的平稳分布，即 <span class=\"math display\">\\[\r\nP\\pi = \\pi\r\n\\]</span></p></li>\r\n</ul>\r\n<h4 id=\"马尔可夫链蒙特卡罗法\">马尔可夫链蒙特卡罗法</h4>\r\n<ul>\r\n<li><p>基本思想</p>\r\n<ul>\r\n<li><p>目标</p>\r\n<ul>\r\n<li>对一个概率分布进行随机抽样</li>\r\n<li>求函数关于该概率分布的数学期望</li>\r\n</ul></li>\r\n<li><p>手段</p>\r\n<ul>\r\n<li>传统的蒙特卡罗法：接受-拒绝法，重要性抽样法</li>\r\n<li>马尔可夫链蒙特卡罗法：更适合随机变量是多元的，密度函数是非标准形式的，随机变量各分量不独立等情况</li>\r\n</ul></li>\r\n<li><p>Pipeline</p>\r\n<p>假设多元随机变量<span class=\"math inline\">\\(x \\in\r\n\\mathcal{X}\\)</span>，其概率密度函数为<span class=\"math inline\">\\(p(x)\\)</span>，<span class=\"math inline\">\\(f(x)\\)</span>为定义在<span class=\"math inline\">\\(x\\in\r\n\\mathcal{X}\\)</span>上的函数，目标是获得概率分布<span class=\"math inline\">\\(p(x)\\)</span>的样本集合，以及求函数<span class=\"math inline\">\\(f(x)\\)</span>的数学期望<span class=\"math inline\">\\(E_{p(x)}[f(x)]\\)</span>。</p>\r\n<ul>\r\n<li><p>在随机变量<span class=\"math inline\">\\(x\\)</span>的状态空间<span class=\"math inline\">\\(S\\)</span>上构造一个满足遍历定理的马尔可夫链，使其平稳分布为目标分布<span class=\"math inline\">\\(p(x)\\)</span></p>\r\n<blockquote>\r\n<p>连续变量的时候需要定义转移核函数；离散变量的时候需要定义转移矩阵。</p>\r\n<p>一个方法是定义特殊的转移核函数或转移矩阵，构建可逆马尔可夫链。这样可以保证（充分条件：可逆马尔科夫连一定有唯一平稳分布）遍历定理成立。</p>\r\n</blockquote></li>\r\n<li><p>从状态空间某一点<span class=\"math inline\">\\(x_0\\)</span>出发，用构造的马尔可夫链进行随机游走，产生样本序列<span class=\"math inline\">\\(x_0,x_1,...,x_t,...\\)</span></p></li>\r\n<li><p>应用马尔可夫链的遍历定理，确定正整数m和n，(m&lt;n)，得到样本集合<span class=\"math inline\">\\(\\{x_{m+1},x_{m+2},...,x_n\\}\\)</span>，求得函数<span class=\"math inline\">\\(f(x)\\)</span>的遍历均值 <span class=\"math display\">\\[\r\n\\hat{E}f = \\frac{1}{n-m}\\sum_{i=m+1}^nf(x_i)\r\n\\]</span> 就是马尔可夫链蒙特卡洛法的计算公式</p></li>\r\n</ul></li>\r\n</ul></li>\r\n</ul>\r\n<h4 id=\"马尔可夫链蒙特卡罗法与统计学习\">马尔可夫链蒙特卡罗法与统计学习</h4>\r\n<p>在贝叶斯学习中起着重要作用：它可以用于概率模型的学习和推理上。</p>\r\n<p>假设观测数据有随机变量<span class=\"math inline\">\\(y\\in\r\n\\mathcal{Y}\\)</span>表示，模型由随机变量<span class=\"math inline\">\\(x\\in\r\n\\mathcal{X}\\)</span>表示，贝叶斯学习通过贝叶斯定理计算给定数据条件下的模型的后验概率，并选择后验概率最大的模型。</p>\r\n<p>后验概率 <span class=\"math display\">\\[\r\np(x|y) =\r\n\\frac{p(x)p(y|x)}{\\int_{\\mathcal{X}}p(y|x&#39;)p(x&#39;)dx&#39;}\r\n\\]</span> 贝叶斯经常需要三种积分运算：</p>\r\n<ul>\r\n<li><p>规范化：后验概率计算中需要的： <span class=\"math display\">\\[\r\n\\int_{\\mathcal{X}}p(y|x&#39;)p(x&#39;)dx&#39;\r\n\\]</span></p></li>\r\n<li><p>边缘化：如果有隐变量<span class=\"math inline\">\\(z\\in\\mathcal{Z}\\)</span>，后验概率的计算需要边缘化计算\r\n<span class=\"math display\">\\[\r\np(x|y)=\\int_{\\mathcal{Z}}p(x,z|y)dz\r\n\\]</span></p></li>\r\n<li><p>数学期望：如果有一个函数<span class=\"math inline\">\\(f(x)\\)</span>，可以计算该函数关于后验概率分布的数学期望\r\n<span class=\"math display\">\\[\r\nE_{p(x)}[f(x)] = \\int_{\\mathcal{X}}f(x)p(x|y)dx\r\n\\]</span></p></li>\r\n</ul>\r\n<h4 id=\"metropolis-hastings算法\">Metropolis-Hastings算法</h4>\r\n<p>假设要抽样的概率分布为<span class=\"math inline\">\\(p(x)\\)</span>。Metropolis-Hastings算法采用的转移核为<span class=\"math inline\">\\(p(x,x&#39;)\\)</span>的马尔可夫链： <span class=\"math display\">\\[\r\np(x,x&#39;) = q(x,x&#39;)\\alpha(x,x&#39;)\r\n\\]</span> 其中<span class=\"math inline\">\\(q(x,x&#39;)\\)</span>和<span class=\"math inline\">\\(\\alpha(x,x&#39;)\\)</span>分别被称为建议分布和接受分布。</p>\r\n<ul>\r\n<li><p>建议分布</p>\r\n<ul>\r\n<li>是另一个马尔可夫链的转移核</li>\r\n<li>是不可约的，即概率值恒不为0</li>\r\n<li>是一个容易抽样的分布</li>\r\n<li>常见的两种形式\r\n<ul>\r\n<li>假设建议分布是对称的：q(x,x') = q(x',x)\r\n<ul>\r\n<li>比如选择条件概率分布<span class=\"math inline\">\\(p(x&#39;|x)\\)</span>，<strong>定义为</strong>以<span class=\"math inline\">\\(x\\)</span>为均值的多元正态分布，协方差矩阵是常数矩阵（在知道当前的x后，就可以从正态分布中抽取下一步的x'）</li>\r\n</ul></li>\r\n<li>独立抽样。假设q(x,x')与当前状态x无关，即q(x,x') = q(x')</li>\r\n</ul></li>\r\n</ul></li>\r\n<li><p>接受分布</p>\r\n<ul>\r\n<li>公式定义 <span class=\"math display\">\\[\r\n\\alpha(x,x&#39;) = min\\{1,\\frac{p(x&#39;)q(x&#39;,x)}{p(x)q(x,x&#39;)}\\}\r\n\\]</span></li>\r\n</ul></li>\r\n<li></li>\r\n<li><p>满条件分布</p>\r\n<ul>\r\n<li><p>定义</p>\r\n<p>多元联合概率分布<span class=\"math inline\">\\(p(x)=p(x_1,x_2,...,x_k)\\)</span>，其中<span class=\"math inline\">\\(x =\r\n(x_1,x_2,...,x_k)^T\\)</span>是k维随机变量。如果条件概率分布<span class=\"math inline\">\\(p(x_I|x_{-I})\\)</span>中所有k个变量全部出现，其中<span class=\"math inline\">\\(x_I = \\{x_i,i\\in I\\},x_{-I}=\\{x_i,i\\notin\r\nI\\},I\\subset K = \\{1,2,...,k\\}\\)</span></p></li>\r\n<li><p>性质</p>\r\n<p>对任意的<span class=\"math inline\">\\(x\\in\r\n\\mathcal{X}\\)</span>和任意的<span class=\"math inline\">\\(I \\subset\r\nK\\)</span>，有 <span class=\"math display\">\\[\r\np(x_I|x_{-I}) = \\frac{p(x)}{\\int p(x)dx_I} \\propto p(x)\r\n\\]</span> 而且对任意的<span class=\"math inline\">\\(x,x&#39;\\in\r\n\\mathcal{X}\\)</span>和任意的<span class=\"math inline\">\\(I \\subset\r\nK\\)</span>，有 <span class=\"math display\">\\[\r\n\\frac{p(x_I&#39;|x_{-I}&#39;)}{p(x_I|x_{-I})} = \\frac{p(x&#39;)}{p(x)}\r\n\\]</span>\r\n利用这个性质，可以通过满条件分布概率的比来计算联合概率的比，计算更加简单。</p></li>\r\n</ul></li>\r\n<li><p>Pipeline</p>\r\n<ul>\r\n<li>输入：抽样的目标分布的密度函数<span class=\"math inline\">\\(p(x)\\)</span>，函数<span class=\"math inline\">\\(f(x)\\)</span></li>\r\n<li>输出：<span class=\"math inline\">\\(p(x)\\)</span>的随机样本<span class=\"math inline\">\\(x_{m+1},x_{m+2},...,x_n\\)</span>，函数样本均值<span class=\"math inline\">\\(f_{mn}\\)</span></li>\r\n<li>参数：收敛步数m，迭代步数n</li>\r\n</ul>\r\n<p>(1)任选初始值<span class=\"math inline\">\\(x_0\\)</span></p>\r\n<p>(2)对i=1,2,...,n循环执行</p>\r\n<ul>\r\n<li>设状态<span class=\"math inline\">\\(x_{i-1} =\r\nx\\)</span>，按照<strong>建议分布</strong><span class=\"math inline\">\\(q(x,x&#39;)\\)</span>随机抽取一个候选状态<span class=\"math inline\">\\(x&#39;\\)</span></li>\r\n<li>计算接受概率<span class=\"math inline\">\\(\\alpha(x,x&#39;)\\)</span></li>\r\n<li>从区间(0,1)中按均匀分布抽取<span class=\"math inline\">\\(u\\)</span>\r\n<ul>\r\n<li>若<span class=\"math inline\">\\(u\\leq\r\n\\alpha(x,x&#39;)\\)</span>，则状态<span class=\"math inline\">\\(x_i=x&#39;\\)</span></li>\r\n<li>否则，<span class=\"math inline\">\\(x_i = x\\)</span></li>\r\n</ul></li>\r\n</ul>\r\n<p>得到<strong>样本集合</strong>并计算<strong>函数样本均值</strong>并返回·</p></li>\r\n<li><p>单分量Metropolis-Hastings算法</p>\r\n<p>在Metropolis-Hastings算法中，通常需要对多元变量分布进行抽样，有时对多元变量分布进行抽样是困难的。</p>\r\n<p>可以对多元变量的每一变量的条件分布一次进行抽样，从而实现对整个多元变量的一次抽样。</p></li>\r\n</ul>\r\n<h4 id=\"lda\">LDA</h4>\r\n<ul>\r\n<li></li>\r\n</ul>\r\n<h3 id=\"广义em的另一个特例是ws算法\">广义EM的另一个特例是WS算法</h3>\r\n<h4 id=\"bp算法\">BP算法</h4>\r\n<h4 id=\"wake-sleep算法\">Wake-Sleep算法</h4>\r\n<h3 id=\"广义em的再一个特例是gibbs-sampling\">广义EM的再一个特例是Gibbs\r\nSampling</h3>\r\n<h4 id=\"gibbs-sampling\">Gibbs Sampling</h4>\r\n<p>吉布斯抽样是单分量Metropolis-Hastings算法的特殊情况。前者抽样会在样本点见移动，但可能会由于被拒绝而有停留；后者会在样本点之间持续移动。前者适合于满条件概率分布不容易计算的情况，使用更容易抽样的条件概率分布做建议分布。后者适合于满条件概率分布容易计算的情况。</p>\r\n<p>定义建议分布是当前变量<span class=\"math inline\">\\(x_j,j=1,2,...,k\\)</span>的满条件概率分布 <span class=\"math display\">\\[\r\nq(x,x&#39;) = p(x&#39;_j|x_{-j})\r\n\\]</span>\r\n这时，接受概率很容易得到是1。因此，转移核函数也是满条件概率分布： <span class=\"math display\">\\[\r\np(x,x&#39;) = p(x&#39;_j|x_{-j})\r\n\\]</span></p>\r\n<ul>\r\n<li><p>输入：目标概率分布的密度函数<span class=\"math inline\">\\(p(x)\\)</span>，函数<span class=\"math inline\">\\(f(x)\\)</span></p></li>\r\n<li><p>输出：<span class=\"math inline\">\\(p(x)\\)</span>的随机样本<span class=\"math inline\">\\(x_{m+1},x_{m+2},...,x_n\\)</span>，函数样本均值<span class=\"math inline\">\\(f_{mn}\\)</span></p></li>\r\n<li><p>参数：收敛步数m，迭代步数n</p></li>\r\n<li><p>具体步骤：</p>\r\n<figure>\r\n<img src=\"/2023/01/16/%E5%B9%BF%E4%B9%89EM%E7%9A%84%E4%B8%80%E4%B8%AA%E7%89%B9%E4%BE%8B%E6%98%AFVBEM/image-20221026163129064-16738440550728.png\" alt=\"image-20221026163129064\">\r\n<figcaption aria-hidden=\"true\">image-20221026163129064</figcaption>\r\n</figure></li>\r\n<li><p>抽样计算</p>\r\n<p>可以利用概率分布的性质提高抽样的效率。</p>\r\n<figure>\r\n<img src=\"/2023/01/16/%E5%B9%BF%E4%B9%89EM%E7%9A%84%E4%B8%80%E4%B8%AA%E7%89%B9%E4%BE%8B%E6%98%AFVBEM/image-20221026164342352-167384405507310.png\" alt=\"image-20221026164342352\">\r\n<figcaption aria-hidden=\"true\">image-20221026164342352</figcaption>\r\n</figure>\r\n<p>也就是说，直接算看上去是和所有变量都有关的（都出现在了式子左边部分）但是实际上通过式子右边部分计算，只需要用到部分变量即可进行计算，更加简单。</p></li>\r\n</ul>\r\n<h3 id=\"ws算法是vae和gan组合的简化版\">WS算法是VAE和GAN组合的简化版</h3>\r\n<h4 id=\"vae\">VAE</h4>\r\n<h4 id=\"gan\">GAN</h4>\r\n<h3 id=\"kl距离的统一\">KL距离的统一</h3>\r\n<ul>\r\n<li>TODO</li>\r\n</ul>\r\n"},{"title":"GraphConstructionMethods4NLP","url":"/2023/01/16/GraphConstructionMethods4NLP/","content":"<h1 id=\"gnn-in-nlp-2\">GNN in NLP 2</h1>\r\n<blockquote>\r\n<p>GNN in\r\nNLP介绍的第二部分，延续上一部分内容。继续介绍三个子部分内容：</p>\r\n<ul>\r\n<li>Graph Construction Methods</li>\r\n<li>Graph Representation Learning</li>\r\n<li>Graph Based Encoder-Decoder Model</li>\r\n</ul>\r\n<span id=\"more\"></span>\r\n</blockquote>\r\n<h2 id=\"graph-construction-methods-for-natural-language-processing\">Graph\r\nConstruction Methods for Natural Language Processing</h2>\r\n<p>对绝大多数的NLP任务，典型的输入是一个文本序列，而不是图。因此，为了利用\r\nGNN 的强大功能，如何从文本序列构建图形输入成为一个艰巨的步骤。</p>\r\n<h3 id=\"static-graph-construction\">Static Graph Construction</h3>\r\n<p>静态图构建方法旨在通过利用现有的<strong>关系解析工具</strong>（例如，依赖解析）或手动定义的<strong>规则</strong>在预处理期间构建图结构。从概念上讲，静态图结合了隐藏在原始文本序列中的不同<strong>领域知识/外部知识</strong>，从而为原始文本增加了丰富的<strong>结构化信息</strong>。</p>\r\n<p>我们假设输入是一个文档<span class=\"math inline\">\\(doc =\r\n\\{para_1,para_2,...,para_n\\}\\)</span>，它由n个表示为para的段落组成。类似的，一个段落由m个句子组成<span class=\"math inline\">\\(para_i =\r\n\\{sent_1,sent_2,...,sent_m\\}\\)</span>每个句子由l个单词组成<span class=\"math inline\">\\(sent_i = \\{w_1,w_2,...,w_l\\}\\)</span></p>\r\n<p><strong>STATIC GRAPH CONSTRUCTION APPROACHES</strong></p>\r\n<ul>\r\n<li><p>Dependency Graph Construction</p>\r\n<figure>\r\n<img src=\"/2023/01/16/GraphConstructionMethods4NLP/image-20221013115352600.png\" alt=\"image-20221013115352600\">\r\n<figcaption aria-hidden=\"true\">image-20221013115352600</figcaption>\r\n</figure>\r\n<p>省流：</p>\r\n<ul>\r\n<li>节点：单词</li>\r\n<li>边：\r\n<ul>\r\n<li>依赖关系的边</li>\r\n<li>词在初始输入中的顺序的边（相邻则添加无向边）</li>\r\n</ul></li>\r\n</ul></li>\r\n<li><p>Constituency Graph Construction</p>\r\n<figure>\r\n<img src=\"/2023/01/16/GraphConstructionMethods4NLP/image-20221013115412629.png\" alt=\"image-20221013115412629\">\r\n<figcaption aria-hidden=\"true\">image-20221013115412629</figcaption>\r\n</figure>\r\n<p>省流：</p>\r\n<ul>\r\n<li>节点：\r\n<ul>\r\n<li>非终结节点<span class=\"math inline\">\\(V_{nt}\\)</span></li>\r\n<li>终结节点<span class=\"math inline\">\\(V_{words}\\)</span></li>\r\n</ul></li>\r\n<li>边：<span class=\"math inline\">\\(\\textbf{R}_{cons} \\subseteq\r\n\\textbf{V}_{nt} \\times (\\textbf{V}_{nt}+\\textbf{V}_{words})\\)</span>\r\n<ul>\r\n<li>选取关系的边，有向边从非终结节点指向终结节点，可以一对多（短语级别的关系）</li>\r\n<li>初始输入顺序的边仍然添加在相邻单词之间的无向边</li>\r\n</ul></li>\r\n</ul></li>\r\n<li><p>AMR Graph Construction</p>\r\n<figure>\r\n<img src=\"/2023/01/16/GraphConstructionMethods4NLP/image-20221013120751635.png\" alt=\"image-20221013120751635\">\r\n<figcaption aria-hidden=\"true\">image-20221013120751635</figcaption>\r\n</figure>\r\n<blockquote>\r\n<p>这是一个AMR图的示例，原始的句子是：\"Pual’s description of himself: a\r\nfighter\"。</p>\r\n</blockquote>\r\n<p>AMR图是<strong>有根、有标签、有向、无环图</strong>，广泛用于表示非结构化和具体自然文本的抽象概念之间的高级<strong>语义关系</strong>。</p>\r\n<p>AMR图表示的是句子的高级语义抽象。语义相似的不同句子可能会共享同样的AMR图。</p>\r\n<p>省流：AMR 图 G(V, E) 是有根的、标记的、有向的、无环图\r\n(DAG)，由下面讨论的 AMR 节点和 AMR 关系组成。</p>\r\n<ul>\r\n<li>节点：\r\n<ul>\r\n<li><strong>名称（name）</strong>（例如“Paul”）是节点实例的特定值</li>\r\n<li><strong>概念（concept）</strong>可以是英文单词（例如“boy”）、PropBank\r\n框架集（Kingsbury 和 Palmer，2002\r\n年）（例如“want-01”）或特殊关键字。</li>\r\n<li><strong>名称</strong>节点是唯一身份，而<strong>概念</strong>节点由不同的实例共享。</li>\r\n</ul></li>\r\n<li>边:连接节点的边称为关系（例如 :ARG0 和\r\n:name）。可以从带边的节点对中提取这些 AMR 关系，表示为<span class=\"math inline\">\\((n_i,r_{i,j},n_j)\\in R_{amr}\\)</span>\r\n<ul>\r\n<li>对每一个三元组，设置从节点<span class=\"math inline\">\\(n_i\\)</span>指向<span class=\"math inline\">\\(n_j\\)</span>的有向边，其边的类型为<span class=\"math inline\">\\(r_{i,j}\\)</span></li>\r\n</ul></li>\r\n</ul></li>\r\n<li><p>Information Extraction Graph Construction</p>\r\n<figure>\r\n<img src=\"/2023/01/16/GraphConstructionMethods4NLP/image-20221013151356999.png\" alt=\"image-20221013151356999\">\r\n<figcaption aria-hidden=\"true\">image-20221013151356999</figcaption>\r\n</figure>\r\n<blockquote>\r\n<p>一个 IE 图构建的例子，它包含<strong>共同引用过程(Co-reference\r\nprocess)</strong>和<strong>开放信息提取过程(Open Information Extraction\r\nprocess)</strong>。</p>\r\n</blockquote>\r\n<p>信息提取图（IE\r\nGraph）旨在提取结构信息以表示自然句子中的高级信息，例如基于文本的文档。</p>\r\n<p>下面我们将描述如何从给定的段落<span class=\"math inline\">\\(para\\)</span>中生成对应的IE\r\ngraph,这个过程主要分为三个步骤：</p>\r\n<ul>\r\n<li><p>coreference resolution</p>\r\n<p>共指解析是信息提取任务的基本过程，旨在找到引用文本序列中相同<strong>实体</strong>的<strong>表达式(expressions)</strong>。如图\r\n4 所示，名称“Pual”、名词术语“He”和“a renowned computer\r\nscientist”可能指的是同一个对象（人）。</p>\r\n<p>我们将共指簇 C\r\n表示为一组<strong>引用同一对象的短语</strong>。给定一个段落，可以得到从非结构化数据中提取的共指集\r\n<span class=\"math inline\">\\(C = \\{C_1, C_2, ...,\r\nC_n\\}\\)</span>。</p></li>\r\n<li><p>constructing IE relations</p>\r\n<p>为了构建IE图，我们首先需要从段落中提取三元组，这可以通过使用一些注明的信息提取系统实现。</p>\r\n<p>我们称<span class=\"math inline\">\\((subject,predicate,object)\\)</span>为一个关系，可以表示为<span class=\"math inline\">\\((n_i,r_{i,j},n_j)\\in R_{ie}\\)</span>.</p>\r\n<blockquote>\r\n<p>值得注意的是，如果两个三元组只有一个参数不同，而其他参数重叠，我们只保留较长的三元组。</p>\r\n</blockquote></li>\r\n<li><p>graph construction</p>\r\n<ul>\r\n<li>首先，对关系三元组，我们添加节点和对应的有向边，边的类型是对应的谓语类型</li>\r\n<li>然后，对于每个共指簇 <span class=\"math inline\">\\(C_i \\in\r\nC\\)</span>，可以将 <span class=\"math inline\">\\(C_i\\)</span>\r\n中的所有共指短语折叠到一个节点中。这可以通过仅保留一个节点来帮助大大<strong>减少节点数</strong>量并<strong>消除歧义</strong>。</li>\r\n</ul></li>\r\n</ul></li>\r\n<li><p>Discourse Graph Construction</p>\r\n<p>当候选文档太长时，许多 NLP\r\n任务都会遇到长依赖挑战。描述两个句子如何在逻辑上相互连接的<strong>语篇图(Discourse\r\nGraph)</strong>被证明可以有效应对这一挑战。</p>\r\n<ul>\r\n<li><p>Discourse Relation</p>\r\n<p>语篇关系源自语篇分析，旨在识别一组句子上的句子顺序约束。</p>\r\n<p>给定两个句子，我们可以将discourse relation定义为<span class=\"math inline\">\\((sent_i,sent_j)\\)</span>,它代表着\"<span class=\"math inline\">\\(sentence_j\\)</span>可以被放置到<span class=\"math inline\">\\(sentence_i\\)</span>之后\"的discourse relation。</p>\r\n<p>在许多NLP任务中，给定一个文档<span class=\"math inline\">\\(doc\\)</span>,我们首先将它分割成句子集<span class=\"math inline\">\\(V =\r\n\\{sent_1,sent_2,...,sent_m\\}\\)</span>。然后，我们应用discourse\r\nanalysis来得到成对的discourse relation，表示为<span class=\"math inline\">\\(R_{sep}\\subseteq V\\times V\\)</span>。</p></li>\r\n<li><p>Discourse Graph</p>\r\n<p>话语图 G(V, E) 由上面讨论的句子节点和话语关系组成。</p>\r\n<p>给定文档 doc 和话语关系集 <span class=\"math inline\">\\(R_{dis}\\)</span>，对于每个关系 <span class=\"math inline\">\\((sent_i, sent_j) \\in R_{dis}\\)</span>，添加节点\r\n<span class=\"math inline\">\\(v_i\\)</span>（对于句子 <span class=\"math inline\">\\(sent_i\\)</span>）和 <span class=\"math inline\">\\(v_j\\)</span>（对于句子 <span class=\"math inline\">\\(sent_j\\)</span>），并添加从节点 <span class=\"math inline\">\\(v_i\\)</span> 到节点 <span class=\"math inline\">\\(v_j\\)</span>的<strong>有向边</strong>。</p></li>\r\n</ul></li>\r\n<li><p>Knowledge Graph Construction</p>\r\n<figure>\r\n<img src=\"/2023/01/16/GraphConstructionMethods4NLP/image-20221013165928021.png\" alt=\"image-20221013165928021\">\r\n<figcaption aria-hidden=\"true\">image-20221013165928021</figcaption>\r\n</figure>\r\n<blockquote>\r\n<p>知识图构建示例，其中使用的知识库 (KB) 和生成的概念图均来自数据集\r\nMetaQA（Zhang 等人，2018b）。</p>\r\n</blockquote>\r\n<p>捕获实体和关系的知识图 (KG) 可以极大地促进许多 NLP\r\n应用程序中的学习和推理。</p>\r\n<p>一般来说，KG 可以根据它们的图构建方法分为两大类。</p>\r\n<ul>\r\n<li>许多应用程序将 KG\r\n视为<strong>非结构化数据</strong>的紧凑且可解释的中间表示。从概念上讲，它几乎类似于我们之前讨论过的\r\nIE 图。</li>\r\n<li>许多其他作品（Wu et al., 2020b; Ye et al., 2019; Bansal et al.,\r\n2019; Yang et al., 2019）整合了现有的知识库，例如 YAGO (Suchanek et al.,\r\n2008)）和ConceptNet (Speer et al., 2017) 进一步提高下游任务的性能 (Zhao\r\net al., 2020c)。</li>\r\n</ul>\r\n<p>下面我们重点讨论第二种知识图。</p>\r\n<p><span class=\"math inline\">\\(\\mathcal{G}(\\mathcal{V},\\mathcal{E})\\)</span>由知识库中的元素构成，元素三元组<span class=\"math inline\">\\((e_1,rel,e_2)\\)</span>中，前者是source\r\nentity,后者是target\r\nentity，中间的rel表示关系的类型。构建知识图的时候，前后两者为节点，中间的是从前者指向后者的有向边的类型。</p>\r\n<p>在当做数据增广手段的时候，由于知识库过大，且存在许多噪声，因此需要在特定域中抽取出对应的子图。其构建方法：不同应用差距很大，下面只是一种例子:</p>\r\n<ul>\r\n<li>首先需要做的是获取给定<strong>查询</strong>中的<strong>术语实例</strong>。</li>\r\n<li>然后可以通过一些匹配算法（例如最大子字符串匹配）将术语实例链接到 KG\r\n中的概念。这些概念被视为抽取出的子图中的初始节点</li>\r\n<li>下一步是获取 KG 中初始节点的 1 跳邻居。</li>\r\n<li>此外，可以通过应用一些图节点相关性模型来计算邻居与初始节点的相关性，例如个性化\r\nPageRank (PPR) 算法 (Page et al., 1999)。</li>\r\n<li>然后根据结果，可以进一步剪除相关分数低于置信阈值的边缘，并移除孤立的邻居。</li>\r\n<li>剩余的最终子图随后用于提供任何图表示学习模块。</li>\r\n</ul></li>\r\n<li><p>Coreference Graph Construction</p>\r\n<p>当给定段落中的两个或多个术语指代同一个对象时，就会发生<strong>共同指称(coreference或co-reference）</strong></p>\r\n<p>这种现象有助于更好地理解语料库的复杂结构和逻辑，解决歧义</p>\r\n<p>为了有效地利用共指信息，共指图被构造为显式地对隐式共指关系建模。</p>\r\n<p>给定一组短语，共指图可以链接指向文本语料库中相同实体的节点（短语）。在下面的小节中，我们将重点关注由\r\nm 个句子组成的段落 para 的共指图构造。值得注意的是，虽然它与 IE\r\n图的第一步类似，但共指图将通过图<strong>显式地对共指关系进行建模</strong>，而不是<strong>折叠成一个节点</strong>。</p>\r\n<ul>\r\n<li><p>Coreference Relation</p>\r\n<p>共指关系可以很容易地通过共指解析系统获得，如 IE\r\n图构造中所讨论的。类似地，我们可以在给定特定段落的情况下获得共指簇 C。簇\r\n<span class=\"math inline\">\\(C_i \\in C\\)</span>\r\n中的所有短语都指向同一个对象。</p></li>\r\n<li><p>Coreference Graph</p>\r\n<p>共指图建立在共指关系集 <span class=\"math inline\">\\(R_{coref}\\)</span>\r\n之上。根据节点类型，一般可以分为两大类：</p>\r\n<ul>\r\n<li>phrases (or mentions)</li>\r\n<li>words</li>\r\n</ul>\r\n<p>对第一类，coreference图由关系集合<span class=\"math inline\">\\(\\mathcal{R}_{coref}\\)</span>中的所有mentions构成。对于共指簇中的短语对<span class=\"math inline\">\\(p_i,p_j\\)</span>，我们可以在代表两个短语的节点之间添加无向边。</p>\r\n<p>对于第二类，共指图则是由words构成</p>\r\n<p>一个小的区别是，对于每个相关的<strong>短语</strong>，<strong>只链接</strong>每个短语的<strong>第一个单词</strong>。</p></li>\r\n</ul></li>\r\n<li><p>Similarity Graph Construction</p>\r\n<figure>\r\n<img src=\"/2023/01/16/GraphConstructionMethods4NLP/image-20221013174523073.png\" alt=\"image-20221013174523073\">\r\n<figcaption aria-hidden=\"true\">image-20221013174523073</figcaption>\r\n</figure>\r\n<blockquote>\r\n<p>相似图构建的示例。我们使用<strong>句子</strong>作为节点，并使用\r\n<strong>TF-IDF\r\n向量</strong>初始化它们的特征。<strong>较大的相似度值对应于较粗的虚线</strong>。</p>\r\n</blockquote>\r\n<p>由于相似度图通常是面向应用程序的，因此我们只关注为实体、句子和文档等各种类型的元素构建相似度图的基本过程，而忽略了应用程序的具体细节。值得注意的是，相似图的构建是在<strong>预处理过程</strong>中进行的，并<strong>没有</strong>与剩余的学习系统以端到端的方式<strong>联合训练</strong>。</p>\r\n<ul>\r\n<li><p>Similarity Graph</p>\r\n<p>给定一个语料库C，在相似度图G(V,\r\nE)中，图节点可以定义为实体、句子和文档等不同粒度级别。基础的节点集合用<span class=\"math inline\">\\(\\mathcal{V}\\)</span>来表示。</p>\r\n<p>人们可以通过各种机制计算节点特征，例如句子（或文档）的 TF-IDF（Liu\r\n等人，2019a；Yasunaga 等人，2017）和实体的embeddings（Linmei\r\n等人，2019）。</p>\r\n<p>节点对之间的<strong>相似度分数</strong>可以通过余弦相似度等各种度量来计算（Liu\r\net al., 2019a; Linmei et al., 2019; Yasunaga et al.,\r\n2017），用于表示节点对的<strong>边权重</strong>。</p></li>\r\n<li><p>Spare mechanism</p>\r\n<p>初始相似度图通常是密集的，即使某些边缘权重非常小甚至为负。这些值可以被视为噪声，它在相似度图中的作用很小。</p>\r\n<p>因此，提出了各种稀疏技术，通过对图进行稀疏化来进一步提高图的质量。</p>\r\n<p>一种广泛使用的稀疏方法是 <strong>k-NN</strong> (Liu et al.,\r\n2019a)。具体来说，对于节点 <span class=\"math inline\">\\(v_i\\)</span>\r\n和它的邻居集合 <span class=\"math inline\">\\(N\r\n(v_i)\\)</span>，只有通过保留 k 个最大边权重并丢弃剩余边来保留边。</p>\r\n<p>另一种广泛使用的方法是<span class=\"math inline\">\\(\\epsilon\r\n-sparse\\)</span>（Linmei et al., 2019; Yasunaga et al.,\r\n2017）。特别是，将删除权重小于某个阈值<span class=\"math inline\">\\(\\epsilon\\)</span>的边。</p></li>\r\n</ul></li>\r\n<li><p>Co-occurrence Graph Construction</p>\r\n<figure>\r\n<img src=\"/2023/01/16/GraphConstructionMethods4NLP/image-20221013235057395.png\" alt=\"image-20221013235057395\">\r\n<figcaption aria-hidden=\"true\">image-20221013235057395</figcaption>\r\n</figure>\r\n<blockquote>\r\n<p>共现图构造的示例，其中边权重代表单词之间的共现频率。我们将窗口大小设置为\r\n3。</p>\r\n</blockquote>\r\n<p>共现图旨在捕捉文本中单词之间的<strong>共现关系</strong>，广泛用于许多\r\nNLP 任务（Christopoulou 等人，2019；Zhang 和 Qian，2020；Zhang\r\n等人，2020f）。共现关系描述了两个词在固定大小的上下文窗口内同时出现的频率，是捕捉语料库中词之间语义关系的重要特征。在下文中，我们将首先介绍获得同现关系的方法，然后讨论为语料库\r\nC 构建同现图的基本过程。</p>\r\n<ul>\r\n<li><p>Co-occurrence Relation:</p>\r\n<p>共现关系由给定语料库 C 的共现矩阵定义。</p>\r\n<p>可以将矩阵的共现表示为 <span class=\"math inline\">\\(M \\in\r\n\\mathbb{R}^{|V |×|V |}\\)</span>，其中$ |V |$是 <span class=\"math inline\">\\(C\\)</span> 的词汇量。<span class=\"math inline\">\\(M_{w_i,w_j}\\)</span> 描述了词 <span class=\"math inline\">\\(w_i,w_j\\)</span> 在语料库 C\r\n中固定大小的滑动窗口内一起出现的次数。</p>\r\n<p>在得到共现矩阵之后，有两种典型的方法来计算单词之间的权重：</p>\r\n<ul>\r\n<li>共现频率</li>\r\n<li>逐点互信息/point-wise mutual information (PMI)</li>\r\n</ul></li>\r\n<li><p>Co-occurrence Graph</p>\r\n<p>同现图 <span class=\"math inline\">\\(\\mathcal{G}(\\mathcal{V},\\mathcal{E})\\)</span>\r\n由上面讨论的<strong>单词节点</strong>和<strong>同现关系</strong>组成。</p>\r\n<p>给定语料库<span class=\"math inline\">\\(C\\)</span> 和共现关系集 <span class=\"math inline\">\\(R_{co}\\)</span>，对于每个关系 <span class=\"math inline\">\\((w_i, w_j) \\in R_{co}\\)</span>，添加节点 <span class=\"math inline\">\\(v_i\\)</span>（对于单词 <span class=\"math inline\">\\(w_i\\)</span>）和 <span class=\"math inline\">\\(v_j\\)</span>（对于单词 <span class=\"math inline\">\\(w_j\\)</span>）并添加来自节点的无向<strong>边</strong><span class=\"math inline\">\\(v_i\\)</span> 到节点 <span class=\"math inline\">\\(v_j\\)</span>\r\n用上述计算的<strong>边权重</strong>初始化。</p></li>\r\n</ul></li>\r\n<li><p>Topic Graph Construction</p>\r\n<figure>\r\n<img src=\"/2023/01/16/GraphConstructionMethods4NLP/image-20221014000501523.png\" alt=\"image-20221014000501523\">\r\n<figcaption aria-hidden=\"true\">image-20221014000501523</figcaption>\r\n</figure>\r\n<blockquote>\r\n<p>主题图构建示例，其中虚线表示通过利用数据集 AG 新闻上的 LDA\r\n算法进行的主题建模过程</p>\r\n</blockquote>\r\n<p>主题图建立在<strong>多个文档</strong>之上，旨在对<strong>不同主题之间的高级语义关系</strong>进行建模。</p>\r\n<ul>\r\n<li>输入：<span class=\"math inline\">\\(\\mathcal{D} =\r\n\\{doc_1,doc_2,...,doc_m\\}\\)</span></li>\r\n<li>流程：\r\n<ul>\r\n<li>通过LDA等算法学习潜在的主题<span class=\"math inline\">\\(\\mathcal{T}\\)</span></li>\r\n<li>则图为<span class=\"math inline\">\\(\\mathcal{G}(\\mathcal{V},\\mathcal{E})\\)</span>,其中<span class=\"math inline\">\\(\\mathcal{V} =\r\n\\mathcal{D}\\cup\\mathcal{T}\\)</span>,我们添加从文档<span class=\"math inline\">\\(v_i\\)</span>到主题<span class=\"math inline\">\\(v_j\\)</span>之间的无向边。当且仅当该文档含有该主题时添加。</li>\r\n</ul></li>\r\n</ul></li>\r\n<li><p>App-driven Graph Construction</p>\r\n<figure>\r\n<img src=\"/2023/01/16/GraphConstructionMethods4NLP/image-20221014000533458.png\" alt=\"image-20221014000533458\">\r\n<figcaption aria-hidden=\"true\">image-20221014000533458</figcaption>\r\n</figure>\r\n<blockquote>\r\n<p>应用程序驱动的图构建示例，专为 SQL 查询输入而设计。</p>\r\n</blockquote>\r\n<p>应用驱动图是指专门为特定 NLP\r\n任务设计的图，前面讨论的静态图类型无法轻松涵盖。</p>\r\n<p>在一些 NLP\r\n任务中，通常使用特定于应用程序的方法通过结构化形成来表示非结构化数据。例如，SQL\r\n语言可以很自然地用 SQL 解析树来表示。因此它可以转换为 SQL 图（Xu et al.,\r\n2018a; Bogin et al., 2019a; Huo et al., 2019; Bogin et al.,\r\n2019b）。由于这些图基于领域知识过于专业，因此没有统一的模式来总结如何构建应用程序驱动的图。</p></li>\r\n</ul>\r\n<p><strong>HYBRID GRAPH CONSTRUCTION AND DISCUSSION</strong></p>\r\n<p>大多数以前的静态图构造方法只考虑节点之间的<strong>一种</strong>特定关系。尽管获得的图在一定程度上很好地捕捉了结构信息，但它们在利用<strong>不同类型</strong>的图关系方面也受到限制。</p>\r\n<p>为了解决这个限制，人们越来越关注通过将<strong>多个图组合在一起</strong>来构建<strong>混合图</strong>，以丰富图中的语义信息。这些构造混合图的方法往往是根据应用变化的，下面给出一些代表性方法。</p>\r\n<p>为了捕获多个关系，一个常见的策略是构建一个<strong>异构图(heterogeneous\r\ngraph)</strong>，其中包含多种类型的节点和边。在不失一般性的情况下，我们假设可以创建具有两个不同图源\r\n<span class=\"math inline\">\\(\\mathcal{G}_a(\\mathcal{V}_a,\r\n\\mathcal{E}_a)\\)</span> 和 <span class=\"math inline\">\\(\\mathcal{G}_b(\\mathcal{V}_b,\r\n\\mathcal{E}_b)\\)</span>的混合图 Ghybrid。图 a、b\r\n是两种不同的图类型，例如依赖图和选区图。</p>\r\n<ul>\r\n<li><p>给定这些文本输入，如果 <span class=\"math inline\">\\(\\mathcal{G}_a\\)</span> 和 <span class=\"math inline\">\\(\\mathcal{G}_b\\)</span> 共享相同的节点集（即 <span class=\"math inline\">\\(\\mathcal{V}_a =\r\n\\mathcal{V}_b\\)</span>），我们通过<strong>注释特定关系的边类型</strong>来合并边集。</p></li>\r\n<li><p>否则，我们将 $_a <span class=\"math inline\">\\(和\\)</span> _b$\r\n合并得到混合节点集，记为 <span class=\"math inline\">\\(\\mathcal{V} =\r\n\\mathcal{V}_a \\cup\r\n\\mathcal{V}_b\\)</span>。然后我们通过将源节点和目标节点从 $_a <span class=\"math inline\">\\(和\\)</span> _b$ 映射到 <span class=\"math inline\">\\(\\mathcal{V}\\)</span> 来生成 <span class=\"math inline\">\\(\\mathcal{E}_a\\)</span> 和 <span class=\"math inline\">\\(\\mathcal{E}_b\\)</span> 到 <span class=\"math inline\">\\(\\mathcal{E}\\)</span>。</p></li>\r\n</ul>\r\n<h3 id=\"dynamic-graph-construction\">Dynamic Graph Construction</h3>\r\n<p>尽管静态图构造具有将数据的<strong>先验知识</strong>编码到图结构中的优点，但它有几个限制。</p>\r\n<ul>\r\n<li>为了构建合理性能的图拓扑，需要大量的人力和领域专业知识。</li>\r\n<li>手动构建的图结构可能容易出错（例如，嘈杂或不完整）</li>\r\n<li>由于图构建阶段和图表示学习阶段是不相交的，在图构建阶段引入的错误无法纠正，可能会累积到后续阶段，从而导致性能下降。</li>\r\n<li>图构建过程通常仅由机器学习从业者的洞察力提供信息，并且对于下游预测任务可能不是最佳的</li>\r\n</ul>\r\n<p>大多数动态图构建方法旨在<strong>动态学习图结构（即加权邻接矩阵）</strong>，并且图构建模块可以<strong>与后续图表示学习模块联合优化</strong>，以实现<strong>端到端</strong>的下游任务。</p>\r\n<figure>\r\n<img src=\"/2023/01/16/GraphConstructionMethods4NLP/image-20221015000556815.png\" alt=\"image-20221015000556815\">\r\n<figcaption aria-hidden=\"true\">image-20221015000556815</figcaption>\r\n</figure>\r\n<blockquote>\r\n<p>动态图构建方法的总体说明。虚线（在左侧的数据点中）表示可选的内在图拓扑。</p>\r\n</blockquote>\r\n<p>这些动态图构建方法通常包括一个<strong>图相似度度量学习组件</strong>，用于通过考虑嵌入空间中的<strong>成对节点相似性</strong>来学习<strong>邻接矩阵</strong>，以及一个<strong>图稀疏化组件</strong>，用于从学习的全连接图中提取<strong>稀疏图</strong>。</p>\r\n<p>据报道，将<strong>内在图结构</strong>和学习的<strong>隐式图结构</strong>相结合以获得更好的学习性能是有益的。</p>\r\n<p>此外，为了有效地进行联合<strong>图结构和表示</strong>学习，已经提出了各种学习范式。</p>\r\n<p><strong>GRAPH SIMILARITY METRIC LEARNING TECHNIQUES</strong></p>\r\n<p>基于假设<strong>节点属性包含用于学习隐式图结构的信息</strong>，最近的工作将图结构学习问题转换成定义在节点嵌入空间的相似度度量学习问题。</p>\r\n<p>学习到的<strong>相似度度量函数</strong>可以之后被应用到未见过的节点embeddings中去推断一个图结构，从而实现归纳图结构。</p>\r\n<ul>\r\n<li><p>Node Embedding Based Similarity Metric Learning</p>\r\n<p>基于节点嵌入的相似度度量函数旨在通过计算嵌入空间中的成对节点<strong>相似度</strong>来学习<strong>加权邻接矩阵</strong>。</p>\r\n<p>常见的度量函数包括基于<strong>注意力</strong>的度量函数和基于<strong>余弦</strong>的度量函数。</p>\r\n<ul>\r\n<li><p>Attention-based Similarity Metric Functions(most of the\r\nsimilarity metric functions)</p>\r\n<p>为了提高基于<strong>点积</strong>的注意力机制的学习能力，Chen 等人。\r\n（2020d）通过引入可学习参数提出了一种改进的点积，公式如下： <span class=\"math display\">\\[\r\nS_{i,j} = (\\vec{v_i}\\odot\\vec{u})^{T}\\vec{v_j}\r\n\\]</span> 其中<span class=\"math inline\">\\(\\vec{u}\\)</span>是一个非负的权重向量，学习它以便于强调节点embeddings中的不同维度。其中<span class=\"math inline\">\\(\\odot\\)</span>是逐元素的向量乘法。</p>\r\n<p>相似的，通过引入一个可学习的权重矩阵，一个更具表现力的点积版本，公式如下：\r\n<span class=\"math display\">\\[\r\nS_{i,j} = ReLU(\\vec{W}\\vec{v_i})^TReLU(\\vec{W}\\vec{v_j})\r\n\\]</span> 其中<span class=\"math inline\">\\(\\vec{W}\\)</span>是一个<span class=\"math inline\">\\(d\\times d\\)</span>的权重矩阵，而<span class=\"math inline\">\\(ReLU(x) = max(0, x)\\)</span> 是一个整流线性单元\r\n(ReLU)，用于强制相似矩阵的稀疏性。</p></li>\r\n<li><p>Cosine-based Similarity Metric Functions.</p>\r\n<p>陈等人。\r\n（2020e）将基础余弦相似度扩展为<strong>多头加权余弦相似度</strong>，以从多个角度捕获成对节点相似度，公式如下：\r\n<span class=\"math display\">\\[\r\nS_{i,j}^p = cos(\\vec{w}_p\\odot\\vec{v_i},\\vec{w}_p\\odot\\vec{v}_j)\r\n\\newline\r\nS_{i,j} = \\frac{1}{m}\\sum_{p=1}^{m}S_{i,j}^p\r\n\\]</span> 其中的<span class=\"math inline\">\\(\\vec{w}_p\\)</span>是一个和第p个视角相关的权重向量，和节点embeddings有相同的维数。</p>\r\n<p>直观地说，<span class=\"math inline\">\\(S^p_{i,j}\\)</span> 计算第 p\r\n个视角的成对余弦相似度，其中每个视角都考虑嵌入中捕获的语义的一部分。</p>\r\n<p>除了<strong>提高学习能力</strong>外，采用多头学习器还能够<strong>稳定学习过程</strong>。</p></li>\r\n</ul></li>\r\n<li><p>Structure-aware Similarity Metric Learning</p>\r\n<p>受结构感知转换器（structure-aware\r\ntransformers）的启发，最近的方法采用了<strong>结构感知相似度度量函数</strong>，该函数额外考虑了节点信息之外的<strong>内在图的现有边缘信息</strong>。</p>\r\n<p>一种用于学习成对节点相似度的结构感知注意机制，公式如下： <span class=\"math display\">\\[\r\nS_{i,j}^l =\r\nsoftmax(\\vec{u}^Ttanh(\\vec{W}[\\vec{h}_i^l,\\vec{h}_j^l,\\vec{v}_i,\\vec{v}_j,\\vec{e}_{i,j}]))\r\n\\]</span> 其中<span class=\"math inline\">\\(\\vec{v}_i\\)</span>表示的是节点i的embeddings,<span class=\"math inline\">\\(\\vec{e}_{i,j}\\)</span>表示的是连接节点i和j的边的embeddings。<span class=\"math inline\">\\(\\vec{h}_i^l\\)</span>是在第l个GNN层中的节点i的embeddings。并且，<span class=\"math inline\">\\(\\vec{u}\\)</span>和<span class=\"math inline\">\\(\\vec{W}\\)</span>是可训练的权重向量和权重矩阵。</p>\r\n<p>一种结构感知的全局注意力机制，公式如下： <span class=\"math display\">\\[\r\nS_{i,j} =\r\n\\frac{ReLU(\\vec{W}^Q\\vec{v}_i)^T(ReLU(\\vec{W}^K\\vec{v}_j))+ReLU(\\vec{W}^R\\vec{e}_{i,j})}{\\sqrt{d}}\r\n\\]</span>\r\n三个W是将节点embeddings和边embeddings映射到潜在embeddings空间的线性映射。</p></li>\r\n</ul>\r\n<p><strong>GRAPH SPARSIFICATION TECHNIQUES</strong></p>\r\n<p>现实世界场景中的大多数图都是稀疏图。<strong>相似度度量函数</strong>考虑任何节点对之间的关系并返回一个<strong>全连接图</strong>，这不仅<strong>计算量大</strong>，而且可能<strong>引入噪声</strong>，例如不重要的边。因此，明确地对学习的图结构<strong>强制执行</strong>稀疏性可能是有益的。除了在相似性度量函数中<strong>应用\r\nReLU 函数</strong>（Chen et al., 2020f; Liu et al.,\r\n2021b），还采用了各种图稀疏化技术来增强学习图结构的稀疏性。</p>\r\n<ul>\r\n<li><p>一个kNN风格的稀疏化操作，从相似度学习函数计算的节点相似度矩阵中得到一个稀疏邻接矩阵，公式如下：\r\n<span class=\"math display\">\\[\r\n\\vec{A}_{i,:} = topk(\\vec{S}_{i,:})\r\n\\]</span>\r\n对每个节点，只有K个最近的邻居节点(包括它自己)以及对应的相似度分数会被保留下来，剩下的相似度分数会被屏蔽掉。</p></li>\r\n<li><p>通过仅考虑每个节点的 <span class=\"math inline\">\\(ε\\)</span>-邻域来强制执行稀疏邻接矩阵，公式如下：\r\n<span class=\"math display\">\\[\r\nA _ { i , j } = \\{ \\begin{array}  { l l  }  { S _ { i , j } } &amp; { S\r\n_ { i , j } \\gt ε } \\\\ { 0 } &amp; { otherwise } \\end{array}\r\n\\]</span> 其中 S 中小于非负阈值<span class=\"math inline\">\\(ε\\)</span>的那些元素都被屏蔽掉（即设置为零）。</p></li>\r\n<li><p>除了通过应用某种形式的阈值来显式地强制学习图的稀疏性之外，稀疏性还以基于<strong>学习的方式隐式地强制执行</strong>。陈等人。\r\n（2020e）引入了以下正则化术语来鼓励稀疏图。 <span class=\"math display\">\\[\r\n\\frac{1}{n^2}||A||^2_F\r\n\\]</span> 在哪里 <span class=\"math inline\">\\(|| · ||_F\\)</span>\r\n表示矩阵的 <strong>Frobenius 范数</strong>。</p>\r\n<blockquote>\r\n<p>矩阵A的Frobenius范数定义为矩阵A各项<strong>元素的绝对值平方的总和</strong></p>\r\n</blockquote></li>\r\n</ul>\r\n<p><strong>COMBINING INTRINSIC GRAPH STRUCTURES AND IMPLICIT GRAPH\r\nSTRUCTURES</strong></p>\r\n<p>最近的研究表明，如果在进行动态图构建时完全丢弃内在图结构，可能会损害下游任务的性能。这可能是因为内在图通常仍然携带有关下游任务的最佳图结构的丰富且有用的信息。</p>\r\n<p>因此，他们提出将学习到的隐式图结构与内在图结构相结合，<strong>假设</strong>是学习到的隐式图可能是内在图结构的“转移”（例如子结构），内在图结构是对内在图结构的补充。</p>\r\n<p>另一个潜在的好处是结合内在的图结构可能有助于<strong>加速训练过程</strong>并提高<strong>训练稳定性</strong>。(由于没有关于相似度度量的先验知识，并且可训练的参数是随机初始化的，因此通常可能需要很长时间才能收敛。)</p>\r\n<p>提出计算内在图结构的归一化图拉普拉斯算子 $L^{(0)} $和隐式图结构 <span class=\"math inline\">\\(f(A)\\)</span>\r\n的归一化邻接矩阵的线性组合，公式如下： <span class=\"math display\">\\[\r\n\\widetilde{A} = \\lambda L^{(0)} + (1-\\lambda)f(A)\r\n\\]</span> 其中<span class=\"math inline\">\\(f: \\mathbb{R}^{n \\times n}\r\n\\rightarrow \\mathbb{R}^{n \\times\r\nn}\\)</span>可以是任意归一化操作，例如图拉普拉斯运算和行归一化操作。</p>\r\n<p>并没有明确地融合两个图邻接矩阵,而是提出了一种用于 GNN\r\n的<strong>混合消息传递机制</strong>，该机制分别融合从内在图和学习到的隐式图计算的两个聚合节点向量，然后将融合向量馈送到\r\nGRU 以更新节点嵌入。</p>\r\n<p><strong>LEARNING PARADIGMS</strong></p>\r\n<p>大多数现有的 GNN\r\n动态图构建方法由两个关键学习组件组成：图结构学习（即相似性度量学习）和图表示学习（即\r\nGNN\r\n模块），最终目标是学习优化关于某些下游预测任务的<strong>图结构和表示</strong>。</p>\r\n<p>如何优化两个独立的学习组件以实现相同的最终目标成为一个重要的问题。</p>\r\n<ul>\r\n<li>最直接的策略是以端到端的方式共同优化整个学习系统，面向下游（半）监督预测任务。</li>\r\n<li>另一种常见的策略是自适应地学习每个堆叠 GNN\r\n层的输入图结构，以反映中间图表示的变化。这类似于 Transformer\r\n模型如何在每一层中学习不同的加权全连接图。</li>\r\n<li>提出了一种<strong>迭代</strong>图学习框架，通过基于更好的<strong>图表示</strong>学习更好的<strong>图结构</strong>，同时以迭代的方式基于更好的<strong>图结构</strong>学习更好的<strong>图表示</strong>。结果，这种迭代学习范式反复细化图结构和图表示以达到最佳下游性能。</li>\r\n</ul>\r\n<h2 id=\"graph-representation-learning-for-nlp\">Graph Representation\r\nLearning for NLP</h2>\r\n<p>在本节中，我们将讨论各种图表示学习技术，这些技术直接在构建的图上运行，用于各种\r\nNLP 任务。</p>\r\n<p>图表示学习技术</p>\r\n<ul>\r\n<li>目标：找到一种通过<strong>机器学习模型</strong>将<strong>图结构和属性信息</strong>合并到<strong>低维embeddings</strong>中的方法</li>\r\n<li>数学形式化：\r\n<ul>\r\n<li>图： <span class=\"math inline\">\\(\\mathcal{G}(\\mathcal{V},\\mathcal{E},\\mathcal{T},\\mathcal{R})\\)</span>\r\n<ul>\r\n<li>节点集合： <span class=\"math inline\">\\(\\mathcal{V}\\)</span></li>\r\n<li>边集合： <span class=\"math inline\">\\(\\mathcal{E}\\)</span></li>\r\n<li>节点类型 <span class=\"math inline\">\\(\\mathcal{T} =\r\n\\{T_1,T_2,...,T_p\\}\\)</span></li>\r\n<li>边类型： <span class=\"math inline\">\\(\\mathcal{R} =\r\n\\{R_1,...,R_q\\}\\)</span></li>\r\n</ul></li>\r\n<li>元素数目： <span class=\"math inline\">\\(|\\cdot|\\)</span></li>\r\n<li>节点类型指示函数：<span class=\"math inline\">\\(\\tau(\\cdot) \\in\r\n\\mathcal{T}\\)</span>，其中输入元素为节点<span class=\"math inline\">\\(v_i\\)</span></li>\r\n<li>边类型指示函数：<span class=\"math inline\">\\(\\phi(\\cdot) \\in\r\n\\mathcal{R}\\)</span>，其中输入元素是边<span class=\"math inline\">\\(e_{i,j}\\)</span></li>\r\n</ul></li>\r\n</ul>\r\n<h3 id=\"gnns-for-homogeneous-graphs\">GNNs for Homogeneous Graphs</h3>\r\n<p>Homogeneous Graphs(同构图)：<span class=\"math inline\">\\(|\\mathcal{T}|\r\n= |\\mathcal{R}| = 1\\)</span></p>\r\n<h3 id=\"graph-neural-networks-for-multi-relational-graphs\">Graph Neural\r\nNetworks for Multi-relational Graphs</h3>\r\n<p>Multi-relational Graphs(多关系图)：<span class=\"math inline\">\\(|\\mathcal{T}| = 1\\)</span> 并且 <span class=\"math inline\">\\(|\\mathcal{R}| &gt; 1\\)</span></p>\r\n<h3 id=\"graph-neural-networks-for-heterogeneous-graph\">Graph Neural\r\nNetworks for Heterogeneous Graph</h3>\r\n<p>Heterogeneous Graphs(异构图)：<span class=\"math inline\">\\(|\\mathcal{T}| &gt; 1\\)</span> 或者 <span class=\"math inline\">\\(|\\mathcal{R}| &gt; 1\\)</span></p>\r\n<h2 id=\"gnn-based-encoder-decoder-models\">GNN Based Encoder-Decoder\r\nModels</h2>\r\n<figure>\r\n<img src=\"/2023/01/16/GraphConstructionMethods4NLP/image-20221016223847470.png\" alt=\"image-20221016223847470\">\r\n<figcaption aria-hidden=\"true\">image-20221016223847470</figcaption>\r\n</figure>\r\n<blockquote>\r\n<p>基于图的编码器-解码器模型的整体架构，包含 Graph2Seq 和 Graph2Tree\r\n模型。输入和输出来自 JOBS640 数据集 (Luke, 2005)。 S1、S2\r\n等节点代表子树节点，从中生成新的分支。</p>\r\n</blockquote>\r\n<h3 id=\"sequence-to-sequence-models\">Sequence-to-Sequence Models</h3>\r\n<h3 id=\"graph-to-sequence-models\">Graph-to-Sequence Models</h3>\r\n<p>与 Seq2Seq 范式相比，Graph2Seq\r\n范式更善于捕捉输入文本的丰富结构信息，可以应用于任意图结构数据。与\r\nSeq2Seq 模型相比，Graph2Seq 模型在包括神经机器翻译在内的广泛 NLP\r\n任务中表现出卓越的性能</p>\r\n<h3 id=\"graph-to-tree-models\">Graph-to-Tree Models</h3>\r\n<p>与考虑输入端结构信息的 Graph2Seq 模型相比，许多 NLP\r\n任务还包含以复杂结构表示的输出，例如树，输出端也包含丰富的结构信息，例如句法解析（Ji\r\net al., 2019)(Yang and Deng, 2020), 语义解析(Li et al., 2020a)(Xu et\r\nal., 2018c), 数学单词问题求解(Li et al., 2020a)(Zhang et al.,\r\n2020b)。考虑这些输出的结构信息是我们自然的选择。为此，提出了一些\r\nGraph2Tree\r\n模型，在输入端和输出端都包含结构信息，使编码解码过程中的信息流更加完整。</p>\r\n<h3 id=\"graph-to-graph-models\">Graph-to-Graph Models</h3>\r\n<p>通常用于解决图转换问题的图到图模型作为图编码器-解码器模型。</p>\r\n","tags":["EM算法"]}]